{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa5GTlUs2306",
        "outputId": "bd5b5e11-a69d-4b36-c910-9950053b9975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'stock_time_llm' already exists and is not an empty directory.\n",
            "/home/fakoor/Desktop/chitsaz/emotion_detection/stock_time_llm\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/androidwoman/stock_time_llm.git\n",
        "%cd /home/fakoor/Desktop/chitsaz/emotion_detection/stock_time_llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hH3daSu_B_S2",
        "outputId": "2d5f182a-48d6-4adb-f60d-5cf41819f671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch==2.2.2 (from -r requirements.txt (line 1))\n",
            "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting accelerate==0.28.0 (from -r requirements.txt (line 2))\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting einops==0.7.0 (from -r requirements.txt (line 3))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting matplotlib==3.7.0 (from -r requirements.txt (line 4))\n",
            "  Downloading matplotlib-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting numpy==1.23.5 (from -r requirements.txt (line 5))\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting pandas==1.5.3 (from -r requirements.txt (line 6))\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scikit_learn==1.2.2 (from -r requirements.txt (line 7))\n",
            "  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy==1.12.0 (from -r requirements.txt (line 8))\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting tqdm==4.65.0 (from -r requirements.txt (line 9))\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl.metadata (56 kB)\n",
            "Collecting peft==0.4.0 (from -r requirements.txt (line 10))\n",
            "  Downloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting transformers==4.31.0 (from -r requirements.txt (line 11))\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
            "Collecting deepspeed==0.14.0 (from -r requirements.txt (line 12))\n",
            "  Downloading deepspeed-0.14.0.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m963.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting sentencepiece==0.2.0 (from -r requirements.txt (line 13))\n",
            "  Using cached sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: filelock in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (1.13.2)\n",
            "Requirement already satisfied: networkx in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (12.1.105)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (12.1.0.106)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from torch==2.2.2->-r requirements.txt (line 1)) (12.1.105)\n",
            "Collecting triton==2.2.0 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (24.1)\n",
            "Requirement already satisfied: psutil in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (6.0.0)\n",
            "Requirement already satisfied: pyyaml in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (0.24.6)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (0.4.5)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib==3.7.0->-r requirements.txt (line 4))\n",
            "  Downloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib==3.7.0->-r requirements.txt (line 4))\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib==3.7.0->-r requirements.txt (line 4))\n",
            "  Using cached fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
            "Collecting kiwisolver>=1.0.1 (from matplotlib==3.7.0->-r requirements.txt (line 4))\n",
            "  Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting pillow>=6.2.0 (from matplotlib==3.7.0->-r requirements.txt (line 4))\n",
            "  Using cached pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib==3.7.0->-r requirements.txt (line 4))\n",
            "  Downloading pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 6)) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from scikit_learn==1.2.2->-r requirements.txt (line 7)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from scikit_learn==1.2.2->-r requirements.txt (line 7)) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 11)) (2024.7.24)\n",
            "Requirement already satisfied: requests in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from transformers==4.31.0->-r requirements.txt (line 11)) (2.32.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0->-r requirements.txt (line 11))\n",
            "  Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting hjson (from deepspeed==0.14.0->-r requirements.txt (line 12))\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting ninja (from deepspeed==0.14.0->-r requirements.txt (line 12))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting py-cpuinfo (from deepspeed==0.14.0->-r requirements.txt (line 12))\n",
            "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
            "Collecting pydantic (from deepspeed==0.14.0->-r requirements.txt (line 12))\n",
            "  Downloading pydantic-2.9.1-py3-none-any.whl.metadata (146 kB)\n",
            "Collecting pynvml (from deepspeed==0.14.0->-r requirements.txt (line 12))\n",
            "  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->-r requirements.txt (line 1)) (12.6.68)\n",
            "Requirement already satisfied: six>=1.5 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib==3.7.0->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from jinja2->torch==2.2.2->-r requirements.txt (line 1)) (2.1.5)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic->deepspeed==0.14.0->-r requirements.txt (line 12))\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.23.3 (from pydantic->deepspeed==0.14.0->-r requirements.txt (line 12))\n",
            "  Downloading pydantic_core-2.23.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages (from sympy->torch==2.2.2->-r requirements.txt (line 1)) (1.3.0)\n",
            "Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:08\u001b[0mm\n",
            "\u001b[?25hDownloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "Downloading matplotlib-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
            "\u001b[?25hDownloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "Downloading peft-0.4.0-py3-none-any.whl (72 kB)\n",
            "Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Using cached fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "Downloading kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
            "Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Downloading pydantic-2.9.1-py3-none-any.whl (434 kB)\n",
            "Downloading pydantic_core-2.23.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.14.0-py3-none-any.whl size=1400345 sha256=8d72c049b30fef8b1d7207e4cd71e54103d745425e8dd431e4fa5fca6fdc7e13\n",
            "  Stored in directory: /home/fakoor/.cache/pip/wheels/23/96/24/bab20c3b4e2af15e195b339afaec373eca7072cf90620432e5\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: tokenizers, sentencepiece, py-cpuinfo, ninja, hjson, triton, tqdm, pyparsing, pynvml, pydantic-core, pillow, nvidia-nccl-cu12, nvidia-cudnn-cu12, numpy, kiwisolver, fonttools, einops, cycler, annotated-types, scipy, pydantic, pandas, contourpy, transformers, torch, scikit_learn, matplotlib, deepspeed, accelerate, peft\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.0.0\n",
            "    Uninstalling triton-3.0.0:\n",
            "      Successfully uninstalled triton-3.0.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.5\n",
            "    Uninstalling tqdm-4.66.5:\n",
            "      Successfully uninstalled tqdm-4.66.5\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.1.1\n",
            "    Uninstalling numpy-2.1.1:\n",
            "      Successfully uninstalled numpy-2.1.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.1\n",
            "    Uninstalling torch-2.4.1:\n",
            "      Successfully uninstalled torch-2.4.1\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.5.1\n",
            "    Uninstalling scikit-learn-1.5.1:\n",
            "      Successfully uninstalled scikit-learn-1.5.1\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.34.2\n",
            "    Uninstalling accelerate-0.34.2:\n",
            "      Successfully uninstalled accelerate-0.34.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 2.21.0 requires tqdm>=4.66.3, but you have tqdm 4.65.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.28.0 annotated-types-0.7.0 contourpy-1.3.0 cycler-0.12.1 deepspeed-0.14.0 einops-0.7.0 fonttools-4.53.1 hjson-3.1.0 kiwisolver-1.4.7 matplotlib-3.7.0 ninja-1.11.1.1 numpy-1.23.5 nvidia-cudnn-cu12-8.9.2.26 nvidia-nccl-cu12-2.19.3 pandas-1.5.3 peft-0.4.0 pillow-10.4.0 py-cpuinfo-9.0.0 pydantic-2.9.1 pydantic-core-2.23.3 pynvml-11.5.3 pyparsing-3.1.4 scikit_learn-1.2.2 scipy-1.12.0 sentencepiece-0.2.0 tokenizers-0.13.3 torch-2.2.2 tqdm-4.65.0 transformers-4.31.0 triton-2.2.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.2.43-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pandas>=1.3.0 in ./.venv/lib/python3.10/site-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in ./.venv/lib/python3.10/site-packages (from yfinance) (1.23.5)\n",
            "Requirement already satisfied: requests>=2.31 in ./.venv/lib/python3.10/site-packages (from yfinance) (2.32.3)\n",
            "Collecting multitasking>=0.0.7 (from yfinance)\n",
            "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting lxml>=4.9.1 (from yfinance)\n",
            "  Using cached lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in ./.venv/lib/python3.10/site-packages (from yfinance) (4.3.2)\n",
            "Requirement already satisfied: pytz>=2022.5 in ./.venv/lib/python3.10/site-packages (from yfinance) (2024.1)\n",
            "Collecting frozendict>=2.3.4 (from yfinance)\n",
            "  Downloading frozendict-2.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Collecting peewee>=3.16.2 (from yfinance)\n",
            "  Downloading peewee-3.17.6.tar.gz (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting beautifulsoup4>=4.11.1 (from yfinance)\n",
            "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting html5lib>=1.1 (from yfinance)\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4>=4.11.1->yfinance)\n",
            "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: six>=1.9 in ./.venv/lib/python3.10/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Collecting webencodings (from html5lib>=1.1->yfinance)\n",
            "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests>=2.31->yfinance) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.31->yfinance) (2024.8.30)\n",
            "Downloading yfinance-0.2.43-py2.py3-none-any.whl (84 kB)\n",
            "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
            "Downloading frozendict-2.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "Using cached lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
            "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
            "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: peewee\n",
            "  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for peewee: filename=peewee-3.17.6-cp310-cp310-linux_x86_64.whl size=848960 sha256=c460fade5c2d4b83291daefca13df1230ad21bc6273af0d59214fedfafe2482a\n",
            "  Stored in directory: /home/fakoor/.cache/pip/wheels/4b/b9/b0/83d6e258e8f963f5ff111a2cd8c483ca59372a86e6a2535212\n",
            "Successfully built peewee\n",
            "Installing collected packages: webencodings, peewee, multitasking, soupsieve, lxml, html5lib, frozendict, beautifulsoup4, yfinance\n",
            "Successfully installed beautifulsoup4-4.12.3 frozendict-2.4.4 html5lib-1.1 lxml-5.3.0 multitasking-0.0.11 peewee-3.17.6 soupsieve-2.6 webencodings-0.5.1 yfinance-0.2.43\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l102kT0SCAb1",
        "outputId": "93ebfd75-c7e3-4fd5-cd90-cf667d694c8e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Download stock data for a specific ticker, e.g., Apple (AAPL)\n",
        "data = yf.download('AAPL', start='2000-01-01', end='2024-01-01', interval='1d')\n",
        "data.reset_index(inplace=True)\n",
        "\n",
        "# Prepare the data by selecting necessary columns and renaming them\n",
        "data = data[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "data.columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
        "\n",
        "# Save the data to CSV if needed\n",
        "data.to_csv('data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yq6sopLnDGNW"
      },
      "outputs": [],
      "source": [
        "CHECKPOINT_DIR=\"./checkpoints/AAPL\"\n",
        "\n",
        "# Ensure the checkpoint directory exists\n",
        "!mkdir -p $CHECKPOINT_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiYf2-EFE2ES",
        "outputId": "d2ec644c-77f7-4e4f-8d18-4a7533452c68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AAPL_stock_data.csv  \u001b[0m\u001b[01;34mdata\u001b[0m/     \u001b[01;34mmodel_labeling\u001b[0m/  \u001b[01;34mrandom\u001b[0m/    \u001b[01;34mstock_time_llm\u001b[0m/\n",
            "\u001b[01;34mcheckpoints\u001b[0m/         \u001b[01;34mfa_bert\u001b[0m/  \u001b[01;34mpapers\u001b[0m/          README.md  train.ipynb\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GzSJr5AFirw",
        "outputId": "a6a0380e-2e6c-45fb-9e38-9ad09890bc6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2666235/766685218.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
            "/tmp/ipykernel_2666235/766685218.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.rename(columns={'close': 'y'}, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = data\n",
        "df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
        "df.rename(columns={'close': 'y'}, inplace=True)\n",
        "df = df[['date', 'y']]\n",
        "df.to_csv('data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "SGhypmqiFqrO",
        "outputId": "17ac53dc-9b11-4bf3-9bdc-709e08670dbc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000-01-03</td>\n",
              "      <td>0.999442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>0.915179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-01-05</td>\n",
              "      <td>0.928571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-01-06</td>\n",
              "      <td>0.848214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-01-07</td>\n",
              "      <td>0.888393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6032</th>\n",
              "      <td>2023-12-22</td>\n",
              "      <td>193.600006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6033</th>\n",
              "      <td>2023-12-26</td>\n",
              "      <td>193.050003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6034</th>\n",
              "      <td>2023-12-27</td>\n",
              "      <td>193.149994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6035</th>\n",
              "      <td>2023-12-28</td>\n",
              "      <td>193.580002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6036</th>\n",
              "      <td>2023-12-29</td>\n",
              "      <td>192.529999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6037 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           date           y\n",
              "0    2000-01-03    0.999442\n",
              "1    2000-01-04    0.915179\n",
              "2    2000-01-05    0.928571\n",
              "3    2000-01-06    0.848214\n",
              "4    2000-01-07    0.888393\n",
              "...         ...         ...\n",
              "6032 2023-12-22  193.600006\n",
              "6033 2023-12-26  193.050003\n",
              "6034 2023-12-27  193.149994\n",
              "6035 2023-12-28  193.580002\n",
              "6036 2023-12-29  192.529999\n",
              "\n",
              "[6037 rows x 2 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMi-Hn-def4t",
        "outputId": "650f0fc4-7f0b-4a04-9ad2-b31dfda94501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/fakoor/Desktop/chitsaz/emotion_detection/emotions\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/fakoor/Desktop/chitsaz/emotion_detection/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "%cd /home/fakoor/Desktop/chitsaz/emotion_detection/emotions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "!export RDMAV_FORK_SAFE=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['RDMAV_FORK_SAFE'] = '1'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acReWe6pDDE_",
        "outputId": "73ed6643-89ec-48ef-f44f-1a1e85ec6444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------\n",
            "0\n",
            "['2000-01-03T00:00:00.000000000' '2000-01-04T00:00:00.000000000'\n",
            " '2000-01-05T00:00:00.000000000' ... '2020-05-21T00:00:00.000000000'\n",
            " '2020-05-22T00:00:00.000000000' '2020-05-26T00:00:00.000000000']\n",
            "-------------------------------\n",
            "1\n",
            "['2020-02-25T00:00:00.000000000' '2020-02-26T00:00:00.000000000'\n",
            " '2020-02-27T00:00:00.000000000' '2020-02-28T00:00:00.000000000'\n",
            " '2020-03-02T00:00:00.000000000' '2020-03-03T00:00:00.000000000'\n",
            " '2020-03-04T00:00:00.000000000' '2020-03-05T00:00:00.000000000'\n",
            " '2020-03-06T00:00:00.000000000' '2020-03-09T00:00:00.000000000'\n",
            " '2020-03-10T00:00:00.000000000' '2020-03-11T00:00:00.000000000'\n",
            " '2020-03-12T00:00:00.000000000' '2020-03-13T00:00:00.000000000'\n",
            " '2020-03-16T00:00:00.000000000' '2020-03-17T00:00:00.000000000'\n",
            " '2020-03-18T00:00:00.000000000' '2020-03-19T00:00:00.000000000'\n",
            " '2020-03-20T00:00:00.000000000' '2020-03-23T00:00:00.000000000'\n",
            " '2020-03-24T00:00:00.000000000' '2020-03-25T00:00:00.000000000'\n",
            " '2020-03-26T00:00:00.000000000' '2020-03-27T00:00:00.000000000'\n",
            " '2020-03-30T00:00:00.000000000' '2020-03-31T00:00:00.000000000'\n",
            " '2020-04-01T00:00:00.000000000' '2020-04-02T00:00:00.000000000'\n",
            " '2020-04-03T00:00:00.000000000' '2020-04-06T00:00:00.000000000'\n",
            " '2020-04-07T00:00:00.000000000' '2020-04-08T00:00:00.000000000'\n",
            " '2020-04-09T00:00:00.000000000' '2020-04-13T00:00:00.000000000'\n",
            " '2020-04-14T00:00:00.000000000' '2020-04-15T00:00:00.000000000'\n",
            " '2020-04-16T00:00:00.000000000' '2020-04-17T00:00:00.000000000'\n",
            " '2020-04-20T00:00:00.000000000' '2020-04-21T00:00:00.000000000'\n",
            " '2020-04-22T00:00:00.000000000' '2020-04-23T00:00:00.000000000'\n",
            " '2020-04-24T00:00:00.000000000' '2020-04-27T00:00:00.000000000'\n",
            " '2020-04-28T00:00:00.000000000' '2020-04-29T00:00:00.000000000'\n",
            " '2020-04-30T00:00:00.000000000' '2020-05-01T00:00:00.000000000'\n",
            " '2020-05-04T00:00:00.000000000' '2020-05-05T00:00:00.000000000'\n",
            " '2020-05-06T00:00:00.000000000' '2020-05-07T00:00:00.000000000'\n",
            " '2020-05-08T00:00:00.000000000' '2020-05-11T00:00:00.000000000'\n",
            " '2020-05-12T00:00:00.000000000' '2020-05-13T00:00:00.000000000'\n",
            " '2020-05-14T00:00:00.000000000' '2020-05-15T00:00:00.000000000'\n",
            " '2020-05-18T00:00:00.000000000' '2020-05-19T00:00:00.000000000'\n",
            " '2020-05-20T00:00:00.000000000' '2020-05-21T00:00:00.000000000'\n",
            " '2020-05-22T00:00:00.000000000' '2020-05-26T00:00:00.000000000'\n",
            " '2020-05-27T00:00:00.000000000' '2020-05-28T00:00:00.000000000'\n",
            " '2020-05-29T00:00:00.000000000' '2020-06-01T00:00:00.000000000'\n",
            " '2020-06-02T00:00:00.000000000' '2020-06-03T00:00:00.000000000'\n",
            " '2020-06-04T00:00:00.000000000' '2020-06-05T00:00:00.000000000'\n",
            " '2020-06-08T00:00:00.000000000' '2020-06-09T00:00:00.000000000'\n",
            " '2020-06-10T00:00:00.000000000' '2020-06-11T00:00:00.000000000'\n",
            " '2020-06-12T00:00:00.000000000' '2020-06-15T00:00:00.000000000'\n",
            " '2020-06-16T00:00:00.000000000' '2020-06-17T00:00:00.000000000'\n",
            " '2020-06-18T00:00:00.000000000' '2020-06-19T00:00:00.000000000'\n",
            " '2020-06-22T00:00:00.000000000' '2020-06-23T00:00:00.000000000'\n",
            " '2020-06-24T00:00:00.000000000' '2020-06-25T00:00:00.000000000'\n",
            " '2020-06-26T00:00:00.000000000' '2020-06-29T00:00:00.000000000'\n",
            " '2020-06-30T00:00:00.000000000' '2020-07-01T00:00:00.000000000'\n",
            " '2020-07-02T00:00:00.000000000' '2020-07-06T00:00:00.000000000'\n",
            " '2020-07-07T00:00:00.000000000' '2020-07-08T00:00:00.000000000'\n",
            " '2020-07-09T00:00:00.000000000' '2020-07-10T00:00:00.000000000'\n",
            " '2020-07-13T00:00:00.000000000' '2020-07-14T00:00:00.000000000'\n",
            " '2020-07-15T00:00:00.000000000' '2020-07-16T00:00:00.000000000'\n",
            " '2020-07-17T00:00:00.000000000' '2020-07-20T00:00:00.000000000'\n",
            " '2020-07-21T00:00:00.000000000' '2020-07-22T00:00:00.000000000'\n",
            " '2020-07-23T00:00:00.000000000' '2020-07-24T00:00:00.000000000'\n",
            " '2020-07-27T00:00:00.000000000' '2020-07-28T00:00:00.000000000'\n",
            " '2020-07-29T00:00:00.000000000' '2020-07-30T00:00:00.000000000'\n",
            " '2020-07-31T00:00:00.000000000' '2020-08-03T00:00:00.000000000'\n",
            " '2020-08-04T00:00:00.000000000' '2020-08-05T00:00:00.000000000'\n",
            " '2020-08-06T00:00:00.000000000' '2020-08-07T00:00:00.000000000'\n",
            " '2020-08-10T00:00:00.000000000' '2020-08-11T00:00:00.000000000'\n",
            " '2020-08-12T00:00:00.000000000' '2020-08-13T00:00:00.000000000'\n",
            " '2020-08-14T00:00:00.000000000' '2020-08-17T00:00:00.000000000'\n",
            " '2020-08-18T00:00:00.000000000' '2020-08-19T00:00:00.000000000'\n",
            " '2020-08-20T00:00:00.000000000' '2020-08-21T00:00:00.000000000'\n",
            " '2020-08-24T00:00:00.000000000' '2020-08-25T00:00:00.000000000'\n",
            " '2020-08-26T00:00:00.000000000' '2020-08-27T00:00:00.000000000'\n",
            " '2020-08-28T00:00:00.000000000' '2020-08-31T00:00:00.000000000'\n",
            " '2020-09-01T00:00:00.000000000' '2020-09-02T00:00:00.000000000'\n",
            " '2020-09-03T00:00:00.000000000' '2020-09-04T00:00:00.000000000'\n",
            " '2020-09-08T00:00:00.000000000' '2020-09-09T00:00:00.000000000'\n",
            " '2020-09-10T00:00:00.000000000' '2020-09-11T00:00:00.000000000'\n",
            " '2020-09-14T00:00:00.000000000' '2020-09-15T00:00:00.000000000'\n",
            " '2020-09-16T00:00:00.000000000' '2020-09-17T00:00:00.000000000'\n",
            " '2020-09-18T00:00:00.000000000' '2020-09-21T00:00:00.000000000'\n",
            " '2020-09-22T00:00:00.000000000' '2020-09-23T00:00:00.000000000'\n",
            " '2020-09-24T00:00:00.000000000' '2020-09-25T00:00:00.000000000'\n",
            " '2020-09-28T00:00:00.000000000' '2020-09-29T00:00:00.000000000'\n",
            " '2020-09-30T00:00:00.000000000' '2020-10-01T00:00:00.000000000'\n",
            " '2020-10-02T00:00:00.000000000' '2020-10-05T00:00:00.000000000'\n",
            " '2020-10-06T00:00:00.000000000' '2020-10-07T00:00:00.000000000'\n",
            " '2020-10-08T00:00:00.000000000' '2020-10-09T00:00:00.000000000'\n",
            " '2020-10-12T00:00:00.000000000' '2020-10-13T00:00:00.000000000'\n",
            " '2020-10-14T00:00:00.000000000' '2020-10-15T00:00:00.000000000'\n",
            " '2020-10-16T00:00:00.000000000' '2020-10-19T00:00:00.000000000'\n",
            " '2020-10-20T00:00:00.000000000' '2020-10-21T00:00:00.000000000'\n",
            " '2020-10-22T00:00:00.000000000' '2020-10-23T00:00:00.000000000'\n",
            " '2020-10-26T00:00:00.000000000' '2020-10-27T00:00:00.000000000'\n",
            " '2020-10-28T00:00:00.000000000' '2020-10-29T00:00:00.000000000'\n",
            " '2020-10-30T00:00:00.000000000' '2020-11-02T00:00:00.000000000'\n",
            " '2020-11-03T00:00:00.000000000' '2020-11-04T00:00:00.000000000'\n",
            " '2020-11-05T00:00:00.000000000' '2020-11-06T00:00:00.000000000'\n",
            " '2020-11-09T00:00:00.000000000' '2020-11-10T00:00:00.000000000'\n",
            " '2020-11-11T00:00:00.000000000' '2020-11-12T00:00:00.000000000'\n",
            " '2020-11-13T00:00:00.000000000' '2020-11-16T00:00:00.000000000'\n",
            " '2020-11-17T00:00:00.000000000' '2020-11-18T00:00:00.000000000'\n",
            " '2020-11-19T00:00:00.000000000' '2020-11-20T00:00:00.000000000'\n",
            " '2020-11-23T00:00:00.000000000' '2020-11-24T00:00:00.000000000'\n",
            " '2020-11-25T00:00:00.000000000' '2020-11-27T00:00:00.000000000'\n",
            " '2020-11-30T00:00:00.000000000' '2020-12-01T00:00:00.000000000'\n",
            " '2020-12-02T00:00:00.000000000' '2020-12-03T00:00:00.000000000'\n",
            " '2020-12-04T00:00:00.000000000' '2020-12-07T00:00:00.000000000'\n",
            " '2020-12-08T00:00:00.000000000' '2020-12-09T00:00:00.000000000'\n",
            " '2020-12-10T00:00:00.000000000' '2020-12-11T00:00:00.000000000'\n",
            " '2020-12-14T00:00:00.000000000' '2020-12-15T00:00:00.000000000'\n",
            " '2020-12-16T00:00:00.000000000' '2020-12-17T00:00:00.000000000'\n",
            " '2020-12-18T00:00:00.000000000' '2020-12-21T00:00:00.000000000'\n",
            " '2020-12-22T00:00:00.000000000' '2020-12-23T00:00:00.000000000'\n",
            " '2020-12-24T00:00:00.000000000' '2020-12-28T00:00:00.000000000'\n",
            " '2020-12-29T00:00:00.000000000' '2020-12-30T00:00:00.000000000'\n",
            " '2020-12-31T00:00:00.000000000' '2021-01-04T00:00:00.000000000'\n",
            " '2021-01-05T00:00:00.000000000' '2021-01-06T00:00:00.000000000'\n",
            " '2021-01-07T00:00:00.000000000' '2021-01-08T00:00:00.000000000'\n",
            " '2021-01-11T00:00:00.000000000' '2021-01-12T00:00:00.000000000'\n",
            " '2021-01-13T00:00:00.000000000' '2021-01-14T00:00:00.000000000'\n",
            " '2021-01-15T00:00:00.000000000' '2021-01-19T00:00:00.000000000'\n",
            " '2021-01-20T00:00:00.000000000' '2021-01-21T00:00:00.000000000'\n",
            " '2021-01-22T00:00:00.000000000' '2021-01-25T00:00:00.000000000'\n",
            " '2021-01-26T00:00:00.000000000' '2021-01-27T00:00:00.000000000'\n",
            " '2021-01-28T00:00:00.000000000' '2021-01-29T00:00:00.000000000'\n",
            " '2021-02-01T00:00:00.000000000' '2021-02-02T00:00:00.000000000'\n",
            " '2021-02-03T00:00:00.000000000' '2021-02-04T00:00:00.000000000'\n",
            " '2021-02-05T00:00:00.000000000' '2021-02-08T00:00:00.000000000'\n",
            " '2021-02-09T00:00:00.000000000' '2021-02-10T00:00:00.000000000'\n",
            " '2021-02-11T00:00:00.000000000' '2021-02-12T00:00:00.000000000'\n",
            " '2021-02-16T00:00:00.000000000' '2021-02-17T00:00:00.000000000'\n",
            " '2021-02-18T00:00:00.000000000' '2021-02-19T00:00:00.000000000'\n",
            " '2021-02-22T00:00:00.000000000' '2021-02-23T00:00:00.000000000'\n",
            " '2021-02-24T00:00:00.000000000' '2021-02-25T00:00:00.000000000'\n",
            " '2021-02-26T00:00:00.000000000' '2021-03-01T00:00:00.000000000'\n",
            " '2021-03-02T00:00:00.000000000' '2021-03-03T00:00:00.000000000'\n",
            " '2021-03-04T00:00:00.000000000' '2021-03-05T00:00:00.000000000'\n",
            " '2021-03-08T00:00:00.000000000' '2021-03-09T00:00:00.000000000'\n",
            " '2021-03-10T00:00:00.000000000' '2021-03-11T00:00:00.000000000'\n",
            " '2021-03-12T00:00:00.000000000' '2021-03-15T00:00:00.000000000'\n",
            " '2021-03-16T00:00:00.000000000' '2021-03-17T00:00:00.000000000'\n",
            " '2021-03-18T00:00:00.000000000' '2021-03-19T00:00:00.000000000'\n",
            " '2021-03-22T00:00:00.000000000' '2021-03-23T00:00:00.000000000'\n",
            " '2021-03-24T00:00:00.000000000' '2021-03-25T00:00:00.000000000'\n",
            " '2021-03-26T00:00:00.000000000' '2021-03-29T00:00:00.000000000'\n",
            " '2021-03-30T00:00:00.000000000' '2021-03-31T00:00:00.000000000'\n",
            " '2021-04-01T00:00:00.000000000' '2021-04-05T00:00:00.000000000'\n",
            " '2021-04-06T00:00:00.000000000' '2021-04-07T00:00:00.000000000'\n",
            " '2021-04-08T00:00:00.000000000' '2021-04-09T00:00:00.000000000'\n",
            " '2021-04-12T00:00:00.000000000' '2021-04-13T00:00:00.000000000'\n",
            " '2021-04-14T00:00:00.000000000' '2021-04-15T00:00:00.000000000'\n",
            " '2021-04-16T00:00:00.000000000' '2021-04-19T00:00:00.000000000'\n",
            " '2021-04-20T00:00:00.000000000' '2021-04-21T00:00:00.000000000'\n",
            " '2021-04-22T00:00:00.000000000' '2021-04-23T00:00:00.000000000'\n",
            " '2021-04-26T00:00:00.000000000' '2021-04-27T00:00:00.000000000'\n",
            " '2021-04-28T00:00:00.000000000' '2021-04-29T00:00:00.000000000'\n",
            " '2021-04-30T00:00:00.000000000' '2021-05-03T00:00:00.000000000'\n",
            " '2021-05-04T00:00:00.000000000' '2021-05-05T00:00:00.000000000'\n",
            " '2021-05-06T00:00:00.000000000' '2021-05-07T00:00:00.000000000'\n",
            " '2021-05-10T00:00:00.000000000' '2021-05-11T00:00:00.000000000'\n",
            " '2021-05-12T00:00:00.000000000' '2021-05-13T00:00:00.000000000'\n",
            " '2021-05-14T00:00:00.000000000' '2021-05-17T00:00:00.000000000'\n",
            " '2021-05-18T00:00:00.000000000' '2021-05-19T00:00:00.000000000'\n",
            " '2021-05-20T00:00:00.000000000' '2021-05-21T00:00:00.000000000'\n",
            " '2021-05-24T00:00:00.000000000' '2021-05-25T00:00:00.000000000'\n",
            " '2021-05-26T00:00:00.000000000' '2021-05-27T00:00:00.000000000'\n",
            " '2021-05-28T00:00:00.000000000' '2021-06-01T00:00:00.000000000'\n",
            " '2021-06-02T00:00:00.000000000' '2021-06-03T00:00:00.000000000'\n",
            " '2021-06-04T00:00:00.000000000' '2021-06-07T00:00:00.000000000'\n",
            " '2021-06-08T00:00:00.000000000' '2021-06-09T00:00:00.000000000'\n",
            " '2021-06-10T00:00:00.000000000' '2021-06-11T00:00:00.000000000'\n",
            " '2021-06-14T00:00:00.000000000' '2021-06-15T00:00:00.000000000'\n",
            " '2021-06-16T00:00:00.000000000' '2021-06-17T00:00:00.000000000'\n",
            " '2021-06-18T00:00:00.000000000' '2021-06-21T00:00:00.000000000'\n",
            " '2021-06-22T00:00:00.000000000' '2021-06-23T00:00:00.000000000'\n",
            " '2021-06-24T00:00:00.000000000' '2021-06-25T00:00:00.000000000'\n",
            " '2021-06-28T00:00:00.000000000' '2021-06-29T00:00:00.000000000'\n",
            " '2021-06-30T00:00:00.000000000' '2021-07-01T00:00:00.000000000'\n",
            " '2021-07-02T00:00:00.000000000' '2021-07-06T00:00:00.000000000'\n",
            " '2021-07-07T00:00:00.000000000' '2021-07-08T00:00:00.000000000'\n",
            " '2021-07-09T00:00:00.000000000' '2021-07-12T00:00:00.000000000'\n",
            " '2021-07-13T00:00:00.000000000' '2021-07-14T00:00:00.000000000'\n",
            " '2021-07-15T00:00:00.000000000' '2021-07-16T00:00:00.000000000'\n",
            " '2021-07-19T00:00:00.000000000' '2021-07-20T00:00:00.000000000'\n",
            " '2021-07-21T00:00:00.000000000' '2021-07-22T00:00:00.000000000'\n",
            " '2021-07-23T00:00:00.000000000' '2021-07-26T00:00:00.000000000'\n",
            " '2021-07-27T00:00:00.000000000' '2021-07-28T00:00:00.000000000'\n",
            " '2021-07-29T00:00:00.000000000' '2021-07-30T00:00:00.000000000'\n",
            " '2021-08-02T00:00:00.000000000' '2021-08-03T00:00:00.000000000'\n",
            " '2021-08-04T00:00:00.000000000' '2021-08-05T00:00:00.000000000'\n",
            " '2021-08-06T00:00:00.000000000' '2021-08-09T00:00:00.000000000'\n",
            " '2021-08-10T00:00:00.000000000' '2021-08-11T00:00:00.000000000'\n",
            " '2021-08-12T00:00:00.000000000' '2021-08-13T00:00:00.000000000'\n",
            " '2021-08-16T00:00:00.000000000' '2021-08-17T00:00:00.000000000'\n",
            " '2021-08-18T00:00:00.000000000' '2021-08-19T00:00:00.000000000'\n",
            " '2021-08-20T00:00:00.000000000' '2021-08-23T00:00:00.000000000'\n",
            " '2021-08-24T00:00:00.000000000' '2021-08-25T00:00:00.000000000'\n",
            " '2021-08-26T00:00:00.000000000' '2021-08-27T00:00:00.000000000'\n",
            " '2021-08-30T00:00:00.000000000' '2021-08-31T00:00:00.000000000'\n",
            " '2021-09-01T00:00:00.000000000' '2021-09-02T00:00:00.000000000'\n",
            " '2021-09-03T00:00:00.000000000' '2021-09-07T00:00:00.000000000'\n",
            " '2021-09-08T00:00:00.000000000' '2021-09-09T00:00:00.000000000'\n",
            " '2021-09-10T00:00:00.000000000' '2021-09-13T00:00:00.000000000'\n",
            " '2021-09-14T00:00:00.000000000' '2021-09-15T00:00:00.000000000'\n",
            " '2021-09-16T00:00:00.000000000' '2021-09-17T00:00:00.000000000'\n",
            " '2021-09-20T00:00:00.000000000' '2021-09-21T00:00:00.000000000'\n",
            " '2021-09-22T00:00:00.000000000' '2021-09-23T00:00:00.000000000'\n",
            " '2021-09-24T00:00:00.000000000' '2021-09-27T00:00:00.000000000'\n",
            " '2021-09-28T00:00:00.000000000' '2021-09-29T00:00:00.000000000'\n",
            " '2021-09-30T00:00:00.000000000' '2021-10-01T00:00:00.000000000'\n",
            " '2021-10-04T00:00:00.000000000' '2021-10-05T00:00:00.000000000'\n",
            " '2021-10-06T00:00:00.000000000' '2021-10-07T00:00:00.000000000'\n",
            " '2021-10-08T00:00:00.000000000' '2021-10-11T00:00:00.000000000'\n",
            " '2021-10-12T00:00:00.000000000' '2021-10-13T00:00:00.000000000'\n",
            " '2021-10-14T00:00:00.000000000' '2021-10-15T00:00:00.000000000'\n",
            " '2021-10-18T00:00:00.000000000' '2021-10-19T00:00:00.000000000'\n",
            " '2021-10-20T00:00:00.000000000' '2021-10-21T00:00:00.000000000'\n",
            " '2021-10-22T00:00:00.000000000' '2021-10-25T00:00:00.000000000'\n",
            " '2021-10-26T00:00:00.000000000' '2021-10-27T00:00:00.000000000'\n",
            " '2021-10-28T00:00:00.000000000' '2021-10-29T00:00:00.000000000'\n",
            " '2021-11-01T00:00:00.000000000' '2021-11-02T00:00:00.000000000'\n",
            " '2021-11-03T00:00:00.000000000' '2021-11-04T00:00:00.000000000'\n",
            " '2021-11-05T00:00:00.000000000' '2021-11-08T00:00:00.000000000'\n",
            " '2021-11-09T00:00:00.000000000' '2021-11-10T00:00:00.000000000'\n",
            " '2021-11-11T00:00:00.000000000' '2021-11-12T00:00:00.000000000'\n",
            " '2021-11-15T00:00:00.000000000' '2021-11-16T00:00:00.000000000'\n",
            " '2021-11-17T00:00:00.000000000' '2021-11-18T00:00:00.000000000'\n",
            " '2021-11-19T00:00:00.000000000' '2021-11-22T00:00:00.000000000'\n",
            " '2021-11-23T00:00:00.000000000' '2021-11-24T00:00:00.000000000'\n",
            " '2021-11-26T00:00:00.000000000' '2021-11-29T00:00:00.000000000'\n",
            " '2021-11-30T00:00:00.000000000' '2021-12-01T00:00:00.000000000'\n",
            " '2021-12-02T00:00:00.000000000' '2021-12-03T00:00:00.000000000'\n",
            " '2021-12-06T00:00:00.000000000' '2021-12-07T00:00:00.000000000'\n",
            " '2021-12-08T00:00:00.000000000' '2021-12-09T00:00:00.000000000'\n",
            " '2021-12-10T00:00:00.000000000' '2021-12-13T00:00:00.000000000'\n",
            " '2021-12-14T00:00:00.000000000' '2021-12-15T00:00:00.000000000'\n",
            " '2021-12-16T00:00:00.000000000' '2021-12-17T00:00:00.000000000'\n",
            " '2021-12-20T00:00:00.000000000' '2021-12-21T00:00:00.000000000'\n",
            " '2021-12-22T00:00:00.000000000' '2021-12-23T00:00:00.000000000'\n",
            " '2021-12-27T00:00:00.000000000' '2021-12-28T00:00:00.000000000'\n",
            " '2021-12-29T00:00:00.000000000' '2021-12-30T00:00:00.000000000'\n",
            " '2021-12-31T00:00:00.000000000' '2022-01-03T00:00:00.000000000'\n",
            " '2022-01-04T00:00:00.000000000' '2022-01-05T00:00:00.000000000'\n",
            " '2022-01-06T00:00:00.000000000' '2022-01-07T00:00:00.000000000'\n",
            " '2022-01-10T00:00:00.000000000' '2022-01-11T00:00:00.000000000'\n",
            " '2022-01-12T00:00:00.000000000' '2022-01-13T00:00:00.000000000'\n",
            " '2022-01-14T00:00:00.000000000' '2022-01-18T00:00:00.000000000'\n",
            " '2022-01-19T00:00:00.000000000' '2022-01-20T00:00:00.000000000'\n",
            " '2022-01-21T00:00:00.000000000' '2022-01-24T00:00:00.000000000'\n",
            " '2022-01-25T00:00:00.000000000' '2022-01-26T00:00:00.000000000'\n",
            " '2022-01-27T00:00:00.000000000' '2022-01-28T00:00:00.000000000'\n",
            " '2022-01-31T00:00:00.000000000' '2022-02-01T00:00:00.000000000'\n",
            " '2022-02-02T00:00:00.000000000' '2022-02-03T00:00:00.000000000'\n",
            " '2022-02-04T00:00:00.000000000' '2022-02-07T00:00:00.000000000'\n",
            " '2022-02-08T00:00:00.000000000' '2022-02-09T00:00:00.000000000'\n",
            " '2022-02-10T00:00:00.000000000' '2022-02-11T00:00:00.000000000'\n",
            " '2022-02-14T00:00:00.000000000' '2022-02-15T00:00:00.000000000'\n",
            " '2022-02-16T00:00:00.000000000' '2022-02-17T00:00:00.000000000'\n",
            " '2022-02-18T00:00:00.000000000' '2022-02-22T00:00:00.000000000'\n",
            " '2022-02-23T00:00:00.000000000' '2022-02-24T00:00:00.000000000'\n",
            " '2022-02-25T00:00:00.000000000' '2022-02-28T00:00:00.000000000'\n",
            " '2022-03-01T00:00:00.000000000' '2022-03-02T00:00:00.000000000'\n",
            " '2022-03-03T00:00:00.000000000' '2022-03-04T00:00:00.000000000'\n",
            " '2022-03-07T00:00:00.000000000' '2022-03-08T00:00:00.000000000'\n",
            " '2022-03-09T00:00:00.000000000' '2022-03-10T00:00:00.000000000'\n",
            " '2022-03-11T00:00:00.000000000' '2022-03-14T00:00:00.000000000'\n",
            " '2022-03-15T00:00:00.000000000' '2022-03-16T00:00:00.000000000'\n",
            " '2022-03-17T00:00:00.000000000' '2022-03-18T00:00:00.000000000'\n",
            " '2022-03-21T00:00:00.000000000' '2022-03-22T00:00:00.000000000'\n",
            " '2022-03-23T00:00:00.000000000' '2022-03-24T00:00:00.000000000'\n",
            " '2022-03-25T00:00:00.000000000' '2022-03-28T00:00:00.000000000'\n",
            " '2022-03-29T00:00:00.000000000' '2022-03-30T00:00:00.000000000'\n",
            " '2022-03-31T00:00:00.000000000' '2022-04-01T00:00:00.000000000'\n",
            " '2022-04-04T00:00:00.000000000' '2022-04-05T00:00:00.000000000'\n",
            " '2022-04-06T00:00:00.000000000' '2022-04-07T00:00:00.000000000'\n",
            " '2022-04-08T00:00:00.000000000' '2022-04-11T00:00:00.000000000'\n",
            " '2022-04-12T00:00:00.000000000' '2022-04-13T00:00:00.000000000'\n",
            " '2022-04-14T00:00:00.000000000' '2022-04-18T00:00:00.000000000'\n",
            " '2022-04-19T00:00:00.000000000' '2022-04-20T00:00:00.000000000'\n",
            " '2022-04-21T00:00:00.000000000' '2022-04-22T00:00:00.000000000'\n",
            " '2022-04-25T00:00:00.000000000' '2022-04-26T00:00:00.000000000'\n",
            " '2022-04-27T00:00:00.000000000' '2022-04-28T00:00:00.000000000'\n",
            " '2022-04-29T00:00:00.000000000' '2022-05-02T00:00:00.000000000'\n",
            " '2022-05-03T00:00:00.000000000' '2022-05-04T00:00:00.000000000'\n",
            " '2022-05-05T00:00:00.000000000' '2022-05-06T00:00:00.000000000'\n",
            " '2022-05-09T00:00:00.000000000' '2022-05-10T00:00:00.000000000'\n",
            " '2022-05-11T00:00:00.000000000' '2022-05-12T00:00:00.000000000'\n",
            " '2022-05-13T00:00:00.000000000' '2022-05-16T00:00:00.000000000'\n",
            " '2022-05-17T00:00:00.000000000' '2022-05-18T00:00:00.000000000'\n",
            " '2022-05-19T00:00:00.000000000' '2022-05-20T00:00:00.000000000'\n",
            " '2022-05-23T00:00:00.000000000' '2022-05-24T00:00:00.000000000'\n",
            " '2022-05-25T00:00:00.000000000' '2022-05-26T00:00:00.000000000'\n",
            " '2022-05-27T00:00:00.000000000' '2022-05-31T00:00:00.000000000'\n",
            " '2022-06-01T00:00:00.000000000' '2022-06-02T00:00:00.000000000'\n",
            " '2022-06-03T00:00:00.000000000' '2022-06-06T00:00:00.000000000'\n",
            " '2022-06-07T00:00:00.000000000' '2022-06-08T00:00:00.000000000'\n",
            " '2022-06-09T00:00:00.000000000' '2022-06-10T00:00:00.000000000'\n",
            " '2022-06-13T00:00:00.000000000' '2022-06-14T00:00:00.000000000'\n",
            " '2022-06-15T00:00:00.000000000' '2022-06-16T00:00:00.000000000'\n",
            " '2022-06-17T00:00:00.000000000' '2022-06-21T00:00:00.000000000'\n",
            " '2022-06-22T00:00:00.000000000' '2022-06-23T00:00:00.000000000'\n",
            " '2022-06-24T00:00:00.000000000' '2022-06-27T00:00:00.000000000'\n",
            " '2022-06-28T00:00:00.000000000' '2022-06-29T00:00:00.000000000'\n",
            " '2022-06-30T00:00:00.000000000' '2022-07-01T00:00:00.000000000'\n",
            " '2022-07-05T00:00:00.000000000' '2022-07-06T00:00:00.000000000'\n",
            " '2022-07-07T00:00:00.000000000' '2022-07-08T00:00:00.000000000'\n",
            " '2022-07-11T00:00:00.000000000' '2022-07-12T00:00:00.000000000'\n",
            " '2022-07-13T00:00:00.000000000' '2022-07-14T00:00:00.000000000'\n",
            " '2022-07-15T00:00:00.000000000' '2022-07-18T00:00:00.000000000'\n",
            " '2022-07-19T00:00:00.000000000' '2022-07-20T00:00:00.000000000'\n",
            " '2022-07-21T00:00:00.000000000' '2022-07-22T00:00:00.000000000'\n",
            " '2022-07-25T00:00:00.000000000' '2022-07-26T00:00:00.000000000'\n",
            " '2022-07-27T00:00:00.000000000' '2022-07-28T00:00:00.000000000'\n",
            " '2022-07-29T00:00:00.000000000' '2022-08-01T00:00:00.000000000'\n",
            " '2022-08-02T00:00:00.000000000' '2022-08-03T00:00:00.000000000'\n",
            " '2022-08-04T00:00:00.000000000' '2022-08-05T00:00:00.000000000'\n",
            " '2022-08-08T00:00:00.000000000' '2022-08-09T00:00:00.000000000'\n",
            " '2022-08-10T00:00:00.000000000' '2022-08-11T00:00:00.000000000'\n",
            " '2022-08-12T00:00:00.000000000' '2022-08-15T00:00:00.000000000'\n",
            " '2022-08-16T00:00:00.000000000' '2022-08-17T00:00:00.000000000'\n",
            " '2022-08-18T00:00:00.000000000' '2022-08-19T00:00:00.000000000'\n",
            " '2022-08-22T00:00:00.000000000' '2022-08-23T00:00:00.000000000'\n",
            " '2022-08-24T00:00:00.000000000' '2022-08-25T00:00:00.000000000'\n",
            " '2022-08-26T00:00:00.000000000' '2022-08-29T00:00:00.000000000'\n",
            " '2022-08-30T00:00:00.000000000' '2022-08-31T00:00:00.000000000'\n",
            " '2022-09-01T00:00:00.000000000' '2022-09-02T00:00:00.000000000'\n",
            " '2022-09-06T00:00:00.000000000' '2022-09-07T00:00:00.000000000'\n",
            " '2022-09-08T00:00:00.000000000' '2022-09-09T00:00:00.000000000'\n",
            " '2022-09-12T00:00:00.000000000' '2022-09-13T00:00:00.000000000'\n",
            " '2022-09-14T00:00:00.000000000' '2022-09-15T00:00:00.000000000'\n",
            " '2022-09-16T00:00:00.000000000' '2022-09-19T00:00:00.000000000'\n",
            " '2022-09-20T00:00:00.000000000' '2022-09-21T00:00:00.000000000'\n",
            " '2022-09-22T00:00:00.000000000' '2022-09-23T00:00:00.000000000'\n",
            " '2022-09-26T00:00:00.000000000' '2022-09-27T00:00:00.000000000'\n",
            " '2022-09-28T00:00:00.000000000' '2022-09-29T00:00:00.000000000'\n",
            " '2022-09-30T00:00:00.000000000' '2022-10-03T00:00:00.000000000'\n",
            " '2022-10-04T00:00:00.000000000' '2022-10-05T00:00:00.000000000'\n",
            " '2022-10-06T00:00:00.000000000' '2022-10-07T00:00:00.000000000'\n",
            " '2022-10-10T00:00:00.000000000' '2022-10-11T00:00:00.000000000'\n",
            " '2022-10-12T00:00:00.000000000' '2022-10-13T00:00:00.000000000'\n",
            " '2022-10-14T00:00:00.000000000' '2022-10-17T00:00:00.000000000'\n",
            " '2022-10-18T00:00:00.000000000' '2022-10-19T00:00:00.000000000'\n",
            " '2022-10-20T00:00:00.000000000' '2022-10-21T00:00:00.000000000'\n",
            " '2022-10-24T00:00:00.000000000' '2022-10-25T00:00:00.000000000'\n",
            " '2022-10-26T00:00:00.000000000' '2022-10-27T00:00:00.000000000'\n",
            " '2022-10-28T00:00:00.000000000' '2022-10-31T00:00:00.000000000'\n",
            " '2022-11-01T00:00:00.000000000' '2022-11-02T00:00:00.000000000'\n",
            " '2022-11-03T00:00:00.000000000' '2022-11-04T00:00:00.000000000'\n",
            " '2022-11-07T00:00:00.000000000' '2022-11-08T00:00:00.000000000'\n",
            " '2022-11-09T00:00:00.000000000' '2022-11-10T00:00:00.000000000'\n",
            " '2022-11-11T00:00:00.000000000' '2022-11-14T00:00:00.000000000'\n",
            " '2022-11-15T00:00:00.000000000' '2022-11-16T00:00:00.000000000'\n",
            " '2022-11-17T00:00:00.000000000' '2022-11-18T00:00:00.000000000'\n",
            " '2022-11-21T00:00:00.000000000' '2022-11-22T00:00:00.000000000'\n",
            " '2022-11-23T00:00:00.000000000' '2022-11-25T00:00:00.000000000'\n",
            " '2022-11-28T00:00:00.000000000' '2022-11-29T00:00:00.000000000'\n",
            " '2022-11-30T00:00:00.000000000' '2022-12-01T00:00:00.000000000'\n",
            " '2022-12-02T00:00:00.000000000' '2022-12-05T00:00:00.000000000'\n",
            " '2022-12-06T00:00:00.000000000' '2022-12-07T00:00:00.000000000'\n",
            " '2022-12-08T00:00:00.000000000' '2022-12-09T00:00:00.000000000'\n",
            " '2022-12-12T00:00:00.000000000' '2022-12-13T00:00:00.000000000'\n",
            " '2022-12-14T00:00:00.000000000' '2022-12-15T00:00:00.000000000'\n",
            " '2022-12-16T00:00:00.000000000' '2022-12-19T00:00:00.000000000'\n",
            " '2022-12-20T00:00:00.000000000' '2022-12-21T00:00:00.000000000'\n",
            " '2022-12-22T00:00:00.000000000' '2022-12-23T00:00:00.000000000'\n",
            " '2022-12-27T00:00:00.000000000' '2022-12-28T00:00:00.000000000'\n",
            " '2022-12-29T00:00:00.000000000' '2022-12-30T00:00:00.000000000'\n",
            " '2023-01-03T00:00:00.000000000' '2023-01-04T00:00:00.000000000'\n",
            " '2023-01-05T00:00:00.000000000' '2023-01-06T00:00:00.000000000'\n",
            " '2023-01-09T00:00:00.000000000' '2023-01-10T00:00:00.000000000'\n",
            " '2023-01-11T00:00:00.000000000' '2023-01-12T00:00:00.000000000'\n",
            " '2023-01-13T00:00:00.000000000' '2023-01-17T00:00:00.000000000'\n",
            " '2023-01-18T00:00:00.000000000' '2023-01-19T00:00:00.000000000'\n",
            " '2023-01-20T00:00:00.000000000' '2023-01-23T00:00:00.000000000'\n",
            " '2023-01-24T00:00:00.000000000' '2023-01-25T00:00:00.000000000'\n",
            " '2023-01-26T00:00:00.000000000' '2023-01-27T00:00:00.000000000'\n",
            " '2023-01-30T00:00:00.000000000' '2023-01-31T00:00:00.000000000'\n",
            " '2023-02-01T00:00:00.000000000' '2023-02-02T00:00:00.000000000'\n",
            " '2023-02-03T00:00:00.000000000' '2023-02-06T00:00:00.000000000'\n",
            " '2023-02-07T00:00:00.000000000' '2023-02-08T00:00:00.000000000'\n",
            " '2023-02-09T00:00:00.000000000' '2023-02-10T00:00:00.000000000'\n",
            " '2023-02-13T00:00:00.000000000' '2023-02-14T00:00:00.000000000'\n",
            " '2023-02-15T00:00:00.000000000' '2023-02-16T00:00:00.000000000'\n",
            " '2023-02-17T00:00:00.000000000' '2023-02-21T00:00:00.000000000'\n",
            " '2023-02-22T00:00:00.000000000' '2023-02-23T00:00:00.000000000'\n",
            " '2023-02-24T00:00:00.000000000' '2023-02-27T00:00:00.000000000'\n",
            " '2023-02-28T00:00:00.000000000' '2023-03-01T00:00:00.000000000'\n",
            " '2023-03-02T00:00:00.000000000' '2023-03-03T00:00:00.000000000'\n",
            " '2023-03-06T00:00:00.000000000' '2023-03-07T00:00:00.000000000'\n",
            " '2023-03-08T00:00:00.000000000' '2023-03-09T00:00:00.000000000'\n",
            " '2023-03-10T00:00:00.000000000' '2023-03-13T00:00:00.000000000'\n",
            " '2023-03-14T00:00:00.000000000' '2023-03-15T00:00:00.000000000'\n",
            " '2023-03-16T00:00:00.000000000' '2023-03-17T00:00:00.000000000'\n",
            " '2023-03-20T00:00:00.000000000' '2023-03-21T00:00:00.000000000'\n",
            " '2023-03-22T00:00:00.000000000' '2023-03-23T00:00:00.000000000'\n",
            " '2023-03-24T00:00:00.000000000' '2023-03-27T00:00:00.000000000'\n",
            " '2023-03-28T00:00:00.000000000' '2023-03-29T00:00:00.000000000'\n",
            " '2023-03-30T00:00:00.000000000' '2023-03-31T00:00:00.000000000'\n",
            " '2023-04-03T00:00:00.000000000' '2023-04-04T00:00:00.000000000']\n",
            "-------------------------------\n",
            "2\n",
            "['2023-01-03T00:00:00.000000000' '2023-01-04T00:00:00.000000000'\n",
            " '2023-01-05T00:00:00.000000000' '2023-01-06T00:00:00.000000000'\n",
            " '2023-01-09T00:00:00.000000000' '2023-01-10T00:00:00.000000000'\n",
            " '2023-01-11T00:00:00.000000000' '2023-01-12T00:00:00.000000000'\n",
            " '2023-01-13T00:00:00.000000000' '2023-01-17T00:00:00.000000000'\n",
            " '2023-01-18T00:00:00.000000000' '2023-01-19T00:00:00.000000000'\n",
            " '2023-01-20T00:00:00.000000000' '2023-01-23T00:00:00.000000000'\n",
            " '2023-01-24T00:00:00.000000000' '2023-01-25T00:00:00.000000000'\n",
            " '2023-01-26T00:00:00.000000000' '2023-01-27T00:00:00.000000000'\n",
            " '2023-01-30T00:00:00.000000000' '2023-01-31T00:00:00.000000000'\n",
            " '2023-02-01T00:00:00.000000000' '2023-02-02T00:00:00.000000000'\n",
            " '2023-02-03T00:00:00.000000000' '2023-02-06T00:00:00.000000000'\n",
            " '2023-02-07T00:00:00.000000000' '2023-02-08T00:00:00.000000000'\n",
            " '2023-02-09T00:00:00.000000000' '2023-02-10T00:00:00.000000000'\n",
            " '2023-02-13T00:00:00.000000000' '2023-02-14T00:00:00.000000000'\n",
            " '2023-02-15T00:00:00.000000000' '2023-02-16T00:00:00.000000000'\n",
            " '2023-02-17T00:00:00.000000000' '2023-02-21T00:00:00.000000000'\n",
            " '2023-02-22T00:00:00.000000000' '2023-02-23T00:00:00.000000000'\n",
            " '2023-02-24T00:00:00.000000000' '2023-02-27T00:00:00.000000000'\n",
            " '2023-02-28T00:00:00.000000000' '2023-03-01T00:00:00.000000000'\n",
            " '2023-03-02T00:00:00.000000000' '2023-03-03T00:00:00.000000000'\n",
            " '2023-03-06T00:00:00.000000000' '2023-03-07T00:00:00.000000000'\n",
            " '2023-03-08T00:00:00.000000000' '2023-03-09T00:00:00.000000000'\n",
            " '2023-03-10T00:00:00.000000000' '2023-03-13T00:00:00.000000000'\n",
            " '2023-03-14T00:00:00.000000000' '2023-03-15T00:00:00.000000000'\n",
            " '2023-03-16T00:00:00.000000000' '2023-03-17T00:00:00.000000000'\n",
            " '2023-03-20T00:00:00.000000000' '2023-03-21T00:00:00.000000000'\n",
            " '2023-03-22T00:00:00.000000000' '2023-03-23T00:00:00.000000000'\n",
            " '2023-03-24T00:00:00.000000000' '2023-03-27T00:00:00.000000000'\n",
            " '2023-03-28T00:00:00.000000000' '2023-03-29T00:00:00.000000000'\n",
            " '2023-03-30T00:00:00.000000000' '2023-03-31T00:00:00.000000000'\n",
            " '2023-04-03T00:00:00.000000000' '2023-04-04T00:00:00.000000000'\n",
            " '2023-04-05T00:00:00.000000000' '2023-04-06T00:00:00.000000000'\n",
            " '2023-04-10T00:00:00.000000000' '2023-04-11T00:00:00.000000000'\n",
            " '2023-04-12T00:00:00.000000000' '2023-04-13T00:00:00.000000000'\n",
            " '2023-04-14T00:00:00.000000000' '2023-04-17T00:00:00.000000000'\n",
            " '2023-04-18T00:00:00.000000000' '2023-04-19T00:00:00.000000000'\n",
            " '2023-04-20T00:00:00.000000000' '2023-04-21T00:00:00.000000000'\n",
            " '2023-04-24T00:00:00.000000000' '2023-04-25T00:00:00.000000000'\n",
            " '2023-04-26T00:00:00.000000000' '2023-04-27T00:00:00.000000000'\n",
            " '2023-04-28T00:00:00.000000000' '2023-05-01T00:00:00.000000000'\n",
            " '2023-05-02T00:00:00.000000000' '2023-05-03T00:00:00.000000000'\n",
            " '2023-05-04T00:00:00.000000000' '2023-05-05T00:00:00.000000000'\n",
            " '2023-05-08T00:00:00.000000000' '2023-05-09T00:00:00.000000000'\n",
            " '2023-05-10T00:00:00.000000000' '2023-05-11T00:00:00.000000000'\n",
            " '2023-05-12T00:00:00.000000000' '2023-05-15T00:00:00.000000000'\n",
            " '2023-05-16T00:00:00.000000000' '2023-05-17T00:00:00.000000000'\n",
            " '2023-05-18T00:00:00.000000000' '2023-05-19T00:00:00.000000000'\n",
            " '2023-05-22T00:00:00.000000000' '2023-05-23T00:00:00.000000000'\n",
            " '2023-05-24T00:00:00.000000000' '2023-05-25T00:00:00.000000000'\n",
            " '2023-05-26T00:00:00.000000000' '2023-05-30T00:00:00.000000000'\n",
            " '2023-05-31T00:00:00.000000000' '2023-06-01T00:00:00.000000000'\n",
            " '2023-06-02T00:00:00.000000000' '2023-06-05T00:00:00.000000000'\n",
            " '2023-06-06T00:00:00.000000000' '2023-06-07T00:00:00.000000000'\n",
            " '2023-06-08T00:00:00.000000000' '2023-06-09T00:00:00.000000000'\n",
            " '2023-06-12T00:00:00.000000000' '2023-06-13T00:00:00.000000000'\n",
            " '2023-06-14T00:00:00.000000000' '2023-06-15T00:00:00.000000000'\n",
            " '2023-06-16T00:00:00.000000000' '2023-06-20T00:00:00.000000000'\n",
            " '2023-06-21T00:00:00.000000000' '2023-06-22T00:00:00.000000000'\n",
            " '2023-06-23T00:00:00.000000000' '2023-06-26T00:00:00.000000000'\n",
            " '2023-06-27T00:00:00.000000000' '2023-06-28T00:00:00.000000000'\n",
            " '2023-06-29T00:00:00.000000000' '2023-06-30T00:00:00.000000000'\n",
            " '2023-07-03T00:00:00.000000000' '2023-07-05T00:00:00.000000000'\n",
            " '2023-07-06T00:00:00.000000000' '2023-07-07T00:00:00.000000000'\n",
            " '2023-07-10T00:00:00.000000000' '2023-07-11T00:00:00.000000000'\n",
            " '2023-07-12T00:00:00.000000000' '2023-07-13T00:00:00.000000000'\n",
            " '2023-07-14T00:00:00.000000000' '2023-07-17T00:00:00.000000000'\n",
            " '2023-07-18T00:00:00.000000000' '2023-07-19T00:00:00.000000000'\n",
            " '2023-07-20T00:00:00.000000000' '2023-07-21T00:00:00.000000000'\n",
            " '2023-07-24T00:00:00.000000000' '2023-07-25T00:00:00.000000000'\n",
            " '2023-07-26T00:00:00.000000000' '2023-07-27T00:00:00.000000000'\n",
            " '2023-07-28T00:00:00.000000000' '2023-07-31T00:00:00.000000000'\n",
            " '2023-08-01T00:00:00.000000000' '2023-08-02T00:00:00.000000000'\n",
            " '2023-08-03T00:00:00.000000000' '2023-08-04T00:00:00.000000000'\n",
            " '2023-08-07T00:00:00.000000000' '2023-08-08T00:00:00.000000000'\n",
            " '2023-08-09T00:00:00.000000000' '2023-08-10T00:00:00.000000000'\n",
            " '2023-08-11T00:00:00.000000000' '2023-08-14T00:00:00.000000000'\n",
            " '2023-08-15T00:00:00.000000000' '2023-08-16T00:00:00.000000000'\n",
            " '2023-08-17T00:00:00.000000000' '2023-08-18T00:00:00.000000000'\n",
            " '2023-08-21T00:00:00.000000000' '2023-08-22T00:00:00.000000000'\n",
            " '2023-08-23T00:00:00.000000000' '2023-08-24T00:00:00.000000000'\n",
            " '2023-08-25T00:00:00.000000000' '2023-08-28T00:00:00.000000000'\n",
            " '2023-08-29T00:00:00.000000000' '2023-08-30T00:00:00.000000000'\n",
            " '2023-08-31T00:00:00.000000000' '2023-09-01T00:00:00.000000000'\n",
            " '2023-09-05T00:00:00.000000000' '2023-09-06T00:00:00.000000000'\n",
            " '2023-09-07T00:00:00.000000000' '2023-09-08T00:00:00.000000000'\n",
            " '2023-09-11T00:00:00.000000000' '2023-09-12T00:00:00.000000000'\n",
            " '2023-09-13T00:00:00.000000000' '2023-09-14T00:00:00.000000000'\n",
            " '2023-09-15T00:00:00.000000000' '2023-09-18T00:00:00.000000000'\n",
            " '2023-09-19T00:00:00.000000000' '2023-09-20T00:00:00.000000000'\n",
            " '2023-09-21T00:00:00.000000000' '2023-09-22T00:00:00.000000000'\n",
            " '2023-09-25T00:00:00.000000000' '2023-09-26T00:00:00.000000000'\n",
            " '2023-09-27T00:00:00.000000000' '2023-09-28T00:00:00.000000000'\n",
            " '2023-09-29T00:00:00.000000000' '2023-10-02T00:00:00.000000000'\n",
            " '2023-10-03T00:00:00.000000000' '2023-10-04T00:00:00.000000000'\n",
            " '2023-10-05T00:00:00.000000000' '2023-10-06T00:00:00.000000000'\n",
            " '2023-10-09T00:00:00.000000000' '2023-10-10T00:00:00.000000000'\n",
            " '2023-10-11T00:00:00.000000000' '2023-10-12T00:00:00.000000000'\n",
            " '2023-10-13T00:00:00.000000000' '2023-10-16T00:00:00.000000000'\n",
            " '2023-10-17T00:00:00.000000000' '2023-10-18T00:00:00.000000000'\n",
            " '2023-10-19T00:00:00.000000000' '2023-10-20T00:00:00.000000000'\n",
            " '2023-10-23T00:00:00.000000000' '2023-10-24T00:00:00.000000000'\n",
            " '2023-10-25T00:00:00.000000000' '2023-10-26T00:00:00.000000000'\n",
            " '2023-10-27T00:00:00.000000000' '2023-10-30T00:00:00.000000000'\n",
            " '2023-10-31T00:00:00.000000000' '2023-11-01T00:00:00.000000000'\n",
            " '2023-11-02T00:00:00.000000000' '2023-11-03T00:00:00.000000000'\n",
            " '2023-11-06T00:00:00.000000000' '2023-11-07T00:00:00.000000000'\n",
            " '2023-11-08T00:00:00.000000000' '2023-11-09T00:00:00.000000000'\n",
            " '2023-11-10T00:00:00.000000000' '2023-11-13T00:00:00.000000000'\n",
            " '2023-11-14T00:00:00.000000000' '2023-11-15T00:00:00.000000000'\n",
            " '2023-11-16T00:00:00.000000000' '2023-11-17T00:00:00.000000000'\n",
            " '2023-11-20T00:00:00.000000000' '2023-11-21T00:00:00.000000000'\n",
            " '2023-11-22T00:00:00.000000000' '2023-11-24T00:00:00.000000000'\n",
            " '2023-11-27T00:00:00.000000000' '2023-11-28T00:00:00.000000000'\n",
            " '2023-11-29T00:00:00.000000000' '2023-11-30T00:00:00.000000000'\n",
            " '2023-12-01T00:00:00.000000000' '2023-12-04T00:00:00.000000000'\n",
            " '2023-12-05T00:00:00.000000000' '2023-12-06T00:00:00.000000000'\n",
            " '2023-12-07T00:00:00.000000000' '2023-12-08T00:00:00.000000000'\n",
            " '2023-12-11T00:00:00.000000000' '2023-12-12T00:00:00.000000000'\n",
            " '2023-12-13T00:00:00.000000000' '2023-12-14T00:00:00.000000000'\n",
            " '2023-12-15T00:00:00.000000000' '2023-12-18T00:00:00.000000000'\n",
            " '2023-12-19T00:00:00.000000000' '2023-12-20T00:00:00.000000000'\n",
            " '2023-12-21T00:00:00.000000000' '2023-12-22T00:00:00.000000000'\n",
            " '2023-12-26T00:00:00.000000000' '2023-12-27T00:00:00.000000000'\n",
            " '2023-12-28T00:00:00.000000000' '2023-12-29T00:00:00.000000000']\n",
            "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:00<00:00,  2.74it/s]\n",
            "[2024-09-10 10:18:57,082] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-09-10 10:18:57,287] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
            "[2024-09-10 10:18:57,287] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2024-09-10 10:18:57,287] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
            "[2024-09-10 10:18:57,537] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=192.168.59.30, master_port=29500\n",
            "[2024-09-10 10:18:57,537] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "[2024-09-10 10:19:00,062] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "[2024-09-10 10:19:00,063] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
            "[2024-09-10 10:19:00,063] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
            "[2024-09-10 10:19:00,064] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
            "[2024-09-10 10:19:00,064] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
            "[2024-09-10 10:19:00,065] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
            "[2024-09-10 10:19:00,065] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
            "[2024-09-10 10:19:00,065] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
            "[2024-09-10 10:19:00,065] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
            "[2024-09-10 10:19:00,065] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
            "[2024-09-10 10:19:00,386] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
            "[2024-09-10 10:19:00,386] [INFO] [utils.py:801:see_memory_usage] MA 2.71 GB         Max_MA 2.78 GB         CA 2.78 GB         Max_CA 3 GB \n",
            "[2024-09-10 10:19:00,387] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 33.82 GB, percent = 53.9%\n",
            "[2024-09-10 10:19:00,549] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
            "[2024-09-10 10:19:00,549] [INFO] [utils.py:801:see_memory_usage] MA 2.71 GB         Max_MA 2.84 GB         CA 2.91 GB         Max_CA 3 GB \n",
            "[2024-09-10 10:19:00,550] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 33.82 GB, percent = 53.9%\n",
            "[2024-09-10 10:19:00,550] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
            "[2024-09-10 10:19:00,711] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2024-09-10 10:19:00,712] [INFO] [utils.py:801:see_memory_usage] MA 2.71 GB         Max_MA 2.71 GB         CA 2.91 GB         Max_CA 3 GB \n",
            "[2024-09-10 10:19:00,712] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 33.88 GB, percent = 54.0%\n",
            "[2024-09-10 10:19:00,713] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
            "[2024-09-10 10:19:00,713] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
            "[2024-09-10 10:19:00,713] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
            "[2024-09-10 10:19:00,713] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[4.000000000000002e-06], mom=[(0.95, 0.999)]\n",
            "[2024-09-10 10:19:00,713] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
            "[2024-09-10 10:19:00,714] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2024-09-10 10:19:00,714] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2024-09-10 10:19:00,714] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
            "[2024-09-10 10:19:00,714] [INFO] [config.py:1000:print]   amp_params ................... False\n",
            "[2024-09-10 10:19:00,714] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2024-09-10 10:19:00,714] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
            "[2024-09-10 10:19:00,714] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
            "[2024-09-10 10:19:00,714] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2024-09-10 10:19:00,714] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
            "[2024-09-10 10:19:00,714] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
            "[2024-09-10 10:19:00,714] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7e2bf81e2800>\n",
            "[2024-09-10 10:19:00,714] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
            "[2024-09-10 10:19:00,714] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
            "[2024-09-10 10:19:00,714] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2024-09-10 10:19:00,714] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   dump_state ................... False\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"recompute_fwd_factor\": 0.0, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
            "[2024-09-10 10:19:00,715] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   pld_params ................... False\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   train_batch_size ............. 16\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  16\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   world_size ................... 1\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
            "[2024-09-10 10:19:00,716] [INFO] [config.py:986:print_user_config]   json = {\n",
            "    \"bf16\": {\n",
            "        \"enabled\": true, \n",
            "        \"auto_cast\": true\n",
            "    }, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 2, \n",
            "        \"allgather_partitions\": true, \n",
            "        \"allgather_bucket_size\": 2.000000e+08, \n",
            "        \"overlap_comm\": true, \n",
            "        \"reduce_scatter\": true, \n",
            "        \"reduce_bucket_size\": 2.000000e+08, \n",
            "        \"contiguous_gradients\": true, \n",
            "        \"sub_group_size\": 1.000000e+09\n",
            "    }, \n",
            "    \"gradient_accumulation_steps\": 1, \n",
            "    \"train_batch_size\": 16, \n",
            "    \"train_micro_batch_size_per_gpu\": 16, \n",
            "    \"steps_per_print\": inf, \n",
            "    \"wall_clock_breakdown\": false, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": false\n",
            "    }, \n",
            "    \"zero_allow_untested_optimizer\": true\n",
            "}\n",
            "99it [00:45,  2.17it/s]\titers: 100, epoch: 1 | loss: 0.0055006\n",
            "\tspeed: 0.5038s/iter; left time: 1542.2205s\n",
            "199it [01:29,  2.32it/s]\titers: 200, epoch: 1 | loss: 0.0921604\n",
            "\tspeed: 0.4331s/iter; left time: 1282.4964s\n",
            "299it [02:12,  2.33it/s]\titers: 300, epoch: 1 | loss: 0.0073914\n",
            "\tspeed: 0.4296s/iter; left time: 1229.0601s\n",
            "316it [02:19,  2.26it/s]\n",
            "Epoch: 1 cost time: 139.61657094955444\n",
            "45it [00:09,  4.69it/s]\n",
            "11it [00:02,  4.12it/s]\n",
            "Epoch: 1 | Train Loss: 0.0151778 Vali Loss: 0.3724715 Test Loss: 0.3364630 MAE Loss: 0.5500664\n",
            "lr = 0.0000040000\n",
            "Updating learning rate to 4.000000000000002e-06\n",
            "99it [00:42,  2.32it/s]\titers: 100, epoch: 2 | loss: 0.0208565\n",
            "\tspeed: 0.6803s/iter; left time: 1867.4307s\n",
            "199it [01:26,  2.24it/s]\titers: 200, epoch: 2 | loss: 0.0062555\n",
            "\tspeed: 0.4368s/iter; left time: 1155.2443s\n",
            "299it [02:10,  2.32it/s]\titers: 300, epoch: 2 | loss: 0.0140879\n",
            "\tspeed: 0.4353s/iter; left time: 1107.8365s\n",
            "316it [02:17,  2.30it/s]\n",
            "Epoch: 2 cost time: 137.43162727355957\n",
            "45it [00:09,  4.66it/s]\n",
            "11it [00:02,  4.04it/s]\n",
            "Epoch: 2 | Train Loss: 0.0115930 Vali Loss: 0.1489874 Test Loss: 0.0982393 MAE Loss: 0.2697953\n",
            "Updating learning rate to 2.000000000000001e-06\n",
            "99it [00:42,  2.34it/s]\titers: 100, epoch: 3 | loss: 0.0017216\n",
            "\tspeed: 0.7147s/iter; left time: 1735.9954s\n",
            "199it [01:25,  2.33it/s]\titers: 200, epoch: 3 | loss: 0.0014111\n",
            "\tspeed: 0.4293s/iter; left time: 999.8169s\n",
            "299it [02:09,  2.19it/s]\titers: 300, epoch: 3 | loss: 0.0141256\n",
            "\tspeed: 0.4399s/iter; left time: 980.5241s\n",
            "316it [02:17,  2.30it/s]\n",
            "Epoch: 3 cost time: 137.41372156143188\n",
            "45it [00:09,  4.70it/s]\n",
            "11it [00:02,  4.16it/s]\n",
            "Epoch: 3 | Train Loss: 0.0043645 Vali Loss: 0.0947136 Test Loss: 0.0579151 MAE Loss: 0.1981342\n",
            "Updating learning rate to 1.0000000000000006e-06\n",
            "99it [00:42,  2.31it/s]\titers: 100, epoch: 4 | loss: 0.0014014\n",
            "\tspeed: 0.7138s/iter; left time: 1508.3104s\n",
            "199it [01:25,  2.30it/s]\titers: 200, epoch: 4 | loss: 0.0011385\n",
            "\tspeed: 0.4298s/iter; left time: 865.2331s\n",
            "299it [02:08,  2.33it/s]\titers: 300, epoch: 4 | loss: 0.0118719\n",
            "\tspeed: 0.4289s/iter; left time: 820.4591s\n",
            "316it [02:16,  2.32it/s]\n",
            "Epoch: 4 cost time: 136.09631180763245\n",
            "45it [00:09,  4.69it/s]\n",
            "11it [00:02,  4.24it/s]\n",
            "Epoch: 4 | Train Loss: 0.0039500 Vali Loss: 0.0792342 Test Loss: 0.0510514 MAE Loss: 0.1871631\n",
            "Updating learning rate to 5.000000000000003e-07\n",
            "99it [00:43,  2.34it/s]\titers: 100, epoch: 5 | loss: 0.0020637\n",
            "\tspeed: 0.7158s/iter; left time: 1286.2780s\n",
            "199it [01:26,  2.33it/s]\titers: 200, epoch: 5 | loss: 0.0009930\n",
            "\tspeed: 0.4297s/iter; left time: 729.1569s\n",
            "299it [02:09,  2.33it/s]\titers: 300, epoch: 5 | loss: 0.0007632\n",
            "\tspeed: 0.4297s/iter; left time: 686.2175s\n",
            "316it [02:16,  2.31it/s]\n",
            "Epoch: 5 cost time: 136.67933440208435\n",
            "45it [00:09,  4.72it/s]\n",
            "11it [00:02,  4.20it/s]\n",
            "Epoch: 5 | Train Loss: 0.0035735 Vali Loss: 0.0759282 Test Loss: 0.0465493 MAE Loss: 0.1759684\n",
            "Updating learning rate to 2.5000000000000015e-07\n",
            "99it [00:43,  2.22it/s]\titers: 100, epoch: 6 | loss: 0.0017697\n",
            "\tspeed: 0.7186s/iter; left time: 1064.1745s\n",
            "199it [01:27,  2.32it/s]\titers: 200, epoch: 6 | loss: 0.0049493\n",
            "\tspeed: 0.4337s/iter; left time: 598.9481s\n",
            "299it [02:10,  2.34it/s]\titers: 300, epoch: 6 | loss: 0.0009635\n",
            "\tspeed: 0.4296s/iter; left time: 550.3051s\n",
            "316it [02:17,  2.30it/s]\n",
            "Epoch: 6 cost time: 137.4811806678772\n",
            "45it [00:09,  4.69it/s]\n",
            "11it [00:02,  4.19it/s]\n",
            "Epoch: 6 | Train Loss: 0.0031200 Vali Loss: 0.0734364 Test Loss: 0.0451667 MAE Loss: 0.1732266\n",
            "Updating learning rate to 1.2500000000000007e-07\n",
            "99it [00:42,  2.33it/s]\titers: 100, epoch: 7 | loss: 0.0002889\n",
            "\tspeed: 0.6956s/iter; left time: 810.4239s\n",
            "199it [01:26,  2.21it/s]\titers: 200, epoch: 7 | loss: 0.0008157\n",
            "\tspeed: 0.4385s/iter; left time: 466.9710s\n",
            "299it [02:10,  2.33it/s]\titers: 300, epoch: 7 | loss: 0.0018391\n",
            "\tspeed: 0.4343s/iter; left time: 419.0729s\n",
            "316it [02:17,  2.30it/s]\n",
            "Epoch: 7 cost time: 137.50458359718323\n",
            "45it [00:09,  4.70it/s]\n",
            "11it [00:02,  4.21it/s]\n",
            "Epoch: 7 | Train Loss: 0.0031362 Vali Loss: 0.0720997 Test Loss: 0.0441752 MAE Loss: 0.1710505\n",
            "Updating learning rate to 6.250000000000004e-08\n",
            "99it [00:42,  2.33it/s]\titers: 100, epoch: 8 | loss: 0.0033488\n",
            "\tspeed: 0.7081s/iter; left time: 601.1942s\n",
            "199it [01:25,  2.33it/s]\titers: 200, epoch: 8 | loss: 0.0001694\n",
            "\tspeed: 0.4296s/iter; left time: 321.7688s\n",
            "299it [02:09,  2.25it/s]\titers: 300, epoch: 8 | loss: 0.0010887\n",
            "\tspeed: 0.4403s/iter; left time: 285.7314s\n",
            "316it [02:17,  2.30it/s]\n",
            "Epoch: 8 cost time: 137.53639316558838\n",
            "45it [00:09,  4.65it/s]\n",
            "11it [00:02,  4.14it/s]\n",
            "Epoch: 8 | Train Loss: 0.0034843 Vali Loss: 0.0716662 Test Loss: 0.0439752 MAE Loss: 0.1711248\n",
            "Updating learning rate to 3.125000000000002e-08\n",
            "99it [00:42,  2.35it/s]\titers: 100, epoch: 9 | loss: 0.0005638\n",
            "\tspeed: 0.7193s/iter; left time: 383.3903s\n",
            "199it [01:25,  2.34it/s]\titers: 200, epoch: 9 | loss: 0.0014706\n",
            "\tspeed: 0.4297s/iter; left time: 186.0764s\n",
            "299it [02:08,  2.32it/s]\titers: 300, epoch: 9 | loss: 0.0007691\n",
            "\tspeed: 0.4301s/iter; left time: 143.2094s\n",
            "316it [02:16,  2.32it/s]\n",
            "Epoch: 9 cost time: 136.28022933006287\n",
            "45it [00:09,  4.67it/s]\n",
            "11it [00:02,  4.12it/s]\n",
            "Epoch: 9 | Train Loss: 0.0032334 Vali Loss: 0.0708365 Test Loss: 0.0436928 MAE Loss: 0.1705508\n",
            "Updating learning rate to 1.562500000000001e-08\n",
            "99it [00:43,  2.33it/s]\titers: 100, epoch: 10 | loss: 0.0052249\n",
            "\tspeed: 0.7186s/iter; left time: 155.9417s\n",
            "199it [01:26,  2.32it/s]\titers: 200, epoch: 10 | loss: 0.0010058\n",
            "\tspeed: 0.4292s/iter; left time: 50.2216s\n",
            "299it [02:09,  2.32it/s]\titers: 300, epoch: 10 | loss: 0.0036724\n",
            "\tspeed: 0.4293s/iter; left time: 7.2989s\n",
            "316it [02:16,  2.31it/s]\n",
            "Epoch: 10 cost time: 136.50588703155518\n",
            "45it [00:09,  4.65it/s]\n",
            "11it [00:02,  4.13it/s]\n",
            "Epoch: 10 | Train Loss: 0.0034477 Vali Loss: 0.0719447 Test Loss: 0.0437505 MAE Loss: 0.1708686\n",
            "EarlyStopping counter: 1 out of 5\n",
            "Updating learning rate to 7.812500000000005e-09\n",
            "0it [00:00, ?it/s]batch_y_mark torch.Size([16, 65, 3])\n",
            "[163.76    164.66    162.03    160.8     160.1     165.56    165.21\n",
            " 165.23    166.47    167.63    166.65    165.02    165.32999 163.76999\n",
            " 163.76    168.40999]\n",
            "------------ 0    2022-04-05\n",
            "1    2022-04-06\n",
            "2    2022-04-10\n",
            "3    2022-04-11\n",
            "4    2022-04-12\n",
            "5    2022-04-13\n",
            "6    2022-04-14\n",
            "7    2022-04-17\n",
            "8    2022-04-18\n",
            "9    2022-04-19\n",
            "10   2022-04-20\n",
            "11   2022-04-21\n",
            "12   2022-04-24\n",
            "13   2022-04-25\n",
            "14   2022-04-26\n",
            "15   2022-04-27\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "1it [00:00,  1.67it/s]batch_y_mark torch.Size([16, 65, 3])\n",
            "[169.68    169.59    168.54    167.45    165.79    173.57    173.49998\n",
            " 171.77    173.55998 173.75    172.56999 172.07    172.07    172.68999\n",
            " 175.05    175.15999]\n",
            "------------ 0    2022-04-28\n",
            "1    2022-05-01\n",
            "2    2022-05-02\n",
            "3    2022-05-03\n",
            "4    2022-05-04\n",
            "5    2022-05-05\n",
            "6    2022-05-08\n",
            "7    2022-05-09\n",
            "8    2022-05-10\n",
            "9    2022-05-11\n",
            "10   2022-05-12\n",
            "11   2022-05-15\n",
            "12   2022-05-16\n",
            "13   2022-05-17\n",
            "14   2022-05-18\n",
            "15   2022-05-19\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "2it [00:00,  2.77it/s]batch_y_mark torch.Size([16, 65, 3])\n",
            "[174.2     171.56    171.83998 172.98999 175.42998 177.29999 177.25\n",
            " 180.09    180.95    179.57999 179.21    177.82    180.57    180.96\n",
            " 183.79    183.31   ]\n",
            "------------ 0    2022-05-22\n",
            "1    2022-05-23\n",
            "2    2022-05-24\n",
            "3    2022-05-25\n",
            "4    2022-05-26\n",
            "5    2022-05-30\n",
            "6    2022-05-31\n",
            "7    2022-06-01\n",
            "8    2022-06-02\n",
            "9    2022-06-05\n",
            "10   2022-06-06\n",
            "11   2022-06-07\n",
            "12   2022-06-08\n",
            "13   2022-06-09\n",
            "14   2022-06-12\n",
            "15   2022-06-13\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "3it [00:00,  3.48it/s]batch_y_mark torch.Size([16, 65, 3])\n",
            "[183.94998 186.01    184.91998 185.00998 183.96    186.99998 186.68\n",
            " 185.27    188.06    189.25    189.58998 193.97    192.46    191.32999\n",
            " 191.81    190.68   ]\n",
            "------------ 0    2022-06-14\n",
            "1    2022-06-15\n",
            "2    2022-06-16\n",
            "3    2022-06-20\n",
            "4    2022-06-21\n",
            "5    2022-06-22\n",
            "6    2022-06-23\n",
            "7    2022-06-26\n",
            "8    2022-06-27\n",
            "9    2022-06-28\n",
            "10   2022-06-29\n",
            "11   2022-06-30\n",
            "12   2022-07-03\n",
            "13   2022-07-05\n",
            "14   2022-07-06\n",
            "15   2022-07-07\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "4it [00:01,  3.93it/s]batch_y_mark torch.Size([16, 65, 3])\n",
            "[188.61    188.07999 189.76999 190.54    190.69    193.98999 193.73\n",
            " 195.09999 193.13    191.93999 192.74998 193.61998 194.49998 193.22\n",
            " 195.83    196.45   ]\n",
            "------------ 0    2022-07-10\n",
            "1    2022-07-11\n",
            "2    2022-07-12\n",
            "3    2022-07-13\n",
            "4    2022-07-14\n",
            "5    2022-07-17\n",
            "6    2022-07-18\n",
            "7    2022-07-19\n",
            "8    2022-07-20\n",
            "9    2022-07-21\n",
            "10   2022-07-24\n",
            "11   2022-07-25\n",
            "12   2022-07-26\n",
            "13   2022-07-27\n",
            "14   2022-07-28\n",
            "15   2022-07-31\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "5it [00:01,  4.23it/s]batch_y_mark torch.Size([16, 65, 3])\n",
            "[195.60999 192.58    191.17    181.99    178.85    179.79999 178.19\n",
            " 177.97    177.79    179.46    177.45    176.56999 174.      174.48999\n",
            " 175.84    177.22998]\n",
            "------------ 0    2022-08-01\n",
            "1    2022-08-02\n",
            "2    2022-08-03\n",
            "3    2022-08-04\n",
            "4    2022-08-07\n",
            "5    2022-08-08\n",
            "6    2022-08-09\n",
            "7    2022-08-10\n",
            "8    2022-08-11\n",
            "9    2022-08-14\n",
            "10   2022-08-15\n",
            "11   2022-08-16\n",
            "12   2022-08-17\n",
            "13   2022-08-18\n",
            "14   2022-08-21\n",
            "15   2022-08-22\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "6it [00:01,  4.48it/s]batch_y_mark torch.Size([16, 65, 3])\n",
            "[181.11998 176.38    178.61    180.18999 184.12    187.65    187.86998\n",
            " 189.46    189.7     182.91    177.56    178.18    179.36    176.29999\n",
            " 174.21    175.74   ]\n",
            "------------ 0    2022-08-23\n",
            "1    2022-08-24\n",
            "2    2022-08-25\n",
            "3    2022-08-28\n",
            "4    2022-08-29\n",
            "5    2022-08-30\n",
            "6    2022-08-31\n",
            "7    2022-09-01\n",
            "8    2022-09-05\n",
            "9    2022-09-06\n",
            "10   2022-09-07\n",
            "11   2022-09-08\n",
            "12   2022-09-11\n",
            "13   2022-09-12\n",
            "14   2022-09-13\n",
            "15   2022-09-14\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "7it [00:01,  4.58it/s]batch_y_mark torch.Size([16, 65, 3])\n",
            "[175.01    177.97    179.06999 175.48999 173.93    174.78998 176.08\n",
            " 171.95999 170.43    170.69    171.20999 173.75    172.4     173.66\n",
            " 174.91    177.49   ]\n",
            "------------ 0    2022-09-15\n",
            "1    2022-09-18\n",
            "2    2022-09-19\n",
            "3    2022-09-20\n",
            "4    2022-09-21\n",
            "5    2022-09-22\n",
            "6    2022-09-25\n",
            "7    2022-09-26\n",
            "8    2022-09-27\n",
            "9    2022-09-28\n",
            "10   2022-09-29\n",
            "11   2022-10-02\n",
            "12   2022-10-03\n",
            "13   2022-10-04\n",
            "14   2022-10-05\n",
            "15   2022-10-06\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "8it [00:02,  4.45it/s]batch_y_mark torch.Size([16, 65, 3])\n",
            "[178.99    178.39    179.79999 180.71    178.85    178.72    177.15\n",
            " 175.84    175.45999 172.88    173.      173.43999 171.1     166.89\n",
            " 168.22    170.29   ]\n",
            "------------ 0    2022-10-09\n",
            "1    2022-10-10\n",
            "2    2022-10-11\n",
            "3    2022-10-12\n",
            "4    2022-10-13\n",
            "5    2022-10-16\n",
            "6    2022-10-17\n",
            "7    2022-10-18\n",
            "8    2022-10-19\n",
            "9    2022-10-20\n",
            "10   2022-10-23\n",
            "11   2022-10-24\n",
            "12   2022-10-25\n",
            "13   2022-10-26\n",
            "14   2022-10-27\n",
            "15   2022-10-30\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "9it [00:02,  4.46it/s]batch_y_mark torch.Size([16, 65, 3])\n",
            "[170.77    173.97    177.56999 176.65    179.23    181.81999 182.89\n",
            " 182.41    186.4     184.79999 187.44    188.01    189.70999 189.69\n",
            " 191.44998 190.63998]\n",
            "------------ 0    2022-10-31\n",
            "1    2022-11-01\n",
            "2    2022-11-02\n",
            "3    2022-11-03\n",
            "4    2022-11-06\n",
            "5    2022-11-07\n",
            "6    2022-11-08\n",
            "7    2022-11-09\n",
            "8    2022-11-10\n",
            "9    2022-11-13\n",
            "10   2022-11-14\n",
            "11   2022-11-15\n",
            "12   2022-11-16\n",
            "13   2022-11-17\n",
            "14   2022-11-20\n",
            "15   2022-11-21\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "10it [00:02,  4.63it/s]batch_y_mark torch.Size([16, 65, 3])\n",
            "[191.31    189.97    189.79    190.39998 189.36998 189.94998 191.23999\n",
            " 189.42998 193.42    192.32    194.27    195.71    193.18    194.70999\n",
            " 197.95999 198.10999]\n",
            "------------ 0    2022-11-22\n",
            "1    2022-11-24\n",
            "2    2022-11-27\n",
            "3    2022-11-28\n",
            "4    2022-11-29\n",
            "5    2022-11-30\n",
            "6    2022-12-01\n",
            "7    2022-12-04\n",
            "8    2022-12-05\n",
            "9    2022-12-06\n",
            "10   2022-12-07\n",
            "11   2022-12-08\n",
            "12   2022-12-11\n",
            "13   2022-12-12\n",
            "14   2022-12-13\n",
            "15   2022-12-14\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "11it [00:02,  4.04it/s]\n",
            "Results saved to predictions_2023.csv\n"
          ]
        }
      ],
      "source": [
        "!python run_main.py \\\n",
        "    --task_name long_term_forecast \\\n",
        "    --is_training 1 \\\n",
        "    --model_id AAPL_TimeLLM \\\n",
        "    --model TimeLLM \\\n",
        "    --data_path 'data.csv' \\\n",
        "    --root_path '/home/fakoor/Desktop/chitsaz/emotion_detection/' \\\n",
        "    --model_comment \"prediction\" \\\n",
        "    --target 'y' \\\n",
        "    --freq 'd' \\\n",
        "    --seq_len 64 \\\n",
        "    --label_len 64 \\\n",
        "    --pred_len 1 \\\n",
        "    --train_epochs 10 \\\n",
        "    --batch_size 16 \\\n",
        "    --learning_rate 0.0001 \\\n",
        "    --patience 5 \\\n",
        "    --checkpoints './checkpoints/emotion' \\\n",
        "    --loss MSE \\\n",
        "    --lradj type1 \\\n",
        "    --prompt_domain 1 \\\n",
        "    --data Traffic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "!export RDMAV_FORK_SAFE=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTZY0yHGDLlG",
        "outputId": "372e4790-d89f-4e5e-87a2-d555f9d608aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mpi4py\n",
            "  Using cached mpi4py-4.0.0.tar.gz (464 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for mpi4py: filename=mpi4py-4.0.0-cp310-cp310-linux_x86_64.whl size=4856817 sha256=7ef26bdd6d385be6ace823285d482964ac0c5f3b383ee25d74de02710f291b8a\n",
            "  Stored in directory: /home/fakoor/.cache/pip/wheels/96/17/12/83db63ee0ae5c4b040ee87f2e5c813aea4728b55ec6a37317c\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-4.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mpi4py\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
