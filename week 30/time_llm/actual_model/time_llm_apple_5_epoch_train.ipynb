{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/androidwoman/stock_time_llm.git\n",
        "%cd /content/stock_time_llm"
      ],
      "metadata": {
        "id": "fa5GTlUs2306",
        "outputId": "30c9833b-1bb5-4395-949b-d3d848297a32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'stock_time_llm' already exists and is not an empty directory.\n",
            "/content/stock_time_llm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt\n"
      ],
      "metadata": {
        "id": "hH3daSu_B_S2",
        "outputId": "d8d48a50-54a1-4cfe-a7ab-a19c3a261de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.2.2 (from -r requirements.txt (line 1))\n",
            "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting accelerate==0.28.0 (from -r requirements.txt (line 2))\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting einops==0.7.0 (from -r requirements.txt (line 3))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting matplotlib==3.7.0 (from -r requirements.txt (line 4))\n",
            "  Downloading matplotlib-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting numpy==1.23.5 (from -r requirements.txt (line 5))\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting pandas==1.5.3 (from -r requirements.txt (line 6))\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scikit_learn==1.2.2 (from -r requirements.txt (line 7))\n",
            "  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy==1.12.0 (from -r requirements.txt (line 8))\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.65.0 (from -r requirements.txt (line 9))\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft==0.4.0 (from -r requirements.txt (line 10))\n",
            "  Downloading peft-0.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting transformers==4.31.0 (from -r requirements.txt (line 11))\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deepspeed==0.14.0 (from -r requirements.txt (line 12))\n",
            "  Downloading deepspeed-0.14.0.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece==0.2.0 (from -r requirements.txt (line 13))\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements.txt (line 1)) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements.txt (line 1)) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements.txt (line 1)) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (0.23.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0->-r requirements.txt (line 2)) (0.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3->-r requirements.txt (line 6)) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.2.2->-r requirements.txt (line 7)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.2.2->-r requirements.txt (line 7)) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r requirements.txt (line 11)) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0->-r requirements.txt (line 11)) (2.32.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0->-r requirements.txt (line 11))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting hjson (from deepspeed==0.14.0->-r requirements.txt (line 12))\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting ninja (from deepspeed==0.14.0->-r requirements.txt (line 12))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.0->-r requirements.txt (line 12)) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.14.0->-r requirements.txt (line 12)) (2.8.2)\n",
            "Collecting pynvml (from deepspeed==0.14.0->-r requirements.txt (line 12))\n",
            "  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.0->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.2->-r requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.14.0->-r requirements.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed==0.14.0->-r requirements.txt (line 12)) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0->-r requirements.txt (line 11)) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2->-r requirements.txt (line 1)) (1.3.0)\n",
            "Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m114.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.4.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.14.0-py3-none-any.whl size=1400397 sha256=5dd99e9ce5ec86fb5434862f6ad0e3a133609425cf69a48373f12d9fd2093ad3\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/96/24/bab20c3b4e2af15e195b339afaec373eca7072cf90620432e5\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: tokenizers, sentencepiece, ninja, hjson, triton, tqdm, pynvml, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, einops, scipy, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, transformers, scikit_learn, nvidia-cusolver-cu12, matplotlib, torch, deepspeed, accelerate, peft\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.99\n",
            "    Uninstalling sentencepiece-0.1.99:\n",
            "      Successfully uninstalled sentencepiece-0.1.99\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.1\n",
            "    Uninstalling triton-2.3.1:\n",
            "      Successfully uninstalled triton-2.3.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.5\n",
            "    Uninstalling tqdm-4.66.5:\n",
            "      Successfully uninstalled tqdm-4.66.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.0\n",
            "    Uninstalling einops-0.8.0:\n",
            "      Successfully uninstalled einops-0.8.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.3.2\n",
            "    Uninstalling scikit-learn-1.3.2:\n",
            "      Successfully uninstalled scikit-learn-1.3.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1+cu121\n",
            "    Uninstalling torch-2.3.1+cu121:\n",
            "      Successfully uninstalled torch-2.3.1+cu121\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.32.1\n",
            "    Uninstalling accelerate-0.32.1:\n",
            "      Successfully uninstalled accelerate-0.32.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.13 requires numpy<2,>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.14 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.15.0 requires matplotlib>=3.7.1, but you have matplotlib 3.7.0 which is incompatible.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 1.5.3 which is incompatible.\n",
            "osqp 0.6.7.post0 requires scipy!=1.12.0,>=0.13.2, but you have scipy 1.12.0 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.23.5 which is incompatible.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.2.2 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.2.2 which is incompatible.\n",
            "torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.2.2 which is incompatible.\n",
            "xarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.28.0 deepspeed-0.14.0 einops-0.7.0 hjson-3.1.0 matplotlib-3.7.0 ninja-1.11.1.1 numpy-1.23.5 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 pandas-1.5.3 peft-0.4.0 pynvml-11.5.3 scikit_learn-1.2.2 scipy-1.12.0 sentencepiece-0.2.0 tokenizers-0.13.3 torch-2.2.2 tqdm-4.65.0 transformers-4.31.0 triton-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pandas"
                ]
              },
              "id": "1245bc83595d4904bc897696a95742c4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Download stock data for a specific ticker, e.g., Apple (AAPL)\n",
        "data = yf.download('AAPL', start='2000-01-01', end='2024-01-01', interval='1d')\n",
        "data.reset_index(inplace=True)\n",
        "\n",
        "# Prepare the data by selecting necessary columns and renaming them\n",
        "data = data[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "data.columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume']\n",
        "\n",
        "# Save the data to CSV if needed\n",
        "data.to_csv('AAPL_stock_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "l102kT0SCAb1",
        "outputId": "6c7e406f-87bb-45a5-9fbd-b27ec2555613",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_DIR=\"./checkpoints/AAPL\"\n",
        "\n",
        "# Ensure the checkpoint directory exists\n",
        "!mkdir -p $CHECKPOINT_DIR"
      ],
      "metadata": {
        "id": "yq6sopLnDGNW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "EiYf2-EFE2ES",
        "outputId": "d2ec644c-77f7-4e4f-8d18-4a7533452c68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AAPL_stock_data.csv  \u001b[0m\u001b[01;34mcheckpoints\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;34mstock_time_llm\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = data\n",
        "df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
        "df.rename(columns={'close': 'y'}, inplace=True)\n",
        "df = df[['date', 'y']]\n",
        "df.to_csv('/content/stock_time_llm/dataset/AAPL_stock_data.csv', index=False)\n"
      ],
      "metadata": {
        "id": "1GzSJr5AFirw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80e6c4a-5e9a-4986-c720-a319c90a9630"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-716a47fc6cce>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
            "<ipython-input-6-716a47fc6cce>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.rename(columns={'close': 'y'}, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "SGhypmqiFqrO",
        "outputId": "ed0ffa71-a154-4543-ebfb-1ea99063c16c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           date           y\n",
              "0    2000-01-03    0.999442\n",
              "1    2000-01-04    0.915179\n",
              "2    2000-01-05    0.928571\n",
              "3    2000-01-06    0.848214\n",
              "4    2000-01-07    0.888393\n",
              "...         ...         ...\n",
              "6032 2023-12-22  193.600006\n",
              "6033 2023-12-26  193.050003\n",
              "6034 2023-12-27  193.149994\n",
              "6035 2023-12-28  193.580002\n",
              "6036 2023-12-29  192.529999\n",
              "\n",
              "[6037 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23870408-afa0-45bb-999d-208009f8787c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000-01-03</td>\n",
              "      <td>0.999442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-01-04</td>\n",
              "      <td>0.915179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-01-05</td>\n",
              "      <td>0.928571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-01-06</td>\n",
              "      <td>0.848214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-01-07</td>\n",
              "      <td>0.888393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6032</th>\n",
              "      <td>2023-12-22</td>\n",
              "      <td>193.600006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6033</th>\n",
              "      <td>2023-12-26</td>\n",
              "      <td>193.050003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6034</th>\n",
              "      <td>2023-12-27</td>\n",
              "      <td>193.149994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6035</th>\n",
              "      <td>2023-12-28</td>\n",
              "      <td>193.580002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6036</th>\n",
              "      <td>2023-12-29</td>\n",
              "      <td>192.529999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6037 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23870408-afa0-45bb-999d-208009f8787c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23870408-afa0-45bb-999d-208009f8787c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23870408-afa0-45bb-999d-208009f8787c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-01b2a122-6c18-40f0-9362-3ac142fc669a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-01b2a122-6c18-40f0-9362-3ac142fc669a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-01b2a122-6c18-40f0-9362-3ac142fc669a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_60819867-6200-4dda-95e7-2fae7d82114d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_60819867-6200-4dda-95e7-2fae7d82114d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6037,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2000-01-03 00:00:00\",\n        \"max\": \"2023-12-29 00:00:00\",\n        \"num_unique_values\": 6037,\n        \"samples\": [\n          \"2021-12-20 00:00:00\",\n          \"2002-10-31 00:00:00\",\n          \"2019-07-26 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51.05085014859531,\n        \"min\": 0.23428599536418915,\n        \"max\": 198.11000061035156,\n        \"num_unique_values\": 5517,\n        \"samples\": [\n          5.994999885559082,\n          3.288928985595703,\n          18.08928680419922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd stock_time_llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMi-Hn-def4t",
        "outputId": "bf7a266d-369f-4b1e-b873-75609f300f59"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stock_time_llm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_main.py \\\n",
        "    --task_name long_term_forecast \\\n",
        "    --is_training 1 \\\n",
        "    --model_id AAPL_TimeLLM \\\n",
        "    --model TimeLLM \\\n",
        "    --data_path 'AAPL_stock_data.csv' \\\n",
        "    --root_path './dataset/' \\\n",
        "    --model_comment \"Stock price prediction\" \\\n",
        "    --target 'y' \\\n",
        "    --freq 'd' \\\n",
        "    --seq_len 64 \\\n",
        "    --label_len 64 \\\n",
        "    --pred_len 1 \\\n",
        "    --train_epochs 5 \\\n",
        "    --batch_size 16 \\\n",
        "    --learning_rate 0.0001 \\\n",
        "    --patience 5 \\\n",
        "    --checkpoints './checkpoints/AAPL' \\\n",
        "    --loss MSE \\\n",
        "    --lradj type1 \\\n",
        "    --prompt_domain 1 \\\n",
        "    --data Traffic\n"
      ],
      "metadata": {
        "id": "acReWe6pDDE_",
        "outputId": "5440f6fd-92b6-4d32-ca1f-9002fcab15bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json: 100% 594/594 [00:00<00:00, 4.34MB/s]\n",
            "Local model files not found. Attempting to download...\n",
            "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 80.4MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/9.98G [00:00<00:55, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/9.98G [00:00<00:35, 280MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 105M/9.98G [00:00<00:30, 323MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 147M/9.98G [00:00<00:32, 302MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 178M/9.98G [00:00<00:32, 300MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 210M/9.98G [00:00<00:32, 304MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 241M/9.98G [00:00<00:32, 302MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 283M/9.98G [00:00<00:30, 317MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 325M/9.98G [00:01<00:29, 332MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 367M/9.98G [00:01<00:36, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 398M/9.98G [00:01<00:37, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 430M/9.98G [00:01<00:37, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 461M/9.98G [00:01<00:40, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 493M/9.98G [00:01<00:39, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 524M/9.98G [00:01<00:37, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 566M/9.98G [00:02<00:34, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 598M/9.98G [00:02<00:38, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 629M/9.98G [00:02<00:38, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 661M/9.98G [00:02<00:38, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 692M/9.98G [00:02<00:43, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 734M/9.98G [00:02<00:38, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 765M/9.98G [00:02<00:36, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 797M/9.98G [00:03<00:35, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 828M/9.98G [00:03<00:38, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 870M/9.98G [00:03<00:37, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 902M/9.98G [00:03<00:37, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 944M/9.98G [00:03<00:34, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 975M/9.98G [00:03<00:36, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 1.02G/9.98G [00:03<00:33, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.06G/9.98G [00:04<00:31, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.09G/9.98G [00:04<00:38, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.12G/9.98G [00:04<00:36, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.15G/9.98G [00:04<00:37, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.18G/9.98G [00:04<00:40, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.22G/9.98G [00:04<00:38, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.25G/9.98G [00:04<00:36, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.28G/9.98G [00:05<00:36, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.31G/9.98G [00:05<00:38, 225MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.34G/9.98G [00:05<00:38, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.37G/9.98G [00:05<00:37, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.41G/9.98G [00:05<00:34, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.44G/9.98G [00:05<00:36, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.47G/9.98G [00:05<00:36, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.50G/9.98G [00:06<00:36, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.53G/9.98G [00:06<00:34, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.56G/9.98G [00:06<00:33, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.59G/9.98G [00:06<00:33, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.63G/9.98G [00:06<00:33, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.66G/9.98G [00:06<00:32, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.69G/9.98G [00:06<00:34, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.72G/9.98G [00:06<00:32, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.75G/9.98G [00:06<00:32, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.78G/9.98G [00:07<00:31, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.81G/9.98G [00:07<00:32, 254MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.85G/9.98G [00:07<00:32, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.88G/9.98G [00:07<00:33, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.91G/9.98G [00:07<00:33, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.94G/9.98G [00:07<00:32, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.97G/9.98G [00:07<00:32, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.00G/9.98G [00:08<00:38, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.03G/9.98G [00:08<00:39, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.07G/9.98G [00:08<00:38, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.10G/9.98G [00:08<00:35, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.13G/9.98G [00:08<00:32, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.16G/9.98G [00:08<00:33, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.19G/9.98G [00:08<00:33, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.22G/9.98G [00:09<00:34, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.25G/9.98G [00:09<00:32, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.29G/9.98G [00:09<00:30, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.32G/9.98G [00:09<00:29, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.35G/9.98G [00:09<00:29, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.38G/9.98G [00:09<00:29, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.41G/9.98G [00:09<00:27, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.44G/9.98G [00:09<00:26, 280MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.49G/9.98G [00:09<00:24, 302MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.52G/9.98G [00:10<00:28, 262MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.55G/9.98G [00:10<00:50, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.58G/9.98G [00:10<01:02, 118MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.60G/9.98G [00:11<01:01, 120MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.62G/9.98G [00:11<01:12, 101MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.64G/9.98G [00:11<01:29, 82.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.66G/9.98G [00:12<01:31, 79.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.67G/9.98G [00:12<01:33, 77.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.68G/9.98G [00:12<01:35, 76.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.69G/9.98G [00:12<01:37, 74.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.71G/9.98G [00:12<01:39, 73.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.72G/9.98G [00:12<01:42, 71.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.73G/9.98G [00:12<01:34, 76.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.74G/9.98G [00:13<01:35, 75.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.75G/9.98G [00:13<01:40, 72.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.76G/9.98G [00:13<01:41, 71.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.77G/9.98G [00:13<01:35, 75.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.78G/9.98G [00:13<01:39, 72.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.79G/9.98G [00:13<01:39, 72.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.80G/9.98G [00:14<01:42, 70.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.81G/9.98G [00:14<01:42, 70.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.84G/9.98G [00:14<01:02, 114MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.87G/9.98G [00:14<00:47, 148MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.90G/9.98G [00:14<00:42, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.93G/9.98G [00:14<00:45, 156MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.95G/9.98G [00:15<00:57, 122MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.97G/9.98G [00:17<04:17, 27.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.00G/9.98G [00:17<02:48, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.03G/9.98G [00:17<01:56, 59.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.06G/9.98G [00:17<01:24, 81.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.09G/9.98G [00:17<01:07, 102MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.12G/9.98G [00:17<00:56, 122MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.16G/9.98G [00:18<00:46, 146MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.19G/9.98G [00:18<00:41, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.22G/9.98G [00:18<00:36, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.25G/9.98G [00:18<00:32, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.28G/9.98G [00:18<00:30, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.31G/9.98G [00:18<00:29, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.34G/9.98G [00:18<00:29, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.38G/9.98G [00:18<00:27, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.41G/9.98G [00:19<00:28, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.44G/9.98G [00:19<00:28, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.47G/9.98G [00:19<00:30, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.50G/9.98G [00:19<00:30, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.53G/9.98G [00:19<00:29, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.57G/9.98G [00:19<00:29, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.60G/9.98G [00:19<00:28, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.63G/9.98G [00:20<00:27, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.66G/9.98G [00:20<00:26, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.69G/9.98G [00:20<00:29, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.72G/9.98G [00:20<00:31, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.74G/9.98G [00:20<00:31, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.76G/9.98G [00:20<00:31, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.79G/9.98G [00:20<00:31, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.81G/9.98G [00:23<03:27, 29.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.84G/9.98G [00:23<02:18, 44.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.87G/9.98G [00:23<01:37, 62.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.90G/9.98G [00:23<01:11, 85.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.93G/9.98G [00:23<00:56, 107MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.96G/9.98G [00:23<00:47, 127MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.00G/9.98G [00:23<00:39, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.03G/9.98G [00:24<00:35, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.06G/9.98G [00:24<00:31, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.09G/9.98G [00:24<00:28, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.12G/9.98G [00:24<00:35, 163MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.15G/9.98G [00:25<00:50, 116MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.17G/9.98G [00:25<00:51, 112MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.19G/9.98G [00:25<00:55, 104MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.22G/9.98G [00:25<01:01, 94.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.24G/9.98G [00:26<01:00, 94.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.26G/9.98G [00:26<00:51, 111MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.28G/9.98G [00:26<00:59, 95.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.30G/9.98G [00:27<01:56, 48.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.32G/9.98G [00:27<01:30, 62.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.35G/9.98G [00:27<01:04, 86.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.38G/9.98G [00:27<00:49, 113MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.40G/9.98G [00:27<00:44, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.44G/9.98G [00:27<00:37, 149MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.47G/9.98G [00:28<00:33, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.50G/9.98G [00:28<00:29, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.53G/9.98G [00:28<00:27, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.56G/9.98G [00:28<00:24, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.59G/9.98G [00:28<00:23, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.62G/9.98G [00:28<00:22, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.66G/9.98G [00:28<00:21, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.69G/9.98G [00:28<00:20, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.72G/9.98G [00:29<00:21, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.75G/9.98G [00:29<00:20, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.78G/9.98G [00:29<00:20, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.81G/9.98G [00:29<00:20, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.84G/9.98G [00:29<00:20, 250MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.88G/9.98G [00:29<00:21, 235MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.91G/9.98G [00:29<00:21, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.94G/9.98G [00:30<00:20, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.97G/9.98G [00:30<00:20, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.00G/9.98G [00:30<00:20, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.03G/9.98G [00:30<00:19, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.06G/9.98G [00:30<00:19, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.10G/9.98G [00:30<00:19, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.13G/9.98G [00:30<00:18, 266MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.16G/9.98G [00:30<00:18, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.19G/9.98G [00:30<00:19, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.22G/9.98G [00:31<00:18, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.25G/9.98G [00:31<00:19, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.28G/9.98G [00:31<00:19, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.32G/9.98G [00:31<00:18, 249MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.35G/9.98G [00:31<00:17, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.38G/9.98G [00:31<00:18, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.41G/9.98G [00:31<00:19, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.44G/9.98G [00:32<00:20, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.47G/9.98G [00:32<00:19, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.51G/9.98G [00:32<00:21, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.54G/9.98G [00:32<00:19, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.57G/9.98G [00:32<00:18, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.60G/9.98G [00:32<00:18, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.63G/9.98G [00:32<00:19, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.66G/9.98G [00:33<00:18, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.69G/9.98G [00:33<00:19, 220MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.73G/9.98G [00:33<00:21, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.76G/9.98G [00:33<00:20, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.79G/9.98G [00:33<00:20, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.82G/9.98G [00:33<00:20, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.85G/9.98G [00:33<00:18, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.88G/9.98G [00:34<00:19, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.91G/9.98G [00:34<00:20, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.93G/9.98G [00:34<00:20, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.97G/9.98G [00:34<00:20, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.99G/9.98G [00:34<00:26, 149MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.01G/9.98G [00:37<02:40, 24.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.03G/9.98G [00:37<02:05, 31.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.06G/9.98G [00:38<01:24, 46.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.09G/9.98G [00:38<00:59, 65.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.12G/9.98G [00:38<00:44, 86.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.16G/9.98G [00:38<00:35, 107MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.19G/9.98G [00:38<00:30, 125MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.22G/9.98G [00:38<00:29, 127MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.24G/9.98G [00:39<00:36, 102MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.26G/9.98G [00:39<00:32, 114MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.29G/9.98G [00:39<00:26, 141MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.32G/9.98G [00:39<00:21, 167MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.35G/9.98G [00:39<00:20, 176MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.39G/9.98G [00:39<00:19, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.42G/9.98G [00:39<00:17, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.45G/9.98G [00:41<00:51, 68.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.48G/9.98G [00:41<00:39, 88.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.51G/9.98G [00:41<00:31, 111MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.54G/9.98G [00:41<00:25, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.57G/9.98G [00:41<00:32, 104MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.60G/9.98G [00:42<00:29, 113MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.63G/9.98G [00:42<00:24, 137MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.66G/9.98G [00:42<00:20, 160MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.69G/9.98G [00:42<00:18, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.72G/9.98G [00:42<00:16, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.75G/9.98G [00:42<00:15, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.78G/9.98G [00:42<00:14, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.82G/9.98G [00:42<00:13, 228MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.85G/9.98G [00:43<00:13, 230MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.88G/9.98G [00:43<00:13, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.91G/9.98G [00:43<00:12, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.94G/9.98G [00:43<00:11, 259MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.97G/9.98G [00:43<00:11, 272MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 7.00G/9.98G [00:43<00:12, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.04G/9.98G [00:43<00:11, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.07G/9.98G [00:43<00:11, 246MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.10G/9.98G [00:44<00:11, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.13G/9.98G [00:44<00:11, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.16G/9.98G [00:44<00:11, 253MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.19G/9.98G [00:44<00:11, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.22G/9.98G [00:44<00:10, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.26G/9.98G [00:44<00:10, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.29G/9.98G [00:44<00:10, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.32G/9.98G [00:44<00:10, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.35G/9.98G [00:45<00:10, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.38G/9.98G [00:45<00:10, 236MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.41G/9.98G [00:45<00:12, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.44G/9.98G [00:45<00:12, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.48G/9.98G [00:45<00:11, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.51G/9.98G [00:45<00:11, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.54G/9.98G [00:45<00:10, 227MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.57G/9.98G [00:46<00:10, 222MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.60G/9.98G [00:46<00:10, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.63G/9.98G [00:46<00:09, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.67G/9.98G [00:46<00:09, 238MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.70G/9.98G [00:46<00:10, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.73G/9.98G [00:46<00:10, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.76G/9.98G [00:46<00:10, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.79G/9.98G [00:47<00:10, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.82G/9.98G [00:47<00:10, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.85G/9.98G [00:47<00:10, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.87G/9.98G [00:47<00:10, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.90G/9.98G [00:47<00:10, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.93G/9.98G [00:47<00:10, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.96G/9.98G [00:47<00:10, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.99G/9.98G [00:48<00:09, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 8.02G/9.98G [00:48<00:09, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.05G/9.98G [00:48<00:08, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.08G/9.98G [00:48<00:08, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.12G/9.98G [00:48<00:08, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.15G/9.98G [00:48<00:07, 242MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.18G/9.98G [00:48<00:06, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.21G/9.98G [00:48<00:07, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.24G/9.98G [00:49<00:07, 243MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.27G/9.98G [00:49<00:06, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.30G/9.98G [00:50<00:25, 64.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.33G/9.98G [00:51<00:43, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.36G/9.98G [00:52<00:31, 52.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.39G/9.98G [00:52<00:22, 70.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.41G/9.98G [00:52<00:18, 82.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.43G/9.98G [00:52<00:16, 95.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.46G/9.98G [00:52<00:12, 119MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.49G/9.98G [00:52<00:10, 146MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.52G/9.98G [00:52<00:08, 163MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.56G/9.98G [00:52<00:08, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.59G/9.98G [00:53<00:07, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.62G/9.98G [00:53<00:06, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.65G/9.98G [00:53<00:06, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.68G/9.98G [00:53<00:05, 233MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.71G/9.98G [00:53<00:05, 247MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.75G/9.98G [00:53<00:04, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.78G/9.98G [00:53<00:04, 261MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.81G/9.98G [00:53<00:04, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.84G/9.98G [00:53<00:04, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.87G/9.98G [00:54<00:03, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.90G/9.98G [00:54<00:04, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.93G/9.98G [00:54<00:03, 265MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.97G/9.98G [00:54<00:03, 273MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.00G/9.98G [00:54<00:03, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.03G/9.98G [00:54<00:03, 280MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.06G/9.98G [00:54<00:03, 271MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.09G/9.98G [00:54<00:03, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.12G/9.98G [00:55<00:03, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.15G/9.98G [00:55<00:03, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.19G/9.98G [00:55<00:03, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.22G/9.98G [00:55<00:03, 248MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.25G/9.98G [00:55<00:02, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.28G/9.98G [00:55<00:02, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.31G/9.98G [00:55<00:02, 267MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.34G/9.98G [00:55<00:02, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.38G/9.98G [00:56<00:02, 284MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.42G/9.98G [00:56<00:02, 271MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.45G/9.98G [00:56<00:01, 275MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.48G/9.98G [00:56<00:01, 277MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.51G/9.98G [00:56<00:01, 276MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.55G/9.98G [00:56<00:01, 289MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.58G/9.98G [00:56<00:01, 285MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.62G/9.98G [00:56<00:01, 284MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.65G/9.98G [00:56<00:01, 287MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.68G/9.98G [00:57<00:01, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.71G/9.98G [00:57<00:01, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.74G/9.98G [00:57<00:01, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.77G/9.98G [00:57<00:00, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.81G/9.98G [00:57<00:00, 245MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.85G/9.98G [00:57<00:00, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.88G/9.98G [00:57<00:00, 252MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.91G/9.98G [00:58<00:00, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.94G/9.98G [00:58<00:00, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [00:58<00:00, 171MB/s]\n",
            "Downloading shards:  50% 1/2 [00:58<00:58, 58.53s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 21.0M/3.50G [00:00<00:21, 159MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 52.4M/3.50G [00:00<00:14, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 83.9M/3.50G [00:00<00:13, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 115M/3.50G [00:00<00:14, 238MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 147M/3.50G [00:00<00:13, 244MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 178M/3.50G [00:00<00:14, 235MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 210M/3.50G [00:00<00:15, 214MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 241M/3.50G [00:01<00:22, 146MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 273M/3.50G [00:01<00:19, 163MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 304M/3.50G [00:01<00:18, 176MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 336M/3.50G [00:01<00:15, 201MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 367M/3.50G [00:01<00:13, 226MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 398M/3.50G [00:01<00:12, 243MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 430M/3.50G [00:02<00:13, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 461M/3.50G [00:02<00:14, 210MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 493M/3.50G [00:02<00:14, 211MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 524M/3.50G [00:02<00:13, 213MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 556M/3.50G [00:03<00:25, 114MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 587M/3.50G [00:03<00:22, 132MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 619M/3.50G [00:03<00:18, 156MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 650M/3.50G [00:03<00:15, 179MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 682M/3.50G [00:03<00:13, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 713M/3.50G [00:03<00:12, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 744M/3.50G [00:03<00:11, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 776M/3.50G [00:03<00:11, 241MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 818M/3.50G [00:04<00:10, 250MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 849M/3.50G [00:04<00:10, 251MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 881M/3.50G [00:04<00:09, 263MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 912M/3.50G [00:04<00:09, 261MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 944M/3.50G [00:04<00:10, 246MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 986M/3.50G [00:04<00:09, 254MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 1.02G/3.50G [00:04<00:10, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 1.05G/3.50G [00:04<00:09, 256MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.08G/3.50G [00:05<00:09, 244MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 1.11G/3.50G [00:05<00:10, 234MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.14G/3.50G [00:05<00:09, 251MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.17G/3.50G [00:05<00:09, 256MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.21G/3.50G [00:05<00:08, 261MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 1.24G/3.50G [00:07<00:51, 44.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.28G/3.50G [00:07<00:34, 64.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.32G/3.50G [00:07<00:24, 90.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.36G/3.50G [00:08<00:18, 118MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.39G/3.50G [00:08<00:15, 137MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.43G/3.50G [00:08<00:13, 154MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.46G/3.50G [00:08<00:11, 171MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.49G/3.50G [00:08<00:10, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.52G/3.50G [00:08<00:09, 214MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.55G/3.50G [00:08<00:08, 229MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.59G/3.50G [00:08<00:07, 257MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.63G/3.50G [00:09<00:07, 267MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.67G/3.50G [00:09<00:06, 289MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.70G/3.50G [00:09<00:06, 268MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.73G/3.50G [00:09<00:06, 257MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.76G/3.50G [00:09<00:07, 245MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.79G/3.50G [00:09<00:06, 244MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.82G/3.50G [00:09<00:07, 216MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 1.86G/3.50G [00:13<01:06, 24.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.89G/3.50G [00:13<00:47, 33.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.92G/3.50G [00:14<00:34, 45.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 1.95G/3.50G [00:14<00:25, 61.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.98G/3.50G [00:14<00:19, 78.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.01G/3.50G [00:14<00:15, 93.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.04G/3.50G [00:14<00:12, 113MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 2.08G/3.50G [00:14<00:11, 129MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 2.11G/3.50G [00:14<00:09, 148MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.14G/3.50G [00:15<00:08, 164MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 2.17G/3.50G [00:15<00:07, 184MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 2.20G/3.50G [00:15<00:06, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.23G/3.50G [00:15<00:06, 206MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.26G/3.50G [00:15<00:05, 216MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 2.30G/3.50G [00:15<00:05, 216MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.33G/3.50G [00:15<00:05, 217MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.36G/3.50G [00:16<00:04, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 2.39G/3.50G [00:16<00:04, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.42G/3.50G [00:16<00:04, 253MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 2.45G/3.50G [00:16<00:04, 239MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 2.49G/3.50G [00:16<00:04, 210MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.52G/3.50G [00:16<00:04, 226MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 2.55G/3.50G [00:16<00:03, 242MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 2.58G/3.50G [00:20<00:32, 28.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.62G/3.50G [00:20<00:20, 42.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 2.66G/3.50G [00:20<00:13, 61.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 2.71G/3.50G [00:20<00:09, 82.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.74G/3.50G [00:20<00:07, 96.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 2.77G/3.50G [00:20<00:06, 118MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.80G/3.50G [00:21<00:04, 141MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.83G/3.50G [00:21<00:04, 165MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 2.86G/3.50G [00:21<00:03, 186MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.90G/3.50G [00:21<00:02, 217MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.94G/3.50G [00:21<00:02, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 2.97G/3.50G [00:21<00:02, 249MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.00G/3.50G [00:21<00:01, 259MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.03G/3.50G [00:21<00:01, 268MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.06G/3.50G [00:21<00:01, 267MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 3.09G/3.50G [00:22<00:01, 279MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 3.14G/3.50G [00:22<00:01, 299MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 3.17G/3.50G [00:22<00:01, 281MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 3.20G/3.50G [00:22<00:01, 281MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 3.23G/3.50G [00:22<00:00, 282MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 3.26G/3.50G [00:22<00:00, 282MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 3.29G/3.50G [00:22<00:00, 276MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 3.32G/3.50G [00:22<00:00, 273MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 3.36G/3.50G [00:22<00:00, 268MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 3.39G/3.50G [00:23<00:00, 261MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 3.42G/3.50G [00:23<00:00, 257MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 3.45G/3.50G [00:23<00:00, 256MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:23<00:00, 148MB/s]\n",
            "Downloading shards: 100% 2/2 [01:22<00:00, 41.12s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:12<00:00,  6.37s/it]\n",
            "Local tokenizer files not found. Atempting to download them..\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 4.86MB/s]\n",
            "special_tokens_map.json: 100% 411/411 [00:00<00:00, 2.47MB/s]\n",
            "tokenizer_config.json: 100% 2.28k/2.28k [00:00<00:00, 13.1MB/s]\n",
            "[2024-08-23 13:48:44,824] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "[2024-08-23 13:48:45,590] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown\n",
            "[2024-08-23 13:48:45,590] [INFO] [comm.py:637:init_distributed] cdb=None\n",
            "[2024-08-23 13:48:45,590] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
            "[2024-08-23 13:48:46,488] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=172.28.0.12, master_port=29500\n",
            "[2024-08-23 13:48:46,489] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
            "[2024-08-23 13:48:51,202] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
            "[2024-08-23 13:48:51,203] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
            "[2024-08-23 13:48:51,203] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
            "[2024-08-23 13:48:51,204] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = Adam\n",
            "[2024-08-23 13:48:51,204] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=Adam type=<class 'torch.optim.adam.Adam'>\n",
            "[2024-08-23 13:48:51,204] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer\n",
            "[2024-08-23 13:48:51,204] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 200000000\n",
            "[2024-08-23 13:48:51,204] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000\n",
            "[2024-08-23 13:48:51,204] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False\n",
            "[2024-08-23 13:48:51,204] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False\n",
            "[2024-08-23 13:48:51,579] [INFO] [utils.py:800:see_memory_usage] Before initializing optimizer states\n",
            "[2024-08-23 13:48:51,580] [INFO] [utils.py:801:see_memory_usage] MA 2.71 GB         Max_MA 2.78 GB         CA 2.78 GB         Max_CA 3 GB \n",
            "[2024-08-23 13:48:51,580] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 1.87 GB, percent = 14.8%\n",
            "[2024-08-23 13:48:51,746] [INFO] [utils.py:800:see_memory_usage] After initializing optimizer states\n",
            "[2024-08-23 13:48:51,746] [INFO] [utils.py:801:see_memory_usage] MA 2.71 GB         Max_MA 2.84 GB         CA 2.91 GB         Max_CA 3 GB \n",
            "[2024-08-23 13:48:51,747] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 1.87 GB, percent = 14.8%\n",
            "[2024-08-23 13:48:51,747] [INFO] [stage_1_and_2.py:539:__init__] optimizer state initialized\n",
            "[2024-08-23 13:48:51,903] [INFO] [utils.py:800:see_memory_usage] After initializing ZeRO optimizer\n",
            "[2024-08-23 13:48:51,904] [INFO] [utils.py:801:see_memory_usage] MA 2.71 GB         Max_MA 2.71 GB         CA 2.91 GB         Max_CA 3 GB \n",
            "[2024-08-23 13:48:51,904] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 1.87 GB, percent = 14.8%\n",
            "[2024-08-23 13:48:51,907] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = Adam\n",
            "[2024-08-23 13:48:51,907] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
            "[2024-08-23 13:48:51,907] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
            "[2024-08-23 13:48:51,907] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[4.000000000000002e-06], mom=[(0.95, 0.999)]\n",
            "[2024-08-23 13:48:51,908] [INFO] [config.py:996:print] DeepSpeedEngine configuration:\n",
            "[2024-08-23 13:48:51,908] [INFO] [config.py:1000:print]   activation_checkpointing_config  {\n",
            "    \"partition_activations\": false, \n",
            "    \"contiguous_memory_optimization\": false, \n",
            "    \"cpu_checkpointing\": false, \n",
            "    \"number_checkpoints\": null, \n",
            "    \"synchronize_checkpoint_boundary\": false, \n",
            "    \"profile\": false\n",
            "}\n",
            "[2024-08-23 13:48:51,908] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
            "[2024-08-23 13:48:51,908] [INFO] [config.py:1000:print]   amp_enabled .................. False\n",
            "[2024-08-23 13:48:51,908] [INFO] [config.py:1000:print]   amp_params ................... False\n",
            "[2024-08-23 13:48:51,908] [INFO] [config.py:1000:print]   autotuning_config ............ {\n",
            "    \"enabled\": false, \n",
            "    \"start_step\": null, \n",
            "    \"end_step\": null, \n",
            "    \"metric_path\": null, \n",
            "    \"arg_mappings\": null, \n",
            "    \"metric\": \"throughput\", \n",
            "    \"model_info\": null, \n",
            "    \"results_dir\": \"autotuning_results\", \n",
            "    \"exps_dir\": \"autotuning_exps\", \n",
            "    \"overwrite\": true, \n",
            "    \"fast\": true, \n",
            "    \"start_profile_step\": 3, \n",
            "    \"end_profile_step\": 5, \n",
            "    \"tuner_type\": \"gridsearch\", \n",
            "    \"tuner_early_stopping\": 5, \n",
            "    \"tuner_num_trials\": 50, \n",
            "    \"model_info_path\": null, \n",
            "    \"mp_size\": 1, \n",
            "    \"max_train_batch_size\": null, \n",
            "    \"min_train_batch_size\": 1, \n",
            "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
            "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
            "    \"num_tuning_micro_batch_sizes\": 3\n",
            "}\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f82d9b30730>\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   communication_data_type ...... None\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   disable_allgather ............ False\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   dump_state ................... False\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06\n",
            "[2024-08-23 13:48:51,909] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   elasticity_enabled ........... False\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   flops_profiler_config ........ {\n",
            "    \"enabled\": false, \n",
            "    \"recompute_fwd_factor\": 0.0, \n",
            "    \"profile_step\": 1, \n",
            "    \"module_depth\": -1, \n",
            "    \"top_modules\": 1, \n",
            "    \"detailed\": true, \n",
            "    \"output_file\": null\n",
            "}\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   fp16_enabled ................. False\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   global_rank .................. 0\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 1\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   gradient_clipping ............ 0.0\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   graph_harvesting ............. False\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   loss_scale ................... 1.0\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   memory_breakdown ............. False\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   mics_shard_size .............. -1\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   nebula_config ................ {\n",
            "    \"enabled\": false, \n",
            "    \"persistent_storage_path\": null, \n",
            "    \"persistent_time_interval\": 100, \n",
            "    \"num_of_version_in_retention\": 2, \n",
            "    \"enable_nebula_load\": true, \n",
            "    \"load_path\": null\n",
            "}\n",
            "[2024-08-23 13:48:51,910] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   optimizer_name ............... None\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   optimizer_params ............. None\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   pld_enabled .................. False\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   pld_params ................... False\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   prescale_gradients ........... False\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   scheduler_name ............... None\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   scheduler_params ............. None\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   sparse_attention ............. None\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   steps_per_print .............. inf\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   train_batch_size ............. 16\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  16\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   use_node_local_storage ....... False\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   weight_quantization_config ... None\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   world_size ................... 1\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  True\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=200000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   zero_enabled ................. True\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True\n",
            "[2024-08-23 13:48:51,911] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 2\n",
            "[2024-08-23 13:48:51,912] [INFO] [config.py:986:print_user_config]   json = {\n",
            "    \"bf16\": {\n",
            "        \"enabled\": true, \n",
            "        \"auto_cast\": true\n",
            "    }, \n",
            "    \"zero_optimization\": {\n",
            "        \"stage\": 2, \n",
            "        \"allgather_partitions\": true, \n",
            "        \"allgather_bucket_size\": 2.000000e+08, \n",
            "        \"overlap_comm\": true, \n",
            "        \"reduce_scatter\": true, \n",
            "        \"reduce_bucket_size\": 2.000000e+08, \n",
            "        \"contiguous_gradients\": true, \n",
            "        \"sub_group_size\": 1.000000e+09\n",
            "    }, \n",
            "    \"gradient_accumulation_steps\": 1, \n",
            "    \"train_batch_size\": 16, \n",
            "    \"train_micro_batch_size_per_gpu\": 16, \n",
            "    \"steps_per_print\": inf, \n",
            "    \"wall_clock_breakdown\": false, \n",
            "    \"fp16\": {\n",
            "        \"enabled\": false\n",
            "    }, \n",
            "    \"zero_allow_untested_optimizer\": true\n",
            "}\n",
            "99it [09:01,  5.51s/it]\titers: 100, epoch: 1 | loss: 0.0150489\n",
            "\tspeed: 5.5155s/iter; left time: 6624.1434s\n",
            "199it [18:15,  5.54s/it]\titers: 200, epoch: 1 | loss: 0.0084836\n",
            "\tspeed: 5.5374s/iter; left time: 6096.7015s\n",
            "260it [23:52,  5.51s/it]\n",
            "Epoch: 1 cost time: 1432.5164573192596\n",
            "37it [01:35,  2.59s/it]\n",
            "75it [03:13,  2.58s/it]\n",
            "Epoch: 1 | Train Loss: 0.0118436 Vali Loss: 0.1440129 Test Loss: 0.9993960 MAE Loss: 0.8028995\n",
            "lr = 0.0000040000\n",
            "Updating learning rate to 4.000000000000002e-06\n",
            "99it [09:06,  5.55s/it]\titers: 100, epoch: 2 | loss: 0.0214608\n",
            "\tspeed: 11.8702s/iter; left time: 11169.8136s\n",
            "199it [18:20,  5.53s/it]\titers: 200, epoch: 2 | loss: 0.0043694\n",
            "\tspeed: 5.5364s/iter; left time: 4656.1356s\n",
            "260it [23:57,  5.53s/it]\n",
            "Epoch: 2 cost time: 1437.8522696495056\n",
            "37it [01:35,  2.59s/it]\n",
            "75it [03:13,  2.58s/it]\n",
            "Epoch: 2 | Train Loss: 0.0090505 Vali Loss: 0.0377278 Test Loss: 0.4088415 MAE Loss: 0.5038851\n",
            "Updating learning rate to 2.000000000000001e-06\n",
            "99it [09:05,  5.53s/it]\titers: 100, epoch: 3 | loss: 0.0021151\n",
            "\tspeed: 11.9712s/iter; left time: 8152.3638s\n",
            "199it [18:18,  5.55s/it]\titers: 200, epoch: 3 | loss: 0.0020587\n",
            "\tspeed: 5.5320s/iter; left time: 3214.0942s\n",
            "260it [23:56,  5.52s/it]\n",
            "Epoch: 3 cost time: 1436.4246950149536\n",
            "37it [01:35,  2.59s/it]\n",
            "75it [03:13,  2.58s/it]\n",
            "Epoch: 3 | Train Loss: 0.0037229 Vali Loss: 0.0213224 Test Loss: 0.2388466 MAE Loss: 0.3825946\n",
            "Updating learning rate to 1.0000000000000006e-06\n",
            "99it [09:05,  5.52s/it]\titers: 100, epoch: 4 | loss: 0.0026111\n",
            "\tspeed: 11.9475s/iter; left time: 5029.8805s\n",
            "199it [18:19,  5.53s/it]\titers: 200, epoch: 4 | loss: 0.0009633\n",
            "\tspeed: 5.5350s/iter; left time: 1776.7262s\n",
            "260it [23:57,  5.53s/it]\n",
            "Epoch: 4 cost time: 1437.6143527030945\n",
            "37it [01:35,  2.59s/it]\n",
            "75it [03:13,  2.58s/it]\n",
            "Epoch: 4 | Train Loss: 0.0029411 Vali Loss: 0.0168933 Test Loss: 0.1935694 MAE Loss: 0.3430173\n",
            "Updating learning rate to 5.000000000000003e-07\n",
            "99it [09:06,  5.53s/it]\titers: 100, epoch: 5 | loss: 0.0037614\n",
            "\tspeed: 12.3955s/iter; left time: 1995.6679s\n",
            "199it [18:18,  5.55s/it]\titers: 200, epoch: 5 | loss: 0.0014775\n",
            "\tspeed: 5.5254s/iter; left time: 337.0501s\n",
            "260it [23:56,  5.53s/it]\n",
            "Epoch: 5 cost time: 1436.686633348465\n",
            "37it [01:35,  2.59s/it]\n",
            "75it [03:13,  2.58s/it]\n",
            "Epoch: 5 | Train Loss: 0.0028911 Vali Loss: 0.0158966 Test Loss: 0.1761321 MAE Loss: 0.3239320\n",
            "Updating learning rate to 2.5000000000000015e-07\n",
            "0it [00:00, ?it/s]batch_y_mark torch.Size([16, 65, 3])\n",
            "[47.005    46.6325   47.04     48.7725   47.7625   47.185    46.6975\n",
            " 47.1175   47.18     47.4875   47.81     48.505    48.837498 48.9225\n",
            " 49.25     50.025   ]\n",
            "------------ 0    2022-03-18\n",
            "1    2022-03-19\n",
            "2    2022-03-20\n",
            "3    2022-03-21\n",
            "4    2022-03-22\n",
            "5    2022-03-25\n",
            "6    2022-03-26\n",
            "7    2022-03-27\n",
            "8    2022-03-28\n",
            "9    2022-03-29\n",
            "10   2022-04-01\n",
            "11   2022-04-02\n",
            "12   2022-04-03\n",
            "13   2022-04-04\n",
            "14   2022-04-05\n",
            "15   2022-04-08\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "1it [00:02,  3.00s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[49.874996 50.155    49.7375   49.7175   49.8075   49.8125   50.7825\n",
            " 50.965    51.1325   51.87     51.79     51.32     51.075    51.1525\n",
            " 50.167496 52.630005]\n",
            "------------ 0    2022-04-09\n",
            "1    2022-04-10\n",
            "2    2022-04-11\n",
            "3    2022-04-12\n",
            "4    2022-04-15\n",
            "5    2022-04-16\n",
            "6    2022-04-17\n",
            "7    2022-04-18\n",
            "8    2022-04-22\n",
            "9    2022-04-23\n",
            "10   2022-04-24\n",
            "11   2022-04-25\n",
            "12   2022-04-26\n",
            "13   2022-04-29\n",
            "14   2022-04-30\n",
            "15   2022-05-01\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "2it [00:05,  2.72s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[52.2875   52.9375   52.12     50.715    50.725002 50.18     49.295\n",
            " 46.43     47.165    47.73     47.52     47.25     45.7725   46.65\n",
            " 45.695    44.915   ]\n",
            "------------ 0    2022-05-02\n",
            "1    2022-05-03\n",
            "2    2022-05-06\n",
            "3    2022-05-07\n",
            "4    2022-05-08\n",
            "5    2022-05-09\n",
            "6    2022-05-10\n",
            "7    2022-05-13\n",
            "8    2022-05-14\n",
            "9    2022-05-15\n",
            "10   2022-05-16\n",
            "11   2022-05-17\n",
            "12   2022-05-20\n",
            "13   2022-05-21\n",
            "14   2022-05-22\n",
            "15   2022-05-23\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "3it [00:08,  2.64s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[44.7425 44.5575 44.345  44.575  43.7675 43.325  44.91   45.635  46.305\n",
            " 47.5375 48.145  48.7025 48.5475 48.5375 48.185  48.4725]\n",
            "------------ 0    2022-05-24\n",
            "1    2022-05-28\n",
            "2    2022-05-29\n",
            "3    2022-05-30\n",
            "4    2022-05-31\n",
            "5    2022-06-03\n",
            "6    2022-06-04\n",
            "7    2022-06-05\n",
            "8    2022-06-06\n",
            "9    2022-06-07\n",
            "10   2022-06-10\n",
            "11   2022-06-11\n",
            "12   2022-06-12\n",
            "13   2022-06-13\n",
            "14   2022-06-14\n",
            "15   2022-06-17\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "4it [00:10,  2.60s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[49.612495 49.4675   49.865    49.695    49.645    48.8925   49.949997\n",
            " 49.934998 49.479996 50.3875   50.6825   51.1025   51.0575   50.005\n",
            " 50.31     50.8075  ]\n",
            "------------ 0    2022-06-18\n",
            "1    2022-06-19\n",
            "2    2022-06-20\n",
            "3    2022-06-21\n",
            "4    2022-06-24\n",
            "5    2022-06-25\n",
            "6    2022-06-26\n",
            "7    2022-06-27\n",
            "8    2022-06-28\n",
            "9    2022-07-01\n",
            "10   2022-07-02\n",
            "11   2022-07-03\n",
            "12   2022-07-05\n",
            "13   2022-07-08\n",
            "14   2022-07-09\n",
            "15   2022-07-10\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "5it [00:13,  2.59s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[50.4375   50.825    51.3025   51.125    50.8375   51.415005 50.6475\n",
            " 51.805    52.21     52.1675   51.755    51.935    52.42     52.195\n",
            " 53.26     52.1075  ]\n",
            "------------ 0    2022-07-11\n",
            "1    2022-07-12\n",
            "2    2022-07-15\n",
            "3    2022-07-16\n",
            "4    2022-07-17\n",
            "5    2022-07-18\n",
            "6    2022-07-19\n",
            "7    2022-07-22\n",
            "8    2022-07-23\n",
            "9    2022-07-24\n",
            "10   2022-07-25\n",
            "11   2022-07-26\n",
            "12   2022-07-29\n",
            "13   2022-07-30\n",
            "14   2022-07-31\n",
            "15   2022-08-01\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "6it [00:15,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[51.005005 48.335    49.25     49.76     50.8575   50.2475   50.12\n",
            " 52.2425   50.6875   50.435    51.625    52.5875   52.59     53.16\n",
            " 53.115    50.66    ]\n",
            "------------ 0    2022-08-02\n",
            "1    2022-08-05\n",
            "2    2022-08-06\n",
            "3    2022-08-07\n",
            "4    2022-08-08\n",
            "5    2022-08-09\n",
            "6    2022-08-12\n",
            "7    2022-08-13\n",
            "8    2022-08-14\n",
            "9    2022-08-15\n",
            "10   2022-08-16\n",
            "11   2022-08-19\n",
            "12   2022-08-20\n",
            "13   2022-08-21\n",
            "14   2022-08-22\n",
            "15   2022-08-23\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "7it [00:18,  2.56s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[51.6225   51.04     51.382496 52.2525   52.185    51.425    52.2975\n",
            " 53.32     53.314995 53.5425   54.175    55.8975   55.7725   54.6875\n",
            " 54.975    55.174995]\n",
            "------------ 0    2022-08-26\n",
            "1    2022-08-27\n",
            "2    2022-08-28\n",
            "3    2022-08-29\n",
            "4    2022-08-30\n",
            "5    2022-09-03\n",
            "6    2022-09-04\n",
            "7    2022-09-05\n",
            "8    2022-09-06\n",
            "9    2022-09-09\n",
            "10   2022-09-10\n",
            "11   2022-09-11\n",
            "12   2022-09-12\n",
            "13   2022-09-13\n",
            "14   2022-09-16\n",
            "15   2022-09-17\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "8it [00:20,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[55.6925   55.24     54.4325   54.68     54.42     55.2575   54.9725\n",
            " 54.705    55.9925   56.1475   54.74     55.204998 56.7525   56.765\n",
            " 56.1      56.757504]\n",
            "------------ 0    2022-09-18\n",
            "1    2022-09-19\n",
            "2    2022-09-20\n",
            "3    2022-09-23\n",
            "4    2022-09-24\n",
            "5    2022-09-25\n",
            "6    2022-09-26\n",
            "7    2022-09-27\n",
            "8    2022-09-30\n",
            "9    2022-10-01\n",
            "10   2022-10-02\n",
            "11   2022-10-03\n",
            "12   2022-10-04\n",
            "13   2022-10-07\n",
            "14   2022-10-08\n",
            "15   2022-10-09\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "9it [00:23,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[57.5225   59.0525   58.967503 58.83     58.5925   58.819996 59.1025\n",
            " 60.1275   59.99     60.794994 60.895    61.645    62.262497 60.8225\n",
            " 60.815    62.19    ]\n",
            "------------ 0    2022-10-10\n",
            "1    2022-10-11\n",
            "2    2022-10-14\n",
            "3    2022-10-15\n",
            "4    2022-10-16\n",
            "5    2022-10-17\n",
            "6    2022-10-18\n",
            "7    2022-10-21\n",
            "8    2022-10-22\n",
            "9    2022-10-23\n",
            "10   2022-10-24\n",
            "11   2022-10-25\n",
            "12   2022-10-28\n",
            "13   2022-10-29\n",
            "14   2022-10-30\n",
            "15   2022-10-31\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "10it [00:25,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[63.955    64.375    64.2825   64.310005 64.8575   65.035    65.55\n",
            " 65.49     66.1175   65.66     66.44     66.775    66.5725   65.7975\n",
            " 65.5025   65.445   ]\n",
            "------------ 0    2022-11-01\n",
            "1    2022-11-04\n",
            "2    2022-11-05\n",
            "3    2022-11-06\n",
            "4    2022-11-07\n",
            "5    2022-11-08\n",
            "6    2022-11-11\n",
            "7    2022-11-12\n",
            "8    2022-11-13\n",
            "9    2022-11-14\n",
            "10   2022-11-15\n",
            "11   2022-11-18\n",
            "12   2022-11-19\n",
            "13   2022-11-20\n",
            "14   2022-11-21\n",
            "15   2022-11-22\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "11it [00:28,  2.54s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[66.5925   66.0725   66.96     66.8125   66.04001  64.8625   65.435\n",
            " 66.395    67.677505 66.73001  67.12     67.6925   67.865    68.7875\n",
            " 69.965    70.1025  ]\n",
            "------------ 0    2022-11-25\n",
            "1    2022-11-26\n",
            "2    2022-11-27\n",
            "3    2022-11-29\n",
            "4    2022-12-02\n",
            "5    2022-12-03\n",
            "6    2022-12-04\n",
            "7    2022-12-05\n",
            "8    2022-12-06\n",
            "9    2022-12-09\n",
            "10   2022-12-10\n",
            "11   2022-12-11\n",
            "12   2022-12-12\n",
            "13   2022-12-13\n",
            "14   2022-12-16\n",
            "15   2022-12-17\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "12it [00:30,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[69.935    70.005005 69.86     71.       71.0675   72.4775   72.45\n",
            " 72.88     73.4125   75.0875   74.3575   74.95     74.5975   75.7975\n",
            " 77.4075   77.5825  ]\n",
            "------------ 0    2022-12-18\n",
            "1    2022-12-19\n",
            "2    2022-12-20\n",
            "3    2022-12-23\n",
            "4    2022-12-24\n",
            "5    2022-12-26\n",
            "6    2022-12-27\n",
            "7    2022-12-30\n",
            "8    2022-12-31\n",
            "9    2022-01-02\n",
            "10   2022-01-03\n",
            "11   2022-01-06\n",
            "12   2022-01-07\n",
            "13   2022-01-08\n",
            "14   2022-01-09\n",
            "15   2022-01-10\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "13it [00:33,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[79.24   78.17   77.835  78.81   79.6825 79.1425 79.425  79.8075 79.5775\n",
            " 77.2375 79.4225 81.085  80.9675 77.3775 77.165  79.7125]\n",
            "------------ 0    2022-01-13\n",
            "1    2022-01-14\n",
            "2    2022-01-15\n",
            "3    2022-01-16\n",
            "4    2022-01-17\n",
            "5    2022-01-21\n",
            "6    2022-01-22\n",
            "7    2022-01-23\n",
            "8    2022-01-24\n",
            "9    2022-01-27\n",
            "10   2022-01-28\n",
            "11   2022-01-29\n",
            "12   2022-01-30\n",
            "13   2022-01-31\n",
            "14   2022-02-03\n",
            "15   2022-02-04\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "14it [00:36,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[80.3625   81.3025   80.0075   80.3875   79.9025   81.8      81.2175\n",
            " 81.2375   79.75     80.905    80.075    78.2625   74.545    72.02\n",
            " 73.1625   68.380005]\n",
            "------------ 0    2022-02-05\n",
            "1    2022-02-06\n",
            "2    2022-02-07\n",
            "3    2022-02-10\n",
            "4    2022-02-11\n",
            "5    2022-02-12\n",
            "6    2022-02-13\n",
            "7    2022-02-14\n",
            "8    2022-02-18\n",
            "9    2022-02-19\n",
            "10   2022-02-20\n",
            "11   2022-02-21\n",
            "12   2022-02-24\n",
            "13   2022-02-25\n",
            "14   2022-02-26\n",
            "15   2022-02-27\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "15it [00:38,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[68.34   74.7025 72.33   75.685  73.23   72.2575 66.5425 71.335  68.8575\n",
            " 62.0575 69.4925 60.5525 63.215  61.6675 61.195  57.31  ]\n",
            "------------ 0    2022-02-28\n",
            "1    2022-03-03\n",
            "2    2022-03-04\n",
            "3    2022-03-05\n",
            "4    2022-03-06\n",
            "5    2022-03-07\n",
            "6    2022-03-10\n",
            "7    2022-03-11\n",
            "8    2022-03-12\n",
            "9    2022-03-13\n",
            "10   2022-03-14\n",
            "11   2022-03-17\n",
            "12   2022-03-18\n",
            "13   2022-03-19\n",
            "14   2022-03-20\n",
            "15   2022-03-21\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "16it [00:41,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[56.0925   61.719997 61.38     64.61     61.935    63.7025   63.5725\n",
            " 60.227497 61.2325   60.3525   65.6175   64.8575   66.5175   66.9975\n",
            " 68.3125   71.7625  ]\n",
            "------------ 0    2022-03-24\n",
            "1    2022-03-25\n",
            "2    2022-03-26\n",
            "3    2022-03-27\n",
            "4    2022-03-28\n",
            "5    2022-03-31\n",
            "6    2022-04-01\n",
            "7    2022-04-02\n",
            "8    2022-04-03\n",
            "9    2022-04-04\n",
            "10   2022-04-07\n",
            "11   2022-04-08\n",
            "12   2022-04-09\n",
            "13   2022-04-10\n",
            "14   2022-04-14\n",
            "15   2022-04-15\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "17it [00:43,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[71.1075  71.6725  70.7     69.2325  67.09251 69.025   68.7575  70.7425\n",
            " 70.7925  69.645   71.9325  73.45    72.2675  73.29    74.39    75.1575 ]\n",
            "------------ 0    2022-04-16\n",
            "1    2022-04-17\n",
            "2    2022-04-18\n",
            "3    2022-04-21\n",
            "4    2022-04-22\n",
            "5    2022-04-23\n",
            "6    2022-04-24\n",
            "7    2022-04-25\n",
            "8    2022-04-28\n",
            "9    2022-04-29\n",
            "10   2022-04-30\n",
            "11   2022-05-01\n",
            "12   2022-05-02\n",
            "13   2022-05-05\n",
            "14   2022-05-06\n",
            "15   2022-05-07\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "18it [00:46,  2.54s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[75.935  77.5325 78.7525 77.8525 76.9125 77.385  76.9275 78.74   78.285\n",
            " 79.8075 79.2125 79.7225 79.1825 79.5275 79.5625 79.485 ]\n",
            "------------ 0    2022-05-08\n",
            "1    2022-05-09\n",
            "2    2022-05-12\n",
            "3    2022-05-13\n",
            "4    2022-05-14\n",
            "5    2022-05-15\n",
            "6    2022-05-16\n",
            "7    2022-05-19\n",
            "8    2022-05-20\n",
            "9    2022-05-21\n",
            "10   2022-05-22\n",
            "11   2022-05-23\n",
            "12   2022-05-27\n",
            "13   2022-05-28\n",
            "14   2022-05-29\n",
            "15   2022-05-30\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "19it [00:48,  2.54s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[80.4625  80.835   81.28    80.58    82.875   83.365   85.9975  88.20999\n",
            " 83.975   84.7     85.7475  88.02    87.8975  87.9325  87.43    89.7175 ]\n",
            "------------ 0    2022-06-02\n",
            "1    2022-06-03\n",
            "2    2022-06-04\n",
            "3    2022-06-05\n",
            "4    2022-06-06\n",
            "5    2022-06-09\n",
            "6    2022-06-10\n",
            "7    2022-06-11\n",
            "8    2022-06-12\n",
            "9    2022-06-13\n",
            "10   2022-06-16\n",
            "11   2022-06-17\n",
            "12   2022-06-18\n",
            "13   2022-06-19\n",
            "14   2022-06-20\n",
            "15   2022-06-23\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "20it [00:51,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[91.6325  90.015   91.21    88.4075  90.445   91.2     91.0275  91.0275\n",
            " 93.4625  93.1725  95.3425  95.7525  95.92    95.4775  97.05751 97.72499]\n",
            "------------ 0    2022-06-24\n",
            "1    2022-06-25\n",
            "2    2022-06-26\n",
            "3    2022-06-27\n",
            "4    2022-06-30\n",
            "5    2022-07-01\n",
            "6    2022-07-02\n",
            "7    2022-07-03\n",
            "8    2022-07-07\n",
            "9    2022-07-08\n",
            "10   2022-07-09\n",
            "11   2022-07-10\n",
            "12   2022-07-11\n",
            "13   2022-07-14\n",
            "14   2022-07-15\n",
            "15   2022-07-16\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "21it [00:53,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[ 96.5225  96.3275  98.3575  97.      97.2725  92.845   92.615   94.81\n",
            "  93.2525  95.04    96.19   106.26   108.9375 109.665  110.0625 113.9025]\n",
            "------------ 0    2022-07-17\n",
            "1    2022-07-18\n",
            "2    2022-07-21\n",
            "3    2022-07-22\n",
            "4    2022-07-23\n",
            "5    2022-07-24\n",
            "6    2022-07-25\n",
            "7    2022-07-28\n",
            "8    2022-07-29\n",
            "9    2022-07-30\n",
            "10   2022-07-31\n",
            "11   2022-08-01\n",
            "12   2022-08-04\n",
            "13   2022-08-05\n",
            "14   2022-08-06\n",
            "15   2022-08-07\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "22it [00:56,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[111.1125   112.7275   109.375    113.009995 115.01     114.9075\n",
            " 114.6075   115.5625   115.7075   118.275    124.37     125.8575\n",
            " 124.825    126.5225   125.01     124.8075  ]\n",
            "------------ 0    2022-08-08\n",
            "1    2022-08-11\n",
            "2    2022-08-12\n",
            "3    2022-08-13\n",
            "4    2022-08-14\n",
            "5    2022-08-15\n",
            "6    2022-08-18\n",
            "7    2022-08-19\n",
            "8    2022-08-20\n",
            "9    2022-08-21\n",
            "10   2022-08-22\n",
            "11   2022-08-25\n",
            "12   2022-08-26\n",
            "13   2022-08-27\n",
            "14   2022-08-28\n",
            "15   2022-08-29\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "23it [00:59,  2.56s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[129.04     134.18     131.4      120.88     120.96     112.82\n",
            " 117.32     113.49     112.       115.36     115.54     112.12999\n",
            " 110.34     106.84     110.08     111.810005]\n",
            "------------ 0    2022-09-01\n",
            "1    2022-09-02\n",
            "2    2022-09-03\n",
            "3    2022-09-04\n",
            "4    2022-09-05\n",
            "5    2022-09-09\n",
            "6    2022-09-10\n",
            "7    2022-09-11\n",
            "8    2022-09-12\n",
            "9    2022-09-15\n",
            "10   2022-09-16\n",
            "11   2022-09-17\n",
            "12   2022-09-18\n",
            "13   2022-09-19\n",
            "14   2022-09-22\n",
            "15   2022-09-23\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "24it [01:01,  2.56s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[107.12     108.22     112.28001  114.96     114.08999  115.81\n",
            " 116.79001  113.02     116.5      113.159996 115.08     114.97\n",
            " 116.97     124.399994 121.1      121.19    ]\n",
            "------------ 0    2022-09-24\n",
            "1    2022-09-25\n",
            "2    2022-09-26\n",
            "3    2022-09-29\n",
            "4    2022-09-30\n",
            "5    2022-10-01\n",
            "6    2022-10-02\n",
            "7    2022-10-03\n",
            "8    2022-10-06\n",
            "9    2022-10-07\n",
            "10   2022-10-08\n",
            "11   2022-10-09\n",
            "12   2022-10-10\n",
            "13   2022-10-13\n",
            "14   2022-10-14\n",
            "15   2022-10-15\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "25it [01:04,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[120.70999 119.02    115.98    117.51    116.87    115.75    115.04\n",
            " 115.05    116.6     111.2     115.32    108.86    108.77    110.44\n",
            " 114.95    119.03   ]\n",
            "------------ 0    2022-10-16\n",
            "1    2022-10-17\n",
            "2    2022-10-20\n",
            "3    2022-10-21\n",
            "4    2022-10-22\n",
            "5    2022-10-23\n",
            "6    2022-10-24\n",
            "7    2022-10-27\n",
            "8    2022-10-28\n",
            "9    2022-10-29\n",
            "10   2022-10-30\n",
            "11   2022-10-31\n",
            "12   2022-11-03\n",
            "13   2022-11-04\n",
            "14   2022-11-05\n",
            "15   2022-11-06\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "26it [01:06,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[118.689995 116.32001  115.97001  119.49     119.21     119.26\n",
            " 120.3      119.39     118.03     118.64     117.33999  113.85\n",
            " 115.17     116.03     116.59     119.05    ]\n",
            "------------ 0    2022-11-07\n",
            "1    2022-11-10\n",
            "2    2022-11-11\n",
            "3    2022-11-12\n",
            "4    2022-11-13\n",
            "5    2022-11-14\n",
            "6    2022-11-17\n",
            "7    2022-11-18\n",
            "8    2022-11-19\n",
            "9    2022-11-20\n",
            "10   2022-11-21\n",
            "11   2022-11-24\n",
            "12   2022-11-25\n",
            "13   2022-11-26\n",
            "14   2022-11-28\n",
            "15   2022-12-01\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "27it [01:09,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[122.72     123.08     122.94001  122.25     123.75     124.38\n",
            " 121.78     123.24     122.409996 121.78     127.88     127.81\n",
            " 128.7      126.66001  128.23     131.88    ]\n",
            "------------ 0    2022-12-02\n",
            "1    2022-12-03\n",
            "2    2022-12-04\n",
            "3    2022-12-05\n",
            "4    2022-12-08\n",
            "5    2022-12-09\n",
            "6    2022-12-10\n",
            "7    2022-12-11\n",
            "8    2022-12-12\n",
            "9    2022-12-15\n",
            "10   2022-12-16\n",
            "11   2022-12-17\n",
            "12   2022-12-18\n",
            "13   2022-12-19\n",
            "14   2022-12-22\n",
            "15   2022-12-23\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "28it [01:11,  2.55s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[130.96    131.97    136.69    134.87    133.72    132.69002 129.41\n",
            " 131.01    126.6     130.92    132.05    128.98    128.8     130.89\n",
            " 128.91    127.14   ]\n",
            "------------ 0    2022-12-24\n",
            "1    2022-12-25\n",
            "2    2022-12-29\n",
            "3    2022-12-30\n",
            "4    2022-12-31\n",
            "5    2023-01-01\n",
            "6    2022-01-04\n",
            "7    2022-01-05\n",
            "8    2022-01-06\n",
            "9    2022-01-07\n",
            "10   2022-01-08\n",
            "11   2022-01-11\n",
            "12   2022-01-12\n",
            "13   2022-01-13\n",
            "14   2022-01-14\n",
            "15   2022-01-15\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "29it [01:14,  2.56s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[127.83001 132.03    136.87    139.07    142.92    143.16    142.06001\n",
            " 137.09    131.96002 134.14    134.99    133.94    137.39    136.76\n",
            " 136.91    136.01   ]\n",
            "------------ 0    2022-01-19\n",
            "1    2022-01-20\n",
            "2    2022-01-21\n",
            "3    2022-01-22\n",
            "4    2022-01-25\n",
            "5    2022-01-26\n",
            "6    2022-01-27\n",
            "7    2022-01-28\n",
            "8    2022-01-29\n",
            "9    2022-02-01\n",
            "10   2022-02-02\n",
            "11   2022-02-03\n",
            "12   2022-02-04\n",
            "13   2022-02-05\n",
            "14   2022-02-08\n",
            "15   2022-02-09\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "30it [01:16,  2.56s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[135.39    135.13    135.37    133.19    130.84001 129.71    129.87\n",
            " 126.      125.86    125.35    120.99    121.26    127.79    125.12\n",
            " 122.06    120.13   ]\n",
            "------------ 0    2022-02-10\n",
            "1    2022-02-11\n",
            "2    2022-02-12\n",
            "3    2022-02-16\n",
            "4    2022-02-17\n",
            "5    2022-02-18\n",
            "6    2022-02-19\n",
            "7    2022-02-22\n",
            "8    2022-02-23\n",
            "9    2022-02-24\n",
            "10   2022-02-25\n",
            "11   2022-02-26\n",
            "12   2022-03-01\n",
            "13   2022-03-02\n",
            "14   2022-03-03\n",
            "15   2022-03-04\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "31it [01:19,  2.57s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[121.42     116.36     121.090004 119.979996 121.96     121.02999\n",
            " 123.990005 125.56999  124.76     120.53     119.99     123.39\n",
            " 122.54     120.09     120.58999  121.21001 ]\n",
            "------------ 0    2022-03-05\n",
            "1    2022-03-08\n",
            "2    2022-03-09\n",
            "3    2022-03-10\n",
            "4    2022-03-11\n",
            "5    2022-03-12\n",
            "6    2022-03-15\n",
            "7    2022-03-16\n",
            "8    2022-03-17\n",
            "9    2022-03-18\n",
            "10   2022-03-19\n",
            "11   2022-03-22\n",
            "12   2022-03-23\n",
            "13   2022-03-24\n",
            "14   2022-03-25\n",
            "15   2022-03-26\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "32it [01:22,  2.57s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[121.39 119.9  122.15 123.   125.9  126.21 127.9  130.36 133.   131.24\n",
            " 134.43 132.03 134.5  134.16 134.84 133.11]\n",
            "------------ 0    2022-03-29\n",
            "1    2022-03-30\n",
            "2    2022-03-31\n",
            "3    2022-04-01\n",
            "4    2022-04-05\n",
            "5    2022-04-06\n",
            "6    2022-04-07\n",
            "7    2022-04-08\n",
            "8    2022-04-09\n",
            "9    2022-04-12\n",
            "10   2022-04-13\n",
            "11   2022-04-14\n",
            "12   2022-04-15\n",
            "13   2022-04-16\n",
            "14   2022-04-19\n",
            "15   2022-04-20\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "33it [01:24,  2.57s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[133.5  131.94 134.32 134.72 134.39 133.58 133.48 131.46 132.54 127.85\n",
            " 128.1  129.74 130.21 126.85 125.91 122.77]\n",
            "------------ 0    2022-04-21\n",
            "1    2022-04-22\n",
            "2    2022-04-23\n",
            "3    2022-04-26\n",
            "4    2022-04-27\n",
            "5    2022-04-28\n",
            "6    2022-04-29\n",
            "7    2022-04-30\n",
            "8    2022-05-03\n",
            "9    2022-05-04\n",
            "10   2022-05-05\n",
            "11   2022-05-06\n",
            "12   2022-05-07\n",
            "13   2022-05-10\n",
            "14   2022-05-11\n",
            "15   2022-05-12\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "34it [01:27,  2.57s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[124.97    127.45    126.26999 124.85    124.69    127.31    125.43\n",
            " 127.1     126.9     126.85    125.28001 124.61    124.27999 125.06\n",
            " 123.54    125.89   ]\n",
            "------------ 0    2022-05-13\n",
            "1    2022-05-14\n",
            "2    2022-05-17\n",
            "3    2022-05-18\n",
            "4    2022-05-19\n",
            "5    2022-05-20\n",
            "6    2022-05-21\n",
            "7    2022-05-24\n",
            "8    2022-05-25\n",
            "9    2022-05-26\n",
            "10   2022-05-27\n",
            "11   2022-05-28\n",
            "12   2022-06-01\n",
            "13   2022-06-02\n",
            "14   2022-06-03\n",
            "15   2022-06-04\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "35it [01:29,  2.57s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[125.9     126.73999 127.13    126.11    127.35    130.48    129.64\n",
            " 130.15    131.79    130.46    132.3     133.98    133.7     133.41\n",
            " 133.11    134.78   ]\n",
            "------------ 0    2022-06-07\n",
            "1    2022-06-08\n",
            "2    2022-06-09\n",
            "3    2022-06-10\n",
            "4    2022-06-11\n",
            "5    2022-06-14\n",
            "6    2022-06-15\n",
            "7    2022-06-16\n",
            "8    2022-06-17\n",
            "9    2022-06-18\n",
            "10   2022-06-21\n",
            "11   2022-06-22\n",
            "12   2022-06-23\n",
            "13   2022-06-24\n",
            "14   2022-06-25\n",
            "15   2022-06-28\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "36it [01:32,  2.57s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[136.33    136.96    137.27002 139.96002 142.02    144.57    143.24002\n",
            " 145.11002 144.50002 145.64001 149.15001 148.48    146.39001 142.45\n",
            " 146.15    145.40001]\n",
            "------------ 0    2022-06-29\n",
            "1    2022-06-30\n",
            "2    2022-07-01\n",
            "3    2022-07-02\n",
            "4    2022-07-06\n",
            "5    2022-07-07\n",
            "6    2022-07-08\n",
            "7    2022-07-09\n",
            "8    2022-07-12\n",
            "9    2022-07-13\n",
            "10   2022-07-14\n",
            "11   2022-07-15\n",
            "12   2022-07-16\n",
            "13   2022-07-19\n",
            "14   2022-07-20\n",
            "15   2022-07-21\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "37it [01:34,  2.57s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[146.8     148.56001 148.99    146.77    144.98    145.64001 145.86\n",
            " 145.52002 147.36002 146.95001 147.06    146.14001 146.09    145.6\n",
            " 145.86    148.89001]\n",
            "------------ 0    2022-07-22\n",
            "1    2022-07-23\n",
            "2    2022-07-26\n",
            "3    2022-07-27\n",
            "4    2022-07-28\n",
            "5    2022-07-29\n",
            "6    2022-07-30\n",
            "7    2022-08-02\n",
            "8    2022-08-03\n",
            "9    2022-08-04\n",
            "10   2022-08-05\n",
            "11   2022-08-06\n",
            "12   2022-08-09\n",
            "13   2022-08-10\n",
            "14   2022-08-11\n",
            "15   2022-08-12\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "38it [01:37,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[149.10002 151.12    150.19    146.36    146.7     148.19002 149.71002\n",
            " 149.62001 148.36002 147.54001 148.60002 153.12    151.83    152.51001\n",
            " 153.65001 154.30002]\n",
            "------------ 0    2022-08-13\n",
            "1    2022-08-16\n",
            "2    2022-08-17\n",
            "3    2022-08-18\n",
            "4    2022-08-19\n",
            "5    2022-08-20\n",
            "6    2022-08-23\n",
            "7    2022-08-24\n",
            "8    2022-08-25\n",
            "9    2022-08-26\n",
            "10   2022-08-27\n",
            "11   2022-08-30\n",
            "12   2022-08-31\n",
            "13   2022-09-01\n",
            "14   2022-09-02\n",
            "15   2022-09-03\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "39it [01:40,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[156.69    155.11    154.07002 148.97002 149.55    148.12001 149.03001\n",
            " 148.79001 146.06    142.94002 143.43001 145.85002 146.83    146.92001\n",
            " 145.37001 141.91   ]\n",
            "------------ 0    2022-09-07\n",
            "1    2022-09-08\n",
            "2    2022-09-09\n",
            "3    2022-09-10\n",
            "4    2022-09-13\n",
            "5    2022-09-14\n",
            "6    2022-09-15\n",
            "7    2022-09-16\n",
            "8    2022-09-17\n",
            "9    2022-09-20\n",
            "10   2022-09-21\n",
            "11   2022-09-22\n",
            "12   2022-09-23\n",
            "13   2022-09-24\n",
            "14   2022-09-27\n",
            "15   2022-09-28\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "40it [01:42,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[142.83002 141.5     142.65001 139.14001 141.11    142.00002 143.29001\n",
            " 142.9     142.81    141.51001 140.91    143.76001 144.84001 146.55002\n",
            " 148.76001 149.26001]\n",
            "------------ 0    2022-09-29\n",
            "1    2022-09-30\n",
            "2    2022-10-01\n",
            "3    2022-10-04\n",
            "4    2022-10-05\n",
            "5    2022-10-06\n",
            "6    2022-10-07\n",
            "7    2022-10-08\n",
            "8    2022-10-11\n",
            "9    2022-10-12\n",
            "10   2022-10-13\n",
            "11   2022-10-14\n",
            "12   2022-10-15\n",
            "13   2022-10-18\n",
            "14   2022-10-19\n",
            "15   2022-10-20\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "41it [01:45,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[149.48    148.69    148.64    149.32    148.85    152.57    149.80002\n",
            " 148.96    150.02    151.49002 150.96    151.28001 150.44002 150.81001\n",
            " 147.92001 147.87   ]\n",
            "------------ 0    2022-10-21\n",
            "1    2022-10-22\n",
            "2    2022-10-25\n",
            "3    2022-10-26\n",
            "4    2022-10-27\n",
            "5    2022-10-28\n",
            "6    2022-10-29\n",
            "7    2022-11-01\n",
            "8    2022-11-02\n",
            "9    2022-11-03\n",
            "10   2022-11-04\n",
            "11   2022-11-05\n",
            "12   2022-11-08\n",
            "13   2022-11-09\n",
            "14   2022-11-10\n",
            "15   2022-11-11\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "42it [01:47,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[149.99    150.00002 151.00002 153.49002 157.87001 160.55    161.02\n",
            " 161.41    161.94002 156.81    160.24    165.3     164.77    163.76001\n",
            " 161.84    165.32002]\n",
            "------------ 0    2022-11-12\n",
            "1    2022-11-15\n",
            "2    2022-11-16\n",
            "3    2022-11-17\n",
            "4    2022-11-18\n",
            "5    2022-11-19\n",
            "6    2022-11-22\n",
            "7    2022-11-23\n",
            "8    2022-11-24\n",
            "9    2022-11-26\n",
            "10   2022-11-29\n",
            "11   2022-11-30\n",
            "12   2022-12-01\n",
            "13   2022-12-02\n",
            "14   2022-12-03\n",
            "15   2022-12-06\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "43it [01:50,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[171.18001 175.08    174.56    179.45001 175.74    174.33    179.3\n",
            " 172.26    171.14001 169.75    172.99    175.64001 176.28001 180.33002\n",
            " 179.29    179.38002]\n",
            "------------ 0    2022-12-07\n",
            "1    2022-12-08\n",
            "2    2022-12-09\n",
            "3    2022-12-10\n",
            "4    2022-12-13\n",
            "5    2022-12-14\n",
            "6    2022-12-15\n",
            "7    2022-12-16\n",
            "8    2022-12-17\n",
            "9    2022-12-20\n",
            "10   2022-12-21\n",
            "11   2022-12-22\n",
            "12   2022-12-23\n",
            "13   2022-12-27\n",
            "14   2022-12-28\n",
            "15   2022-12-29\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "44it [01:52,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[178.2     177.57002 182.01001 179.7     174.92    172.00002 172.17001\n",
            " 172.19002 175.08    175.53001 172.19002 173.07002 169.80002 166.23\n",
            " 164.51    162.41002]\n",
            "------------ 0    2022-12-30\n",
            "1    2022-12-31\n",
            "2    2022-01-03\n",
            "3    2022-01-04\n",
            "4    2022-01-05\n",
            "5    2022-01-06\n",
            "6    2022-01-07\n",
            "7    2022-01-10\n",
            "8    2022-01-11\n",
            "9    2022-01-12\n",
            "10   2022-01-13\n",
            "11   2022-01-14\n",
            "12   2022-01-18\n",
            "13   2022-01-19\n",
            "14   2022-01-20\n",
            "15   2022-01-21\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "45it [01:55,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[161.62001 159.78001 159.69002 159.22002 170.33    174.78    174.61\n",
            " 175.84    172.9     172.39    171.66002 174.83002 176.28001 172.12001\n",
            " 168.64    168.88   ]\n",
            "------------ 0    2022-01-24\n",
            "1    2022-01-25\n",
            "2    2022-01-26\n",
            "3    2022-01-27\n",
            "4    2022-01-28\n",
            "5    2022-01-31\n",
            "6    2022-02-01\n",
            "7    2022-02-02\n",
            "8    2022-02-03\n",
            "9    2022-02-04\n",
            "10   2022-02-07\n",
            "11   2022-02-08\n",
            "12   2022-02-09\n",
            "13   2022-02-10\n",
            "14   2022-02-11\n",
            "15   2022-02-14\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "46it [01:58,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[172.79    172.55002 168.88    167.3     164.32002 160.07002 162.74002\n",
            " 164.85002 165.12    163.20001 166.56001 166.23    163.17001 159.3\n",
            " 157.44002 162.95   ]\n",
            "------------ 0    2022-02-15\n",
            "1    2022-02-16\n",
            "2    2022-02-17\n",
            "3    2022-02-18\n",
            "4    2022-02-22\n",
            "5    2022-02-23\n",
            "6    2022-02-24\n",
            "7    2022-02-25\n",
            "8    2022-02-28\n",
            "9    2022-03-01\n",
            "10   2022-03-02\n",
            "11   2022-03-03\n",
            "12   2022-03-04\n",
            "13   2022-03-07\n",
            "14   2022-03-08\n",
            "15   2022-03-09\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "47it [02:00,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[158.52002 154.73    150.62    155.09001 159.59    160.62001 163.98\n",
            " 165.38002 168.82    170.21002 174.07002 174.72    175.60002 178.96\n",
            " 177.77    174.61   ]\n",
            "------------ 0    2022-03-10\n",
            "1    2022-03-11\n",
            "2    2022-03-14\n",
            "3    2022-03-15\n",
            "4    2022-03-16\n",
            "5    2022-03-17\n",
            "6    2022-03-18\n",
            "7    2022-03-21\n",
            "8    2022-03-22\n",
            "9    2022-03-23\n",
            "10   2022-03-24\n",
            "11   2022-03-25\n",
            "12   2022-03-28\n",
            "13   2022-03-29\n",
            "14   2022-03-30\n",
            "15   2022-03-31\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "48it [02:03,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[174.31    178.44002 175.06001 171.83002 172.14001 170.09    165.75002\n",
            " 167.66    170.4     165.29    165.07    167.4     167.23    166.42\n",
            " 161.79001 162.88002]\n",
            "------------ 0    2022-04-01\n",
            "1    2022-04-04\n",
            "2    2022-04-05\n",
            "3    2022-04-06\n",
            "4    2022-04-07\n",
            "5    2022-04-08\n",
            "6    2022-04-11\n",
            "7    2022-04-12\n",
            "8    2022-04-13\n",
            "9    2022-04-14\n",
            "10   2022-04-18\n",
            "11   2022-04-19\n",
            "12   2022-04-20\n",
            "13   2022-04-21\n",
            "14   2022-04-22\n",
            "15   2022-04-25\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "49it [02:05,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[156.80002 156.57    163.64001 157.65    157.96    159.48001 166.02\n",
            " 156.77002 157.28    152.06    154.51001 146.5     142.56001 147.11\n",
            " 145.54001 149.24002]\n",
            "------------ 0    2022-04-26\n",
            "1    2022-04-27\n",
            "2    2022-04-28\n",
            "3    2022-04-29\n",
            "4    2022-05-02\n",
            "5    2022-05-03\n",
            "6    2022-05-04\n",
            "7    2022-05-05\n",
            "8    2022-05-06\n",
            "9    2022-05-09\n",
            "10   2022-05-10\n",
            "11   2022-05-11\n",
            "12   2022-05-12\n",
            "13   2022-05-13\n",
            "14   2022-05-16\n",
            "15   2022-05-17\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "50it [02:08,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[140.82    137.35002 137.59    143.11    140.36002 140.52002 143.78\n",
            " 149.64001 148.84    148.71002 151.21002 145.38002 146.14001 148.71002\n",
            " 147.96002 142.64   ]\n",
            "------------ 0    2022-05-18\n",
            "1    2022-05-19\n",
            "2    2022-05-20\n",
            "3    2022-05-23\n",
            "4    2022-05-24\n",
            "5    2022-05-25\n",
            "6    2022-05-26\n",
            "7    2022-05-27\n",
            "8    2022-05-31\n",
            "9    2022-06-01\n",
            "10   2022-06-02\n",
            "11   2022-06-03\n",
            "12   2022-06-06\n",
            "13   2022-06-07\n",
            "14   2022-06-08\n",
            "15   2022-06-09\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "51it [02:11,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[137.13    131.88    132.76    135.43    130.06    131.56    135.87\n",
            " 135.35    138.27    141.66002 141.66002 137.44002 139.23    136.72\n",
            " 138.93001 141.56001]\n",
            "------------ 0    2022-06-10\n",
            "1    2022-06-13\n",
            "2    2022-06-14\n",
            "3    2022-06-15\n",
            "4    2022-06-16\n",
            "5    2022-06-17\n",
            "6    2022-06-21\n",
            "7    2022-06-22\n",
            "8    2022-06-23\n",
            "9    2022-06-24\n",
            "10   2022-06-27\n",
            "11   2022-06-28\n",
            "12   2022-06-29\n",
            "13   2022-06-30\n",
            "14   2022-07-01\n",
            "15   2022-07-05\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "52it [02:13,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[142.92    146.35    147.04001 144.87001 145.86    145.49002 148.47002\n",
            " 150.17001 147.07002 151.00002 153.04001 155.35    154.09001 152.95001\n",
            " 151.6     156.79001]\n",
            "------------ 0    2022-07-06\n",
            "1    2022-07-07\n",
            "2    2022-07-08\n",
            "3    2022-07-11\n",
            "4    2022-07-12\n",
            "5    2022-07-13\n",
            "6    2022-07-14\n",
            "7    2022-07-15\n",
            "8    2022-07-18\n",
            "9    2022-07-19\n",
            "10   2022-07-20\n",
            "11   2022-07-21\n",
            "12   2022-07-22\n",
            "13   2022-07-25\n",
            "14   2022-07-26\n",
            "15   2022-07-27\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "53it [02:16,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[157.35002 162.51    161.51    160.01001 166.13    165.81001 165.35002\n",
            " 164.87001 164.92    169.24    168.49002 172.1     173.19002 173.03\n",
            " 174.55    174.15   ]\n",
            "------------ 0    2022-07-28\n",
            "1    2022-07-29\n",
            "2    2022-08-01\n",
            "3    2022-08-02\n",
            "4    2022-08-03\n",
            "5    2022-08-04\n",
            "6    2022-08-05\n",
            "7    2022-08-08\n",
            "8    2022-08-09\n",
            "9    2022-08-10\n",
            "10   2022-08-11\n",
            "11   2022-08-12\n",
            "12   2022-08-15\n",
            "13   2022-08-16\n",
            "14   2022-08-17\n",
            "15   2022-08-18\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "54it [02:18,  2.59s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[171.52    167.57002 167.23    167.53    170.03001 163.62    161.38\n",
            " 158.91    157.22    157.96    155.81    154.53001 155.96    154.46002\n",
            " 157.37001 163.43001]\n",
            "------------ 0    2022-08-19\n",
            "1    2022-08-22\n",
            "2    2022-08-23\n",
            "3    2022-08-24\n",
            "4    2022-08-25\n",
            "5    2022-08-26\n",
            "6    2022-08-29\n",
            "7    2022-08-30\n",
            "8    2022-08-31\n",
            "9    2022-09-01\n",
            "10   2022-09-02\n",
            "11   2022-09-06\n",
            "12   2022-09-07\n",
            "13   2022-09-08\n",
            "14   2022-09-09\n",
            "15   2022-09-12\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "55it [02:21,  2.59s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[153.84    155.31    152.37001 150.70001 154.48001 156.90001 153.72002\n",
            " 152.74    150.43001 150.77    151.76    149.84    142.48    138.20001\n",
            " 142.45    146.1    ]\n",
            "------------ 0    2022-09-13\n",
            "1    2022-09-14\n",
            "2    2022-09-15\n",
            "3    2022-09-16\n",
            "4    2022-09-19\n",
            "5    2022-09-20\n",
            "6    2022-09-21\n",
            "7    2022-09-22\n",
            "8    2022-09-23\n",
            "9    2022-09-26\n",
            "10   2022-09-27\n",
            "11   2022-09-28\n",
            "12   2022-09-29\n",
            "13   2022-09-30\n",
            "14   2022-10-03\n",
            "15   2022-10-04\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "56it [02:24,  2.59s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[146.4     145.43001 140.09    140.42001 138.98001 138.34001 142.99\n",
            " 138.38002 142.41    143.75    143.86    143.39    147.27    149.45\n",
            " 152.34001 149.35   ]\n",
            "------------ 0    2022-10-05\n",
            "1    2022-10-06\n",
            "2    2022-10-07\n",
            "3    2022-10-10\n",
            "4    2022-10-11\n",
            "5    2022-10-12\n",
            "6    2022-10-13\n",
            "7    2022-10-14\n",
            "8    2022-10-17\n",
            "9    2022-10-18\n",
            "10   2022-10-19\n",
            "11   2022-10-20\n",
            "12   2022-10-21\n",
            "13   2022-10-24\n",
            "14   2022-10-25\n",
            "15   2022-10-26\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "57it [02:26,  2.59s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[144.8     155.74002 153.34001 150.65    145.03    138.88002 138.38002\n",
            " 138.92    139.5     134.87    146.87    149.70001 148.28    150.04\n",
            " 148.79001 150.72   ]\n",
            "------------ 0    2022-10-27\n",
            "1    2022-10-28\n",
            "2    2022-10-31\n",
            "3    2022-11-01\n",
            "4    2022-11-02\n",
            "5    2022-11-03\n",
            "6    2022-11-04\n",
            "7    2022-11-07\n",
            "8    2022-11-08\n",
            "9    2022-11-09\n",
            "10   2022-11-10\n",
            "11   2022-11-11\n",
            "12   2022-11-14\n",
            "13   2022-11-15\n",
            "14   2022-11-16\n",
            "15   2022-11-17\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "58it [02:29,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[151.29    148.01001 150.18    151.07    148.11    144.22    141.17\n",
            " 148.03001 148.31    147.81    146.63002 142.91002 140.94    142.65001\n",
            " 142.16002 144.49   ]\n",
            "------------ 0    2022-11-18\n",
            "1    2022-11-21\n",
            "2    2022-11-22\n",
            "3    2022-11-23\n",
            "4    2022-11-25\n",
            "5    2022-11-28\n",
            "6    2022-11-29\n",
            "7    2022-11-30\n",
            "8    2022-12-01\n",
            "9    2022-12-02\n",
            "10   2022-12-05\n",
            "11   2022-12-06\n",
            "12   2022-12-07\n",
            "13   2022-12-08\n",
            "14   2022-12-09\n",
            "15   2022-12-12\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "59it [02:31,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[145.47    143.21002 136.5     134.51    132.37    132.3     135.45\n",
            " 132.23    131.86    130.03    126.03999 129.61    129.93001 125.07\n",
            " 126.35999 125.02   ]\n",
            "------------ 0    2022-12-13\n",
            "1    2022-12-14\n",
            "2    2022-12-15\n",
            "3    2022-12-16\n",
            "4    2022-12-19\n",
            "5    2022-12-20\n",
            "6    2022-12-21\n",
            "7    2022-12-22\n",
            "8    2022-12-23\n",
            "9    2022-12-27\n",
            "10   2022-12-28\n",
            "11   2022-12-29\n",
            "12   2022-12-30\n",
            "13   2022-01-03\n",
            "14   2022-01-04\n",
            "15   2022-01-05\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "60it [02:34,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[129.62    130.15    130.73    133.49    133.41    134.76    135.94002\n",
            " 135.21002 135.27    137.87001 141.11    142.53001 141.86002 143.96\n",
            " 145.93001 143.00002]\n",
            "------------ 0    2022-01-06\n",
            "1    2022-01-09\n",
            "2    2022-01-10\n",
            "3    2022-01-11\n",
            "4    2022-01-12\n",
            "5    2022-01-13\n",
            "6    2022-01-17\n",
            "7    2022-01-18\n",
            "8    2022-01-19\n",
            "9    2022-01-20\n",
            "10   2022-01-23\n",
            "11   2022-01-24\n",
            "12   2022-01-25\n",
            "13   2022-01-26\n",
            "14   2022-01-27\n",
            "15   2022-01-30\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "61it [02:36,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[144.29001 145.43001 150.82002 154.5     151.73    154.65001 151.92\n",
            " 150.87001 151.01    153.85    153.2     155.33002 153.71    152.55002\n",
            " 148.48    148.91   ]\n",
            "------------ 0    2022-01-31\n",
            "1    2022-02-01\n",
            "2    2022-02-02\n",
            "3    2022-02-03\n",
            "4    2022-02-06\n",
            "5    2022-02-07\n",
            "6    2022-02-08\n",
            "7    2022-02-09\n",
            "8    2022-02-10\n",
            "9    2022-02-13\n",
            "10   2022-02-14\n",
            "11   2022-02-15\n",
            "12   2022-02-16\n",
            "13   2022-02-17\n",
            "14   2022-02-21\n",
            "15   2022-02-22\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "62it [02:39,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[149.4     146.71    147.92001 147.41    145.31001 145.91    151.03\n",
            " 153.83002 151.6     152.87001 150.59    148.50002 150.47002 152.59\n",
            " 152.99002 155.85   ]\n",
            "------------ 0    2022-02-23\n",
            "1    2022-02-24\n",
            "2    2022-02-27\n",
            "3    2022-02-28\n",
            "4    2022-03-01\n",
            "5    2022-03-02\n",
            "6    2022-03-03\n",
            "7    2022-03-06\n",
            "8    2022-03-07\n",
            "9    2022-03-08\n",
            "10   2022-03-09\n",
            "11   2022-03-10\n",
            "12   2022-03-13\n",
            "13   2022-03-14\n",
            "14   2022-03-15\n",
            "15   2022-03-16\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "63it [02:42,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[155.00002 157.40001 159.28001 157.83    158.93001 160.25002 158.28001\n",
            " 157.65    160.77002 162.36002 164.90001 166.17    165.63    163.76001\n",
            " 164.66    162.03001]\n",
            "------------ 0    2022-03-17\n",
            "1    2022-03-20\n",
            "2    2022-03-21\n",
            "3    2022-03-22\n",
            "4    2022-03-23\n",
            "5    2022-03-24\n",
            "6    2022-03-27\n",
            "7    2022-03-28\n",
            "8    2022-03-29\n",
            "9    2022-03-30\n",
            "10   2022-03-31\n",
            "11   2022-04-03\n",
            "12   2022-04-04\n",
            "13   2022-04-05\n",
            "14   2022-04-06\n",
            "15   2022-04-10\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "64it [02:44,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[160.80002 160.10002 165.56    165.21    165.23    166.47    167.63002\n",
            " 166.65    165.02002 165.33    163.77    163.76001 168.41    169.68\n",
            " 169.59    168.54001]\n",
            "------------ 0    2022-04-11\n",
            "1    2022-04-12\n",
            "2    2022-04-13\n",
            "3    2022-04-14\n",
            "4    2022-04-17\n",
            "5    2022-04-18\n",
            "6    2022-04-19\n",
            "7    2022-04-20\n",
            "8    2022-04-21\n",
            "9    2022-04-24\n",
            "10   2022-04-25\n",
            "11   2022-04-26\n",
            "12   2022-04-27\n",
            "13   2022-04-28\n",
            "14   2022-05-01\n",
            "15   2022-05-02\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "65it [02:47,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[167.45001 165.79    173.57    173.5     171.77002 173.56    173.75\n",
            " 172.57    172.07002 172.07002 172.69    175.05002 175.16002 174.2\n",
            " 171.56    171.84001]\n",
            "------------ 0    2022-05-03\n",
            "1    2022-05-04\n",
            "2    2022-05-05\n",
            "3    2022-05-08\n",
            "4    2022-05-09\n",
            "5    2022-05-10\n",
            "6    2022-05-11\n",
            "7    2022-05-12\n",
            "8    2022-05-15\n",
            "9    2022-05-16\n",
            "10   2022-05-17\n",
            "11   2022-05-18\n",
            "12   2022-05-19\n",
            "13   2022-05-22\n",
            "14   2022-05-23\n",
            "15   2022-05-24\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "66it [02:49,  2.58s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[172.99    175.43    177.3     177.25    180.09001 180.95    179.58\n",
            " 179.21002 177.82002 180.57002 180.96002 183.79    183.31001 183.95001\n",
            " 186.01001 184.92   ]\n",
            "------------ 0    2022-05-25\n",
            "1    2022-05-26\n",
            "2    2022-05-30\n",
            "3    2022-05-31\n",
            "4    2022-06-01\n",
            "5    2022-06-02\n",
            "6    2022-06-05\n",
            "7    2022-06-06\n",
            "8    2022-06-07\n",
            "9    2022-06-08\n",
            "10   2022-06-09\n",
            "11   2022-06-12\n",
            "12   2022-06-13\n",
            "13   2022-06-14\n",
            "14   2022-06-15\n",
            "15   2022-06-16\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "67it [02:52,  2.57s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[185.01001 183.96002 187.00002 186.68    185.27    188.06001 189.25\n",
            " 189.59    193.97002 192.46002 191.33002 191.81001 190.68001 188.61\n",
            " 188.08    189.77002]\n",
            "------------ 0    2022-06-20\n",
            "1    2022-06-21\n",
            "2    2022-06-22\n",
            "3    2022-06-23\n",
            "4    2022-06-26\n",
            "5    2022-06-27\n",
            "6    2022-06-28\n",
            "7    2022-06-29\n",
            "8    2022-06-30\n",
            "9    2022-07-03\n",
            "10   2022-07-05\n",
            "11   2022-07-06\n",
            "12   2022-07-07\n",
            "13   2022-07-10\n",
            "14   2022-07-11\n",
            "15   2022-07-12\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "68it [02:54,  2.57s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[190.54    190.69002 193.99    193.73001 195.10002 193.13    191.94\n",
            " 192.75002 193.62001 194.50002 193.22002 195.83    196.45    195.61002\n",
            " 192.58    191.17001]\n",
            "------------ 0    2022-07-13\n",
            "1    2022-07-14\n",
            "2    2022-07-17\n",
            "3    2022-07-18\n",
            "4    2022-07-19\n",
            "5    2022-07-20\n",
            "6    2022-07-21\n",
            "7    2022-07-24\n",
            "8    2022-07-25\n",
            "9    2022-07-26\n",
            "10   2022-07-27\n",
            "11   2022-07-28\n",
            "12   2022-07-31\n",
            "13   2022-08-01\n",
            "14   2022-08-02\n",
            "15   2022-08-03\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "69it [02:57,  2.57s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[181.99    178.85    179.80002 178.19    177.97002 177.79001 179.46002\n",
            " 177.45001 176.57002 174.00002 174.49    175.84    177.23001 181.12\n",
            " 176.38    178.61   ]\n",
            "------------ 0    2022-08-04\n",
            "1    2022-08-07\n",
            "2    2022-08-08\n",
            "3    2022-08-09\n",
            "4    2022-08-10\n",
            "5    2022-08-11\n",
            "6    2022-08-14\n",
            "7    2022-08-15\n",
            "8    2022-08-16\n",
            "9    2022-08-17\n",
            "10   2022-08-18\n",
            "11   2022-08-21\n",
            "12   2022-08-22\n",
            "13   2022-08-23\n",
            "14   2022-08-24\n",
            "15   2022-08-25\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "70it [03:00,  2.57s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[180.19    184.12001 187.65001 187.87001 189.46002 189.70001 182.91002\n",
            " 177.56001 178.18    179.36    176.30002 174.21    175.74    175.01\n",
            " 177.97002 179.07   ]\n",
            "------------ 0    2022-08-28\n",
            "1    2022-08-29\n",
            "2    2022-08-30\n",
            "3    2022-08-31\n",
            "4    2022-09-01\n",
            "5    2022-09-05\n",
            "6    2022-09-06\n",
            "7    2022-09-07\n",
            "8    2022-09-08\n",
            "9    2022-09-11\n",
            "10   2022-09-12\n",
            "11   2022-09-13\n",
            "12   2022-09-14\n",
            "13   2022-09-15\n",
            "14   2022-09-18\n",
            "15   2022-09-19\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "71it [03:02,  2.57s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[175.49    173.93001 174.79    176.08    171.96002 170.43001 170.69\n",
            " 171.21    173.75    172.4     173.66002 174.91    177.49    178.99002\n",
            " 178.39001 179.80002]\n",
            "------------ 0    2022-09-20\n",
            "1    2022-09-21\n",
            "2    2022-09-22\n",
            "3    2022-09-25\n",
            "4    2022-09-26\n",
            "5    2022-09-27\n",
            "6    2022-09-28\n",
            "7    2022-09-29\n",
            "8    2022-10-02\n",
            "9    2022-10-03\n",
            "10   2022-10-04\n",
            "11   2022-10-05\n",
            "12   2022-10-06\n",
            "13   2022-10-09\n",
            "14   2022-10-10\n",
            "15   2022-10-11\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "72it [03:05,  2.57s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[180.71    178.85    178.72    177.15001 175.84    175.46002 172.88002\n",
            " 173.00002 173.44    171.1     166.89    168.22    170.29    170.77002\n",
            " 173.97    177.57002]\n",
            "------------ 0    2022-10-12\n",
            "1    2022-10-13\n",
            "2    2022-10-16\n",
            "3    2022-10-17\n",
            "4    2022-10-18\n",
            "5    2022-10-19\n",
            "6    2022-10-20\n",
            "7    2022-10-23\n",
            "8    2022-10-24\n",
            "9    2022-10-25\n",
            "10   2022-10-26\n",
            "11   2022-10-27\n",
            "12   2022-10-30\n",
            "13   2022-10-31\n",
            "14   2022-11-01\n",
            "15   2022-11-02\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "73it [03:07,  2.57s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[176.65    179.23    181.82    182.89001 182.41    186.40001 184.8\n",
            " 187.44    188.01    189.71002 189.69002 191.45001 190.64001 191.31\n",
            " 189.97    189.79   ]\n",
            "------------ 0    2022-11-03\n",
            "1    2022-11-06\n",
            "2    2022-11-07\n",
            "3    2022-11-08\n",
            "4    2022-11-09\n",
            "5    2022-11-10\n",
            "6    2022-11-13\n",
            "7    2022-11-14\n",
            "8    2022-11-15\n",
            "9    2022-11-16\n",
            "10   2022-11-17\n",
            "11   2022-11-20\n",
            "12   2022-11-21\n",
            "13   2022-11-22\n",
            "14   2022-11-24\n",
            "15   2022-11-27\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "74it [03:10,  2.57s/it]batch_y_mark torch.Size([16, 65, 3])\n",
            "[190.40001 189.37    189.95    191.24    189.43    193.42    192.32\n",
            " 194.27002 195.71    193.18    194.71    197.96002 198.11    197.57\n",
            " 195.89001 196.94   ]\n",
            "------------ 0    2022-11-28\n",
            "1    2022-11-29\n",
            "2    2022-11-30\n",
            "3    2022-12-01\n",
            "4    2022-12-04\n",
            "5    2022-12-05\n",
            "6    2022-12-06\n",
            "7    2022-12-07\n",
            "8    2022-12-08\n",
            "9    2022-12-11\n",
            "10   2022-12-12\n",
            "11   2022-12-13\n",
            "12   2022-12-14\n",
            "13   2022-12-15\n",
            "14   2022-12-18\n",
            "15   2022-12-19\n",
            "dtype: datetime64[ns] \n",
            "\n",
            "75it [03:13,  2.57s/it]\n",
            "Results saved to predictions_2023.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PaF1OOq_Ch2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mpi4py\n"
      ],
      "metadata": {
        "id": "ZTZY0yHGDLlG",
        "outputId": "3145d8a2-ede5-438c-a96d-164308d5986f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpi4py\n",
            "  Downloading mpi4py-4.0.0.tar.gz (464 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/464.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.8/464.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-4.0.0-cp310-cp310-linux_x86_64.whl size=4266270 sha256=c811f9a2c5052a47974056098c8a170db7d4e04c18706d4985a396ec911ba38d\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/17/12/83db63ee0ae5c4b040ee87f2e5c813aea4728b55ec6a37317c\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-4.0.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}