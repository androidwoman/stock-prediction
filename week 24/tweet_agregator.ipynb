{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import os, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import re"
      ],
      "metadata": {
        "id": "GaxIfQsYQKqo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/koa-fin/sn2.git"
      ],
      "metadata": {
        "id": "Zz7lH429x0Mz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04b765f5-548d-489d-b816-6d86c0ee86f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sn2'...\n",
            "remote: Enumerating objects: 81318, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 81318 (delta 0), reused 2 (delta 0), pack-reused 81315\u001b[K\n",
            "Receiving objects: 100% (81318/81318), 147.74 MiB | 14.26 MiB/s, done.\n",
            "Resolving deltas: 100% (12217/12217), done.\n",
            "Updating files: 100% (81242/81242), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Summarizer:\n",
        "\n",
        "\n",
        "    def get_summary(self, ticker, tweets):\n",
        "        summary = None\n",
        "        if tweets != []:\n",
        "            summary = \"\\n\".join(tweets)\n",
        "\n",
        "        return summary\n",
        "\n",
        "\n",
        "    def is_informative(self, summary):\n",
        "         neg = r'.*[nN]o.*information.*|.*[nN]o.*facts.*|.*[nN]o.*mention.*|.*[nN]o.*tweets.*|.*do not contain.*'\n",
        "         return not re.match(neg, summary)\n"
      ],
      "metadata": {
        "id": "z5W3qnwqQmwH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self):\n",
        "        self.price_dir = \"/content/sn2/price/preprocessed\"\n",
        "        self.tweet_dir = \"/content/sn2/tweet/raw\"\n",
        "        self.seq_len = 5\n",
        "        self.summarizer = Summarizer()\n",
        "\n",
        "    def daterange(self, start_date, end_date):\n",
        "        for n in range(int((end_date - start_date).days)):\n",
        "            yield start_date + timedelta(n)\n",
        "\n",
        "    def get_sentiment(self, date_str, price_path):\n",
        "        price_data = np.genfromtxt(price_path, dtype=str, skip_header=False)\n",
        "        price_chg = price_data[price_data[:, 0] == date_str][0, 1].astype(float)\n",
        "        if price_chg > 0.0:\n",
        "            sentiment = \"Positive\"\n",
        "        else:\n",
        "            sentiment = \"Negative\"\n",
        "        return sentiment\n",
        "\n",
        "    def get_tweets(self, ticker, date_str):\n",
        "        tweets = []\n",
        "        tweet_path = os.path.join(self.tweet_dir, ticker, date_str)\n",
        "        if os.path.exists(tweet_path):\n",
        "            with open(tweet_path) as f:\n",
        "                lines = f.readlines()\n",
        "                for line in lines:\n",
        "                    tweet_obj = json.loads(line)\n",
        "                    tweets.append(tweet_obj['text'])\n",
        "        return tweets\n",
        "\n",
        "    def load(self, flag):\n",
        "        for file in os.listdir(self.price_dir):\n",
        "            price_path = os.path.join(self.price_dir, file)\n",
        "            ordered_price_data = np.flip(np.genfromtxt(price_path, dtype=str, skip_header=False), 0)\n",
        "            ticker = file[:-4]\n",
        "            tes_idx = round(len(ordered_price_data) * 0.8)\n",
        "            end_idx = len(ordered_price_data)\n",
        "\n",
        "            if flag == \"train\":\n",
        "                data_range = range(tes_idx)\n",
        "            else:\n",
        "                data_range = range(tes_idx, end_idx)\n",
        "                print(\"data_range\", data_range)\n",
        "\n",
        "            ticker_data = pd.DataFrame()\n",
        "\n",
        "            for idx in data_range:\n",
        "                summary_all = \"\"\n",
        "                end_date_str = ordered_price_data[idx, 0]\n",
        "                end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n",
        "                start_date = end_date - timedelta(days=self.seq_len)\n",
        "                target = self.get_sentiment(end_date_str, price_path)\n",
        "\n",
        "                for seq_date in self.daterange(start_date, end_date):\n",
        "                    seq_date_str = seq_date.strftime(\"%Y-%m-%d\")\n",
        "                    tweet_data = self.get_tweets(ticker, seq_date_str)\n",
        "                    summary = self.summarizer.get_summary(ticker, tweet_data)\n",
        "\n",
        "                    if summary and summary is not None and summary != \"\" and self.summarizer.is_informative(summary):\n",
        "                        summary_all = summary_all + seq_date_str + \"\\n\" + summary + \"\\n\\n\"\n",
        "\n",
        "                if summary_all != \"\":\n",
        "                    row = pd.DataFrame([{'ticker': ticker, 'summary': summary_all.rstrip(), 'target': target}])\n",
        "                    ticker_data = pd.concat([ticker_data, row], ignore_index=True)\n",
        "\n",
        "            if not ticker_data.empty:\n",
        "                ticker_data.to_csv(f\"{ticker}.csv\", index=False)\n",
        "\n",
        "        return\n",
        "\n",
        "# Example usage\n",
        "data_loader = DataLoader()\n",
        "data_loader.load(\"train\")  # or data_loader.load(\"test\") depending on the flag\n"
      ],
      "metadata": {
        "id": "MfQwhG6kxvxC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KhbX5R90RVRJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}