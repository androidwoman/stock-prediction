{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "yahoo-finance-scrapper-and-Use-LLM-Starter",
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e57bd24380d74e5cab6feaf9cb642fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92304e3b1ec84397a0ed634e3c9749aa",
              "IPY_MODEL_302e1d1fcadb4b139bb7b96cd8d4c3be",
              "IPY_MODEL_6eb3e4d3a0cc4370854f14d13253111c"
            ],
            "layout": "IPY_MODEL_6d9a71a054634b5fb3e5fad51c4b9129"
          }
        },
        "92304e3b1ec84397a0ed634e3c9749aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01483a6bb7b8427bac2a04f5f4c993c3",
            "placeholder": "​",
            "style": "IPY_MODEL_35f9399fb6f34d9a9cab2b9626b50245",
            "value": "Fetching 1 files: 100%"
          }
        },
        "302e1d1fcadb4b139bb7b96cd8d4c3be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3326ede124674edca466ef833e5d5f26",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0cc04c725d14116b34c61cbb5df25ba",
            "value": 1
          }
        },
        "6eb3e4d3a0cc4370854f14d13253111c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_685cbfe79e4a4d5e8edff767875d8560",
            "placeholder": "​",
            "style": "IPY_MODEL_3034d158f35f4a4fb767b726ea8cd082",
            "value": " 1/1 [00:00&lt;00:00,  3.97it/s]"
          }
        },
        "6d9a71a054634b5fb3e5fad51c4b9129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01483a6bb7b8427bac2a04f5f4c993c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35f9399fb6f34d9a9cab2b9626b50245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3326ede124674edca466ef833e5d5f26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0cc04c725d14116b34c61cbb5df25ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "685cbfe79e4a4d5e8edff767875d8560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3034d158f35f4a4fb767b726ea8cd082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e3175d9e4044b6285a49e6c0bf81ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77fe61950bbe497692b836a7e0014f7f",
              "IPY_MODEL_305ab6d105f34a9898035f37779a8ec8",
              "IPY_MODEL_4522c7b0c2fb4ead96a718ec2f3d466f"
            ],
            "layout": "IPY_MODEL_58495acfefc74bdf8e2b32bf3ee1ca30"
          }
        },
        "77fe61950bbe497692b836a7e0014f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce118e44a38e48b1b63401ba1ffcda4c",
            "placeholder": "​",
            "style": "IPY_MODEL_078b0dbabaf84e6eb1a8112485927009",
            "value": "config.json: 100%"
          }
        },
        "305ab6d105f34a9898035f37779a8ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9d03dcd9b104e6782062b46631bccf5",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e8c7ac1bf354b858a88d4f6666194c4",
            "value": 29
          }
        },
        "4522c7b0c2fb4ead96a718ec2f3d466f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_335bf1476e0442c7931966ebc4563634",
            "placeholder": "​",
            "style": "IPY_MODEL_7a1944fb223f4182b9e26de4fd797bce",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.07kB/s]"
          }
        },
        "58495acfefc74bdf8e2b32bf3ee1ca30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce118e44a38e48b1b63401ba1ffcda4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "078b0dbabaf84e6eb1a8112485927009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9d03dcd9b104e6782062b46631bccf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e8c7ac1bf354b858a88d4f6666194c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "335bf1476e0442c7931966ebc4563634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a1944fb223f4182b9e26de4fd797bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43ab23d623a34f4ab4687386bfc9b6b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_677740f9589c4001a36300249d8b1ae6",
              "IPY_MODEL_ba5dd2acf3d84b73849ff697696ca9c6",
              "IPY_MODEL_aab50d67c5bc4b00b72e43adbc8548db"
            ],
            "layout": "IPY_MODEL_fca39744544f42a99eab71d42c0a9c41"
          }
        },
        "677740f9589c4001a36300249d8b1ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a7d60792e54b369e1e7e699c1290c0",
            "placeholder": "​",
            "style": "IPY_MODEL_bf8ed08ab30f4bf7b9ae892bf9392276",
            "value": "Fetching 1 files: 100%"
          }
        },
        "ba5dd2acf3d84b73849ff697696ca9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0811c40990c04bb9a896f306a34fd41f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ff851240a3d4355adce2849ad3aea64",
            "value": 1
          }
        },
        "aab50d67c5bc4b00b72e43adbc8548db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb20fc6d17ae41ccaf819d92407bc7ef",
            "placeholder": "​",
            "style": "IPY_MODEL_f043afb012fc44969a2585ba53a55b2d",
            "value": " 1/1 [01:32&lt;00:00, 92.92s/it]"
          }
        },
        "fca39744544f42a99eab71d42c0a9c41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68a7d60792e54b369e1e7e699c1290c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf8ed08ab30f4bf7b9ae892bf9392276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0811c40990c04bb9a896f306a34fd41f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ff851240a3d4355adce2849ad3aea64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb20fc6d17ae41ccaf819d92407bc7ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f043afb012fc44969a2585ba53a55b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c106ad9f28884d36a098f242293330d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a72c3fccdd440f097403fb16ff1dd29",
              "IPY_MODEL_a80352f191354d5db754ce1166511a76",
              "IPY_MODEL_21d1c32b5a8c45a2ad92b321266f5f3f"
            ],
            "layout": "IPY_MODEL_0e52ec1282514168883c70082a302b48"
          }
        },
        "9a72c3fccdd440f097403fb16ff1dd29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e7327afd0e34a47afbc009b3051e682",
            "placeholder": "​",
            "style": "IPY_MODEL_d9fbfa8fe7254d39a1d444deccc54265",
            "value": "llama-2-7b-chat.ggmlv3.q5_K_M.bin: 100%"
          }
        },
        "a80352f191354d5db754ce1166511a76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a0f3ef6d80848618d67c68a281d947e",
            "max": 4782867072,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d37834797a7472a84e2b453c697c153",
            "value": 4782867072
          }
        },
        "21d1c32b5a8c45a2ad92b321266f5f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ecaaf90cdfa4e47873abf03f086fef7",
            "placeholder": "​",
            "style": "IPY_MODEL_427ed51c172a4ecbb85cd9b409875ffb",
            "value": " 4.78G/4.78G [01:32&lt;00:00, 51.1MB/s]"
          }
        },
        "0e52ec1282514168883c70082a302b48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e7327afd0e34a47afbc009b3051e682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9fbfa8fe7254d39a1d444deccc54265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a0f3ef6d80848618d67c68a281d947e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d37834797a7472a84e2b453c697c153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ecaaf90cdfa4e47873abf03f086fef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "427ed51c172a4ecbb85cd9b409875ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-10-03T04:06:09.333Z",
          "iopub.execute_input": "2023-10-03T04:06:09.333562Z",
          "iopub.status.idle": "2023-10-03T04:06:09.735828Z",
          "shell.execute_reply.started": "2023-10-03T04:06:09.333522Z",
          "shell.execute_reply": "2023-10-03T04:06:09.734723Z"
        },
        "trusted": true,
        "id": "lBC_16XraHV4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    n1=pd.read_csv(\"finance_news.csv\")\n",
        "except:\n",
        "    n1=pd.DataFrame({\"News\":[]})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:06:09.738285Z",
          "iopub.execute_input": "2023-10-03T04:06:09.739285Z",
          "iopub.status.idle": "2023-10-03T04:06:09.749351Z",
          "shell.execute_reply.started": "2023-10-03T04:06:09.73924Z",
          "shell.execute_reply": "2023-10-03T04:06:09.748275Z"
        },
        "trusted": true,
        "id": "G1YrkXSfaHV7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:06:09.751021Z",
          "iopub.execute_input": "2023-10-03T04:06:09.75183Z",
          "iopub.status.idle": "2023-10-03T04:06:09.773024Z",
          "shell.execute_reply.started": "2023-10-03T04:06:09.751788Z",
          "shell.execute_reply": "2023-10-03T04:06:09.77192Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "TGFQM8m3aHV7",
        "outputId": "3253218d-1a28-4cd8-8c41-4ecf4ff09302"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [News]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50174204-dc12-42f3-8a92-fdc347b4d6ab\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50174204-dc12-42f3-8a92-fdc347b4d6ab')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-50174204-dc12-42f3-8a92-fdc347b4d6ab button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-50174204-dc12-42f3-8a92-fdc347b4d6ab');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Define the URL of the Yahoo Finance page for US stock market headlines\n",
        "url = \"https://finance.yahoo.com/\"\n",
        "# Send an HTTP GET request to the URL\n",
        "response = requests.get(url)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:06:09.775304Z",
          "iopub.execute_input": "2023-10-03T04:06:09.775865Z",
          "iopub.status.idle": "2023-10-03T04:06:10.52478Z",
          "shell.execute_reply.started": "2023-10-03T04:06:09.775835Z",
          "shell.execute_reply": "2023-10-03T04:06:10.523476Z"
        },
        "trusted": true,
        "id": "OJt7PcmIaHV8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n1=[]\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the HTML content of the page using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Find all links on the page\n",
        "    links = soup.find_all(\"a\")\n",
        "\n",
        "    # Initialize a list to store the headlines\n",
        "    headlines = []\n",
        "\n",
        "    # Loop through the links to visit each page and extract headlines\n",
        "    for link in links:\n",
        "        link_url = link.get(\"href\")\n",
        "        if link_url and link_url.startswith(\"https://finance.yahoo.com/news/\"):\n",
        "            # Send an HTTP GET request to the link\n",
        "            link_response = requests.get(link_url)\n",
        "            if link_response.status_code == 200:\n",
        "                # Parse the content of the link's page\n",
        "                link_soup = BeautifulSoup(link_response.content, \"html.parser\")\n",
        "                # Find elements with 'data-test-locator=\"headline\"'\n",
        "                headline_elements = link_soup.find_all(attrs={\"data-test-locator\": \"headline\"})\n",
        "                # Extract and append the headline text to the headlines list\n",
        "                for headline_element in headline_elements:\n",
        "                    headline_text = headline_element.text.strip()\n",
        "                    headlines.append(headline_text)\n",
        "\n",
        "    # Print the extracted headlines\n",
        "    for i, headline in enumerate(headlines, start=1):\n",
        "        print(f\"{i}. {headline}\")\n",
        "else:\n",
        "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:06:10.526553Z",
          "iopub.execute_input": "2023-10-03T04:06:10.527059Z",
          "iopub.status.idle": "2023-10-03T04:06:20.312942Z",
          "shell.execute_reply.started": "2023-10-03T04:06:10.527016Z",
          "shell.execute_reply": "2023-10-03T04:06:20.311832Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5BIdQzpaHV8",
        "outputId": "6601737f-a0d3-4afd-a004-dd562da4c4a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. January jobs report: US economy adds 353,000 jobs, blowing past Wall Street expectations\n",
            "2. January jobs report: US economy adds 353,000 jobs, blowing past Wall Street expectations\n",
            "3. January jobs report: US economy adds 353,000 jobs, blowing past Wall Street expectations\n",
            "4. Stock market today: Stocks mostly rise after jobs report whopper, tech earnings\n",
            "5. Apple stock sinks despite earnings beat, as China sales slow\n",
            "6. Meta shares jump more than 16% on solid earnings, stock buyback, and dividend plan\n",
            "7. The latest inflation scourge: Car insurance\n",
            "8. Apple CEO Cook: Gen. AI a 'huge opportunity' for Apple, announcements coming this year\n",
            "9. The ghosts of last year's regional bank collapse still haunt the banking sector\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headlines"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:06:20.314811Z",
          "iopub.execute_input": "2023-10-03T04:06:20.315616Z",
          "iopub.status.idle": "2023-10-03T04:06:20.325235Z",
          "shell.execute_reply.started": "2023-10-03T04:06:20.315575Z",
          "shell.execute_reply": "2023-10-03T04:06:20.324044Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxjb_8rLaHV9",
        "outputId": "e015fd2d-7a76-4402-c910-43bc771568f2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['January jobs report: US economy adds 353,000 jobs, blowing past Wall Street expectations',\n",
              " 'January jobs report: US economy adds 353,000 jobs, blowing past Wall Street expectations',\n",
              " 'January jobs report: US economy adds 353,000 jobs, blowing past Wall Street expectations',\n",
              " 'Stock market today: Stocks mostly rise after jobs report whopper, tech earnings',\n",
              " 'Apple stock sinks despite earnings beat, as China sales slow',\n",
              " 'Meta shares jump more than 16% on solid earnings, stock buyback, and dividend plan',\n",
              " 'The latest inflation scourge: Car insurance',\n",
              " \"Apple CEO Cook: Gen. AI a 'huge opportunity' for Apple, announcements coming this year\",\n",
              " \"The ghosts of last year's regional bank collapse still haunt the banking sector\"]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "headline2=[]\n",
        "\n",
        "# Define the URL of the webpage you want to scrape\n",
        "url = \"https://finance.yahoo.com/\"  # Replace with the URL of the webpage you are interested in\n",
        "\n",
        "# Send an HTTP GET request to the URL\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the HTML content of the page using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Find all occurrences of </u> tags with class \"StretchedBox\" in the HTML\n",
        "    target_tags = soup.find_all(\"u\", class_=\"StretchedBox\")\n",
        "\n",
        "    # Loop through each target_tag to find and print the text after it\n",
        "    for target_tag in target_tags:\n",
        "        # Get the next sibling element, which contains the text after the </u> tag\n",
        "        text_after_u = target_tag.find_next_sibling(text=True)\n",
        "\n",
        "        # Print the text after the </u> tag with class \"StretchedBox\"\n",
        "        if text_after_u:\n",
        "            print(text_after_u.strip())\n",
        "            headline2.append(text_after_u.strip())\n",
        "        else:\n",
        "            print(\"No text found after </u> tag with class 'StretchedBox'\")\n",
        "else:\n",
        "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:06:20.326929Z",
          "iopub.execute_input": "2023-10-03T04:06:20.328014Z",
          "iopub.status.idle": "2023-10-03T04:06:20.903984Z",
          "shell.execute_reply.started": "2023-10-03T04:06:20.327948Z",
          "shell.execute_reply": "2023-10-03T04:06:20.9028Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cIDUED1aHV9",
        "outputId": "65aab3c5-1099-4a6b-baf3-b50ccdc91eee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elon Musk bashed by heavy metal drummer who cost him $56 billion\n",
            "Mark Cuban is leaving ‘Shark Tank.’ Here’s how some of his investments on the show have done\n",
            "Meta shares jump more than 16% on solid earnings, stock buyback, and dividend plan\n",
            "Seattle woman who returned Costco couch after 2.5 years goes viral, sparks ethics debate\n",
            "Meta's Brand-New Dividend Will Make You This Much Richer\n",
            "Analyst Report: Eaton Corporation plc\n",
            "Ask an Advisor: Can a Nursing Home ‘Take Our IRA?' My Wife and I Are Elderly. We Have a $100K IRA and a Trust to Protect Our Assets.\n",
            "Why Volvo has pulled the plug on its electric car brand\n",
            "I'm 68 and My Long-Term Care Insurance Now Costs $600 Per Month. Is This Too Much?\n",
            "I'm 62 With $1.5 Million in an IRA. Should I Convert $150k Per Year to a Roth to Avoid RMDs?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-e2e02320c8db>:22: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  text_after_u = target_tag.find_next_sibling(text=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headline2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:06:20.907218Z",
          "iopub.execute_input": "2023-10-03T04:06:20.907643Z",
          "iopub.status.idle": "2023-10-03T04:06:20.917114Z",
          "shell.execute_reply.started": "2023-10-03T04:06:20.907602Z",
          "shell.execute_reply": "2023-10-03T04:06:20.915957Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwfQvDvlaHV9",
        "outputId": "82b3ea05-dfcb-4cad-98bb-9c86d11c65b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Elon Musk bashed by heavy metal drummer who cost him $56 billion',\n",
              " 'Mark Cuban is leaving ‘Shark Tank.’ Here’s how some of his investments on the show have done',\n",
              " 'Meta shares jump more than 16% on solid earnings, stock buyback, and dividend plan',\n",
              " 'Seattle woman who returned Costco couch after 2.5 years goes viral, sparks ethics debate',\n",
              " \"Meta's Brand-New Dividend Will Make You This Much Richer\",\n",
              " 'Analyst Report: Eaton Corporation plc',\n",
              " \"Ask an Advisor: Can a Nursing Home ‘Take Our IRA?' My Wife and I Are Elderly. We Have a $100K IRA and a Trust to Protect Our Assets.\",\n",
              " 'Why Volvo has pulled the plug on its electric car brand',\n",
              " \"I'm 68 and My Long-Term Care Insurance Now Costs $600 Per Month. Is This Too Much?\",\n",
              " \"I'm 62 With $1.5 Million in an IRA. Should I Convert $150k Per Year to a Roth to Avoid RMDs?\"]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the request was successful (status code 200)\n",
        "if response.status_code == 200:\n",
        "    # Parse the HTML content of the page using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Find all elements with the class \"js-content-viewer\"\n",
        "    content_viewer_elements = soup.find_all(class_=\"js-content-viewer\")\n",
        "\n",
        "    # Initialize a list to store the text from these elements\n",
        "    content_viewer_text = []\n",
        "\n",
        "    # Loop through the content_viewer_elements and extract the text\n",
        "    for element in content_viewer_elements:\n",
        "        text = element.get_text(strip=True)\n",
        "        content_viewer_text.append(text)\n",
        "\n",
        "    # Print the extracted text from elements with the class \"js-content-viewer\"\n",
        "    for text in content_viewer_text:\n",
        "        print(text)\n",
        "else:\n",
        "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:06:20.918765Z",
          "iopub.execute_input": "2023-10-03T04:06:20.919326Z",
          "iopub.status.idle": "2023-10-03T04:06:21.022703Z",
          "shell.execute_reply.started": "2023-10-03T04:06:20.919293Z",
          "shell.execute_reply": "2023-10-03T04:06:21.021547Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKB_p8dNaHV-",
        "outputId": "6a1901b7-43cf-4f91-df4a-31dc7900b545"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Jobs report blowout: US economy adds 353,000 jobsThe labor market continues to show unfathomable resilience.Yahoo Finance\n",
            "Stocks edge up after jobs blowout, tech windfallYahoo Finance\n",
            "Apple slips as China gloom outweighs earnings beatYahoo Finance\n",
            "Meta surges after earnings, first-ever dividendYahoo Finance\n",
            "0 : 50Exxon & Chevron earnings, January jobs report: What to WatchYahoo Finance Video\n",
            "3 : 25Meta flipped 'entire narrative' on AI investments: AnalystYahoo Finance Video\n",
            "The latest inflation scourge: Car insuranceYahoo Finance\n",
            "Apple's Cook: Gen. AI a 'huge opportunity'Yahoo Finance\n",
            "Regional bank crisis roars backYahoo Finance\n",
            "Elon Musk bashed by heavy metal drummer who cost him $56 billion\n",
            "Mark Cuban is leaving ‘Shark Tank.’ Here’s how some of his investments on the show have done\n",
            "Meta shares jump more than 16% on solid earnings, stock buyback, and dividend plan\n",
            "Amazon and Meta surge after results, while Apple dropsReuters\n",
            "Meta Stock Surges On 'Monumental' Quarterly Earnings, Dividend PlanInvestor's Business Daily\n",
            "Seattle woman who returned Costco couch after 2.5 years goes viral, sparks ethics debate\n",
            "Meta's Brand-New Dividend Will Make You This Much Richer\n",
            "Ask an Advisor: Can a Nursing Home ‘Take Our IRA?' My Wife and I Are Elderly. We Have a $100K IRA and a Trust to Protect Our Assets.\n",
            "Why Volvo has pulled the plug on its electric car brand\n",
            "Volvo stock surges on strong sales and EV deliveries, will no longer fund PolestarYahoo Finance\n",
            "Analysis-Volvo's Polestar troubles signal 'shakeout time' for EV industryReuters\n",
            "I'm 68 and My Long-Term Care Insurance Now Costs $600 Per Month. Is This Too Much?\n",
            "I'm 62 With $1.5 Million in an IRA. Should I Convert $150k Per Year to a Roth to Avoid RMDs?\n",
            "Here’s a Way to Delay Some RMDs—and Put Off Your Tax BillThe Wall Street Journal\n",
            "I Have $2.5 Million in a Roth IRA and Will Receive $2,500 Monthly From Social Security. Can I Retire at 62?SmartAsset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content_viewer_text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:06:21.024363Z",
          "iopub.execute_input": "2023-10-03T04:06:21.025076Z",
          "iopub.status.idle": "2023-10-03T04:06:21.032386Z",
          "shell.execute_reply.started": "2023-10-03T04:06:21.025033Z",
          "shell.execute_reply": "2023-10-03T04:06:21.031485Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mihKis-xaHV-",
        "outputId": "59f61ac0-fb98-4a2b-b57f-5b5f2fca8a59"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'Jobs report blowout: US economy adds 353,000 jobsThe labor market continues to show unfathomable resilience.Yahoo Finance',\n",
              " 'Stocks edge up after jobs blowout, tech windfallYahoo Finance',\n",
              " 'Apple slips as China gloom outweighs earnings beatYahoo Finance',\n",
              " 'Meta surges after earnings, first-ever dividendYahoo Finance',\n",
              " '0 : 50Exxon & Chevron earnings, January jobs report: What to WatchYahoo Finance Video',\n",
              " \"3 : 25Meta flipped 'entire narrative' on AI investments: AnalystYahoo Finance Video\",\n",
              " 'The latest inflation scourge: Car insuranceYahoo Finance',\n",
              " \"Apple's Cook: Gen. AI a 'huge opportunity'Yahoo Finance\",\n",
              " 'Regional bank crisis roars backYahoo Finance',\n",
              " 'Elon Musk bashed by heavy metal drummer who cost him $56 billion',\n",
              " 'Mark Cuban is leaving ‘Shark Tank.’ Here’s how some of his investments on the show have done',\n",
              " 'Meta shares jump more than 16% on solid earnings, stock buyback, and dividend plan',\n",
              " 'Amazon and Meta surge after results, while Apple dropsReuters',\n",
              " \"Meta Stock Surges On 'Monumental' Quarterly Earnings, Dividend PlanInvestor's Business Daily\",\n",
              " 'Seattle woman who returned Costco couch after 2.5 years goes viral, sparks ethics debate',\n",
              " \"Meta's Brand-New Dividend Will Make You This Much Richer\",\n",
              " \"Ask an Advisor: Can a Nursing Home ‘Take Our IRA?' My Wife and I Are Elderly. We Have a $100K IRA and a Trust to Protect Our Assets.\",\n",
              " 'Why Volvo has pulled the plug on its electric car brand',\n",
              " 'Volvo stock surges on strong sales and EV deliveries, will no longer fund PolestarYahoo Finance',\n",
              " \"Analysis-Volvo's Polestar troubles signal 'shakeout time' for EV industryReuters\",\n",
              " \"I'm 68 and My Long-Term Care Insurance Now Costs $600 Per Month. Is This Too Much?\",\n",
              " \"I'm 62 With $1.5 Million in an IRA. Should I Convert $150k Per Year to a Roth to Avoid RMDs?\",\n",
              " 'Here’s a Way to Delay Some RMDs—and Put Off Your Tax BillThe Wall Street Journal',\n",
              " 'I Have $2.5 Million in a Roth IRA and Will Receive $2,500 Monthly From Social Security. Can I Retire at 62?SmartAsset']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n=pd.DataFrame({\"News\":headlines+headline2+content_viewer_text})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:06:21.033516Z",
          "iopub.execute_input": "2023-10-03T04:06:21.033926Z",
          "iopub.status.idle": "2023-10-03T04:06:21.046309Z",
          "shell.execute_reply.started": "2023-10-03T04:06:21.033888Z",
          "shell.execute_reply": "2023-10-03T04:06:21.045136Z"
        },
        "trusted": true,
        "id": "6SAqUvR-aHV_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=pd.concat([n,n1]).drop_duplicates().reset_index(drop=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:06:21.733456Z",
          "iopub.execute_input": "2023-10-03T04:06:21.733802Z",
          "iopub.status.idle": "2023-10-03T04:06:21.75109Z",
          "shell.execute_reply.started": "2023-10-03T04:06:21.733775Z",
          "shell.execute_reply": "2023-10-03T04:06:21.749961Z"
        },
        "trusted": true,
        "id": "opKpJ2zWaHV_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:06:22.540808Z",
          "iopub.execute_input": "2023-10-03T04:06:22.541948Z",
          "iopub.status.idle": "2023-10-03T04:06:22.554769Z",
          "shell.execute_reply.started": "2023-10-03T04:06:22.541899Z",
          "shell.execute_reply": "2023-10-03T04:06:22.553775Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xUteJjwIaHV_",
        "outputId": "caac24c7-b615-49b5-ddcd-e142c3127d82"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 News\n",
              "0   January jobs report: US economy adds 353,000 j...\n",
              "1   Stock market today: Stocks mostly rise after j...\n",
              "2   Apple stock sinks despite earnings beat, as Ch...\n",
              "3   Meta shares jump more than 16% on solid earnin...\n",
              "4         The latest inflation scourge: Car insurance\n",
              "5   Apple CEO Cook: Gen. AI a 'huge opportunity' f...\n",
              "6   The ghosts of last year's regional bank collap...\n",
              "7   Elon Musk bashed by heavy metal drummer who co...\n",
              "8   Mark Cuban is leaving ‘Shark Tank.’ Here’s how...\n",
              "9   Seattle woman who returned Costco couch after ...\n",
              "10  Meta's Brand-New Dividend Will Make You This M...\n",
              "11              Analyst Report: Eaton Corporation plc\n",
              "12  Ask an Advisor: Can a Nursing Home ‘Take Our I...\n",
              "13  Why Volvo has pulled the plug on its electric ...\n",
              "14  I'm 68 and My Long-Term Care Insurance Now Cos...\n",
              "15  I'm 62 With $1.5 Million in an IRA. Should I C...\n",
              "16                                                   \n",
              "17  Jobs report blowout: US economy adds 353,000 j...\n",
              "18  Stocks edge up after jobs blowout, tech windfa...\n",
              "19  Apple slips as China gloom outweighs earnings ...\n",
              "20  Meta surges after earnings, first-ever dividen...\n",
              "21  0 : 50Exxon & Chevron earnings, January jobs r...\n",
              "22  3 : 25Meta flipped 'entire narrative' on AI in...\n",
              "23  The latest inflation scourge: Car insuranceYah...\n",
              "24  Apple's Cook: Gen. AI a 'huge opportunity'Yaho...\n",
              "25       Regional bank crisis roars backYahoo Finance\n",
              "26  Amazon and Meta surge after results, while App...\n",
              "27  Meta Stock Surges On 'Monumental' Quarterly Ea...\n",
              "28  Volvo stock surges on strong sales and EV deli...\n",
              "29  Analysis-Volvo's Polestar troubles signal 'sha...\n",
              "30  Here’s a Way to Delay Some RMDs—and Put Off Yo...\n",
              "31  I Have $2.5 Million in a Roth IRA and Will Rec..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3fca083-10f7-474b-a077-3d88fcedf31e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>January jobs report: US economy adds 353,000 j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Stock market today: Stocks mostly rise after j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Apple stock sinks despite earnings beat, as Ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Meta shares jump more than 16% on solid earnin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The latest inflation scourge: Car insurance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Apple CEO Cook: Gen. AI a 'huge opportunity' f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The ghosts of last year's regional bank collap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Elon Musk bashed by heavy metal drummer who co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Mark Cuban is leaving ‘Shark Tank.’ Here’s how...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Seattle woman who returned Costco couch after ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Meta's Brand-New Dividend Will Make You This M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Analyst Report: Eaton Corporation plc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Ask an Advisor: Can a Nursing Home ‘Take Our I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Why Volvo has pulled the plug on its electric ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>I'm 68 and My Long-Term Care Insurance Now Cos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I'm 62 With $1.5 Million in an IRA. Should I C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Jobs report blowout: US economy adds 353,000 j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Stocks edge up after jobs blowout, tech windfa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Apple slips as China gloom outweighs earnings ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Meta surges after earnings, first-ever dividen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0 : 50Exxon &amp; Chevron earnings, January jobs r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3 : 25Meta flipped 'entire narrative' on AI in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>The latest inflation scourge: Car insuranceYah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Apple's Cook: Gen. AI a 'huge opportunity'Yaho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Regional bank crisis roars backYahoo Finance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Amazon and Meta surge after results, while App...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Meta Stock Surges On 'Monumental' Quarterly Ea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Volvo stock surges on strong sales and EV deli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Analysis-Volvo's Polestar troubles signal 'sha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Here’s a Way to Delay Some RMDs—and Put Off Yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>I Have $2.5 Million in a Roth IRA and Will Rec...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3fca083-10f7-474b-a077-3d88fcedf31e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f3fca083-10f7-474b-a077-3d88fcedf31e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f3fca083-10f7-474b-a077-3d88fcedf31e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-db10fb8d-cc1f-40c4-a553-eb250f8f52d8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db10fb8d-cc1f-40c4-a553-eb250f8f52d8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-db10fb8d-cc1f-40c4-a553-eb250f8f52d8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n.to_csv(\"finance_news.csv\",index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:06:28.611598Z",
          "iopub.execute_input": "2023-10-03T04:06:28.611952Z",
          "iopub.status.idle": "2023-10-03T04:06:28.621655Z",
          "shell.execute_reply.started": "2023-10-03T04:06:28.611922Z",
          "shell.execute_reply": "2023-10-03T04:06:28.619392Z"
        },
        "trusted": true,
        "id": "JDIHId3naHWA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Llama 2"
      ],
      "metadata": {
        "id": "KbCeaFWEaHWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ctransformers langchain"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:06:31.329095Z",
          "iopub.execute_input": "2023-10-03T04:06:31.329677Z",
          "iopub.status.idle": "2023-10-03T04:07:02.678919Z",
          "shell.execute_reply.started": "2023-10-03T04:06:31.329633Z",
          "shell.execute_reply": "2023-10-03T04:07:02.677349Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le-mSbODaHWC",
        "outputId": "69c45a95-d63c-4eab-8adf-1fbcfc4bbeff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.7/806.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.0/237.0 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import CTransformers\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:07:02.681388Z",
          "iopub.execute_input": "2023-10-03T04:07:02.681843Z",
          "iopub.status.idle": "2023-10-03T04:07:06.020498Z",
          "shell.execute_reply.started": "2023-10-03T04:07:02.681798Z",
          "shell.execute_reply": "2023-10-03T04:07:06.019217Z"
        },
        "trusted": true,
        "id": "AbXGT7txaHWC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config={\"max_new_tokens\":512,\"context_length\":1024}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:07:06.02232Z",
          "iopub.execute_input": "2023-10-03T04:07:06.024191Z",
          "iopub.status.idle": "2023-10-03T04:07:06.029492Z",
          "shell.execute_reply.started": "2023-10-03T04:07:06.024145Z",
          "shell.execute_reply": "2023-10-03T04:07:06.028269Z"
        },
        "trusted": true,
        "id": "kRlToGhIaHWD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some Background\n",
        "Llama-2 is a 70B parameter large language model created by Meta AI. It is a factual language model, trained on a massive dataset of text and code. Llama-2 can generate different creative text formats, like poems, code, scripts, musical pieces, email, letters, etc. It will try its best to follow your instructions and complete your requests thoughtfully.\n",
        "\n",
        "5-bit quantized Llama-2 models are compressed versions of the original Llama-2 model that use less memory and are faster to run. This is done by reducing the precision of the model's parameters from 16 bits to 5 bits. This can lead to a small loss in accuracy, but it is usually not noticeable.\n",
        "\n",
        "There are several benefits to using 5-bit quantized Llama-2 models. First, they are much smaller than the original Llama-2 model. For example, the 70B parameter 5-bit quantized Llama-2 model is only 4.63 GB in size, compared to 13.5 GB for the original model. This makes it possible to run Llama-2 on devices with less memory, such as laptops and smartphones.\n",
        "\n",
        "Second, 5-bit quantized Llama-2 models are faster to run than the original model. This is because they require less computation to perform the same task. For example, the 70B parameter 5-bit quantized Llama-2 model can generate text twice as fast as the original model on a GPU.\n",
        "\n",
        "Third, 5-bit quantized Llama-2 models are more energy-efficient than the original model. This is because they require less power to run. This makes them ideal for use on mobile devices and other battery-powered devices.\n",
        "\n",
        "Overall, 5-bit quantized Llama-2 models are a good choice for users who need a smaller, faster, and more energy-efficient version of the original Llama-2 model. They are still very accurate and can be used for a variety of tasks, such as text generation, translation, and summarization."
      ],
      "metadata": {
        "id": "TLsJQ6wkaHWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "\n",
        "Llama-2 7B Chat 5 bit quantized models are a new type of large language model (LLM) that uses 5 bits to represent each weight in the model. This is a significant reduction from the 32 bits typically used, which can lead to significant speedups and memory savings.\n",
        "\n",
        "The 5 bit quantized Llama-2 7B Chat models were developed by Meta AI and Microsoft, and are available for free download from the Hugging Face Hub. There are a total of six 5 bit quantized models available, each with a different quantization method:\n",
        "\n",
        "q2_K\n",
        "\n",
        "q3_K_L\n",
        "\n",
        "q3_K_M\n",
        "\n",
        "q3_K_S\n",
        "\n",
        "q4_K_M\n",
        "\n",
        "q5_0\n",
        "\n",
        "The q2_K model is the smallest and fastest, but it also has the lowest accuracy. The q5_0 model is the most accurate, but it is also the largest and slowest. The other four models offer a trade-off between accuracy, speed, and size."
      ],
      "metadata": {
        "id": "mPmQ8-FYaHWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm2 = CTransformers(model=\"TheBloke/Llama-2-7B-Chat-GGML\",model_file=\"llama-2-7b-chat.ggmlv3.q5_K_M.bin\",callbacks=[StreamingStdOutCallbackHandler()],config=config)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:07:06.032927Z",
          "iopub.execute_input": "2023-10-03T04:07:06.033315Z",
          "iopub.status.idle": "2023-10-03T04:10:58.761281Z",
          "shell.execute_reply.started": "2023-10-03T04:07:06.033285Z",
          "shell.execute_reply": "2023-10-03T04:10:58.760354Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269,
          "referenced_widgets": [
            "e57bd24380d74e5cab6feaf9cb642fea",
            "92304e3b1ec84397a0ed634e3c9749aa",
            "302e1d1fcadb4b139bb7b96cd8d4c3be",
            "6eb3e4d3a0cc4370854f14d13253111c",
            "6d9a71a054634b5fb3e5fad51c4b9129",
            "01483a6bb7b8427bac2a04f5f4c993c3",
            "35f9399fb6f34d9a9cab2b9626b50245",
            "3326ede124674edca466ef833e5d5f26",
            "d0cc04c725d14116b34c61cbb5df25ba",
            "685cbfe79e4a4d5e8edff767875d8560",
            "3034d158f35f4a4fb767b726ea8cd082",
            "2e3175d9e4044b6285a49e6c0bf81ca0",
            "77fe61950bbe497692b836a7e0014f7f",
            "305ab6d105f34a9898035f37779a8ec8",
            "4522c7b0c2fb4ead96a718ec2f3d466f",
            "58495acfefc74bdf8e2b32bf3ee1ca30",
            "ce118e44a38e48b1b63401ba1ffcda4c",
            "078b0dbabaf84e6eb1a8112485927009",
            "c9d03dcd9b104e6782062b46631bccf5",
            "1e8c7ac1bf354b858a88d4f6666194c4",
            "335bf1476e0442c7931966ebc4563634",
            "7a1944fb223f4182b9e26de4fd797bce",
            "43ab23d623a34f4ab4687386bfc9b6b8",
            "677740f9589c4001a36300249d8b1ae6",
            "ba5dd2acf3d84b73849ff697696ca9c6",
            "aab50d67c5bc4b00b72e43adbc8548db",
            "fca39744544f42a99eab71d42c0a9c41",
            "68a7d60792e54b369e1e7e699c1290c0",
            "bf8ed08ab30f4bf7b9ae892bf9392276",
            "0811c40990c04bb9a896f306a34fd41f",
            "9ff851240a3d4355adce2849ad3aea64",
            "fb20fc6d17ae41ccaf819d92407bc7ef",
            "f043afb012fc44969a2585ba53a55b2d",
            "c106ad9f28884d36a098f242293330d3",
            "9a72c3fccdd440f097403fb16ff1dd29",
            "a80352f191354d5db754ce1166511a76",
            "21d1c32b5a8c45a2ad92b321266f5f3f",
            "0e52ec1282514168883c70082a302b48",
            "8e7327afd0e34a47afbc009b3051e682",
            "d9fbfa8fe7254d39a1d444deccc54265",
            "4a0f3ef6d80848618d67c68a281d947e",
            "4d37834797a7472a84e2b453c697c153",
            "1ecaaf90cdfa4e47873abf03f086fef7",
            "427ed51c172a4ecbb85cd9b409875ffb"
          ]
        },
        "id": "ECECdm70aHWE",
        "outputId": "d8cd4bef-3023-4b6b-e4e3-5de63658a005"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e57bd24380d74e5cab6feaf9cb642fea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e3175d9e4044b6285a49e6c0bf81ca0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43ab23d623a34f4ab4687386bfc9b6b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "llama-2-7b-chat.ggmlv3.q5_K_M.bin:   0%|          | 0.00/4.78G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c106ad9f28884d36a098f242293330d3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "[INST] <<sys>>\n",
        "you are a helpful, respectful and honest assistent. Your answers are always descriptive.You will be attentive to details.\n",
        "<</sys>>\n",
        "{text}[/INST]\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template= template,input_variables=[\"text\"])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:10:58.76272Z",
          "iopub.execute_input": "2023-10-03T04:10:58.763697Z",
          "iopub.status.idle": "2023-10-03T04:10:58.769095Z",
          "shell.execute_reply.started": "2023-10-03T04:10:58.763632Z",
          "shell.execute_reply": "2023-10-03T04:10:58.767626Z"
        },
        "trusted": true,
        "id": "QAAoJFJEaHWE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llmchain2 = LLMChain(prompt=prompt,llm=llm2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:10:58.770675Z",
          "iopub.execute_input": "2023-10-03T04:10:58.770992Z",
          "iopub.status.idle": "2023-10-03T04:10:58.790415Z",
          "shell.execute_reply.started": "2023-10-03T04:10:58.770946Z",
          "shell.execute_reply": "2023-10-03T04:10:58.78865Z"
        },
        "trusted": true,
        "id": "CmaqvKJuaHWE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news=\".\".join(n[\"News\"].to_list())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:10:58.792386Z",
          "iopub.execute_input": "2023-10-03T04:10:58.79285Z",
          "iopub.status.idle": "2023-10-03T04:10:58.808052Z",
          "shell.execute_reply.started": "2023-10-03T04:10:58.792807Z",
          "shell.execute_reply": "2023-10-03T04:10:58.80628Z"
        },
        "trusted": true,
        "id": "-SXoVs2XaHWF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BBZu44A4aHWF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U3vEXN3MaHWF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the Query as you deem feasible"
      ],
      "metadata": {
        "id": "tTCzn6CSaHWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = f\"\"\"\n",
        "Here are some news headlines:\n",
        "{news}\n",
        "\n",
        "Summarize the market from this news data.\n",
        "\"\"\"\n",
        "\n",
        "response = llmchain2.run(query)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-03T04:12:07.971772Z",
          "iopub.execute_input": "2023-10-03T04:12:07.97384Z",
          "iopub.status.idle": "2023-10-03T04:20:32.114372Z",
          "shell.execute_reply.started": "2023-10-03T04:12:07.973777Z",
          "shell.execute_reply": "2023-10-03T04:20:32.112922Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dVOZlI2zaHWG",
        "outputId": "650d0287-edb4-48a8-eb45-60dd07438edc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the news articles provided, here is a summary of the current state of the market:\n",
            "\n",
            "1. Jobs Report: The US economy added 353,000 jobs in January, blowing past Wall Street expectations. This indicates a strong labor market and economic growth.\n",
            "2. Stock Market Today: Stocks mostly rose after the jobs report, with tech earnings contributing to the gains. However, Apple stock slipped due to concerns about China sales.\n",
            "3. Meta (Facebook) Earnings: Meta's quarterly earnings were better than expected, leading to a 16% jump in stock price. The company also announced its first-ever dividend and a new stock buyback program.\n",
            "4. Inflation: Car insurance is the latest inflation scourge, with prices rising at a faster pace than wages.\n",
            "5. Apple CEO Tim Cook: General Artificial Intelligence (AI) is a \"huge opportunity\" for Apple, and the company is expected to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1025) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1026) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1027) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1028) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1029) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1030) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1031) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1032) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1033) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1034) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "le"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1035) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1036) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " major"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1037) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1038) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1039) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " To"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1040) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1041) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1042) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1043) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1044) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1045) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1046) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1047) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1048) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1049) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1050) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "le"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1051) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " made"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1052) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " major"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1053) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1054) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1055) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1056) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1057) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1058) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1059) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1060) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1061) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1062) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1063) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1064) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1065) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1066) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1067) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1068) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1069) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " major"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1070) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1071) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1072) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1073) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1074) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1075) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1076) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ase"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1077) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " annual"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1078) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1079) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1080) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1081) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1082) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1083) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1084) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1085) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1086) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1087) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1088) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1089) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1090) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1091) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1092) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1093) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " major"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1094) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1095) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1096) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1097) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1098) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1099) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1100) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1101) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1102) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1103) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1104) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1105) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1106) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1107) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1108) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1109) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1110) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " significant"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1111) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " invest"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1112) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " more"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1113) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " news"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1114) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " on"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1115) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1116) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1117) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1118) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1119) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1120) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1121) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1122) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1123) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1124) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1125) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " major"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1126) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1127) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1128) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1129) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1130) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1131) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1132) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1133) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1134) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "le"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1135) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " making"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1136) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1137) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1138) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1139) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1140) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " major"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1141) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1142) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1143) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1144) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1145) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1146) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1147) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1148) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1149) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " major"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1150) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1151) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1152) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1153) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1154) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1155) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1156) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Ann"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1157) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "oun"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1158) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ces"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1159) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ann"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1160) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ou"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1161) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bt"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1162) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " mak"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1163) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1164) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1165) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1166) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1167) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1168) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1169) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1170) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1171) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1172) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ase"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1173) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ann"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1174) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ounce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1175) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " new"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1176) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " product"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1177) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1178) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1179) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1180) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Big"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1181) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Ann"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1182) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "oun"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1183) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1184) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1185) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1186) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1187) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1188) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1189) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1190) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1191) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1192) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1193) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1194) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " significant"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1195) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " growth"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1196) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " in"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1197) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1198) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1199) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1200) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1201) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1202) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1203) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1204) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1205) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1206) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1207) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " some"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1208) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " important"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1209) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1210) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1211) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1212) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1213) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1214) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1215) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1216) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1217) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " significant"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1218) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " re"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1219) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "le"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1220) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1221) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1222) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1223) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1224) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1225) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1226) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " major"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1227) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1228) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1229) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1230) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1231) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1232) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1233) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1234) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1235) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " major"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1236) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1237) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1238) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "le"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1239) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " making"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1240) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " significant"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1241) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " invest"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1242) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ments"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1243) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " coming"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1244) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " up"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1245) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coming"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1246) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " out"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1247) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " new"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1248) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1249) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1250) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announced"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1251) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " new"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1252) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1253) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1254) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1255) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1256) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1257) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1258) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " to"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1259) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " make"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1260) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " announ"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1261) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ce"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1262) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "le"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1263) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ast"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:ctransformers:Number of tokens (1264) exceeded maximum context length (1024).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-73d1956d2303>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllmchain2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m             return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    539\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    361\u001b[0m         }\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         final_outputs: Dict[str, Any] = self.prep_outputs(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    529\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m                 )\n\u001b[1;32m    702\u001b[0m             ]\n\u001b[0;32m--> 703\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             output = (\n\u001b[0;32m--> 554\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    555\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m             text = (\n\u001b[0;32m-> 1139\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/ctransformers.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0m_run_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCallbackManagerForLLMRun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_noop_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0m_run_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_new_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ctransformers/llm.py\u001b[0m in \u001b[0;36m_stream\u001b[0;34m(self, prompt, max_new_tokens, top_k, top_p, temperature, repetition_penalty, last_n_tokens, seed, batch_size, threads, stop, reset)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mincomplete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         for token in self.generate(\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ctransformers/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, tokens, top_k, top_p, temperature, repetition_penalty, last_n_tokens, seed, batch_size, threads, reset)\u001b[0m\n\u001b[1;32m    535\u001b[0m                 \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             )\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eos_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ctransformers/llm.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, tokens, batch_size, threads)\u001b[0m\n\u001b[1;32m    401\u001b[0m             )\n\u001b[1;32m    402\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc_int\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         status = self.ctransformers_llm_batch_eval(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mn_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N69q9llgaHWG"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}